{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Text Matching Classifier: baseline system\n",
    "\n",
    "This program has been adapted and rewritten from sources such as:\n",
    "- [TensorFlow CNN Tutorial](https://www.tensorflow.org/tutorials/images/cnn)\n",
    "- [Keras Concatenate Layer Documentation](https://keras.io/api/layers/merging_layers/concatenate/)\n",
    "- [Sentence Transformers Package](https://pypi.org/project/sentence-transformers/)\n",
    "\n",
    "If you are new to TensorFlow, read the following brief tutorial:\n",
    "- [TensorFlow Quickstart Beginner Tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
    "\n",
    "As you develop your experience and skills, you may want to check details of particular aspects of the TensorFlow API:\n",
    "- [TensorFlow API Documentation](https://www.tensorflow.org/api_docs/python/tf/all_symbols)\n",
    "\n",
    "This is a binary classifier for image-text matching, where the inputs are images and text-based features, and the outputs (denoted as match=[1,0] and nomatch=[0,1]) correspond to (predicted) answers. This baseline classifier makes use of two strands of features. The first are produced by a CNN-classifier, and the second are derived offline from a sentence embedding generator. The latter have the advantage of being generated once, which can accelerate training due to being pre-trained and loaded at runtime. Those two strands of features are concatenated at training time to form a multimodal set of features, combining learnt image features and pre-trained sentence features.\n",
    "\n",
    "This program has been tested using an Anaconda environment with Python 3.9 and 3.10 on Windows 11 and Linux Ubuntu 22. The easiest way to run this baseline at Uni is by booting your PC with Windows and using the following steps:\n",
    "\n",
    "1. Make sure that your downloaded data and baseline system are extracted in the Downloads folder. Note. Your path should start with /mnt/c/Users/Computing/Downloads\n",
    "\n",
    "2. Open a terminal and select Ubuntu from the little arrow pointing down. Note. Your program will be executed under a Linux environment.\n",
    "\n",
    "3. Install the following dependencies:\n",
    "\n",
    "4. Edit file ITM_Classifier-baseline.py and make sure that variable IMAGES_PATH points to the right folder containing the data.\n",
    "\n",
    "5. Run the program using a command such as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ python ITM_Classifier-baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code above can also be run from Visual Studio Code. To access it using the Linux environment type \"code .\" in the Ubuntu terminal. From VSCode, click View, Terminal, type your command (example: python ITM_Classifier-baseline.py) and Enter.\n",
    "\n",
    "Running this baseline takes about 5 minutes with a GPU-enabled Uni PC. WARNING: Running this code without a GPU is too slow and not recommended.\n",
    "\n",
    "In your own PC you can use Anaconda to run this code. From a conda terminal for example. If you want GPU-enabled execution, it is recommended that you install the following versions of software:\n",
    "- CUDA 11.8\n",
    "- CuDNN 8.6\n",
    "- TensorFlow 2.10\n",
    "\n",
    "Feel free to use and/or modify this program as part of your CMP9137 assignment. You are invited to use the knowledge acquired during lectures, workshops and beyond to propose and evaluate alternative solutions to this baseline.\n",
    "\n",
    "Version 1.0, main functionality tested with COCO data\n",
    "Version 1.2, extended functionality for Flickr data\n",
    "Contact: {hcuayahuitl, lzhang, friaz}@lincoln.ac.uk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dependencies\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import einops\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from official.nlp import optimization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n",
      "Using GPU: GPU /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Verify TensorFlow can detect the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if len(gpus) > 0:\n",
    "    print(f\"Using GPU: {gpus[0].device_type} {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading image and text data\n",
    "\n",
    "class ITM_DataLoader():\n",
    "    BATCH_SIZE = 16\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    IMAGE_SHAPE = (224, 224, 3)\n",
    "    SENTENCE_EMBEDDING_SHAPE = (384)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    IMAGES_PATH = \"/home/rinzler/Github/Image-Text-Matching/data/images\"\n",
    "    train_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.TrainImages.txt\"\n",
    "    dev_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.DevImages.txt\"\n",
    "    test_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.TestImages.txt\"\n",
    "    sentence_embeddings_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.cmp9137.sentence_transformers.pkl\"\n",
    "    sentence_embeddings = {}\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    test_ds = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentence_embeddings = self.load_sentence_embeddings()\n",
    "        self.train_ds = self.load_classifier_data(self.train_data_file)\n",
    "        self.val_ds = self.load_classifier_data(self.dev_data_file)\n",
    "        self.test_ds = self.load_classifier_data(self.test_data_file)\n",
    "        print(\"done loading data...\")\n",
    "\n",
    "    # Sentence embeddings are dense vectors representing text data, one vector per sentence. \n",
    "    # Sentences with similar vectors would mean sentences with equivalent meanning.  \n",
    "\t# They are useful here to provide text-based features of questions in the data.\n",
    "    # Note: sentence embeddings don't include label info, they are solely based on captions.\n",
    "    def load_sentence_embeddings(self):\n",
    "        sentence_embeddings = {}\n",
    "        print(\"READING sentence embeddings...\")\n",
    "        with open(self.sentence_embeddings_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            for sentence, dense_vector in data.items():\n",
    "                sentence_embeddings[sentence] = dense_vector\n",
    "                #print(\"*sentence=\",sentence)\n",
    "        print(\"Done reading sentence_embeddings!\")\n",
    "        return sentence_embeddings\n",
    "\n",
    "    # In contrast to text-data based on pre-trained features, image data does not use\n",
    "    # any form of pre-training in this program. Instead, it makes use of raw pixels.\n",
    "    # Notes that input features to the classifier are only pixels and sentence embeddings.\n",
    "    def process_input(self, img_path, dense_vector, text, label):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.IMAGE_SIZE)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.cast(img, tf.float32) / 255\n",
    "        features = {}\n",
    "        features[\"image_input\"] = img\n",
    "        features[\"text_embedding\"] = dense_vector\n",
    "        features[\"caption\"] = text\n",
    "        features[\"file_name\"] = img_path\n",
    "        return features, label\n",
    "\n",
    "    # This method loads the multimodal data, which comes from the following sources:\n",
    "    # (1) image files in IMAGES_PATH, and (2) files with pattern flickr8k.*Images.txt\n",
    "    # The data is stored in a tensorflow data structure to make it easy to use by\n",
    "    # the tensorflow model during training, validation and test. This method was \n",
    "    # carefully prepared to load the data rapidly, i.e., by loading already created\n",
    "    # sentence embeddings (text features) rather than creating them at runtime.\n",
    "    def load_classifier_data(self, data_files):\n",
    "        print(\"LOADING data from \"+str(data_files))\n",
    "        print(\"=========================================\")\n",
    "        image_data = []\n",
    "        text_data = []\n",
    "        embeddings_data = []\n",
    "        label_data = []\n",
    "\t\t\n",
    "        # get image, text, label of image_files\n",
    "        with open(data_files) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                img_name, text, raw_label = line.split(\"\t\")\n",
    "                img_name = os.path.join(self.IMAGES_PATH, img_name.strip())\n",
    "\n",
    "                # get binary labels from match/no-match answers\n",
    "                label = [1, 0] if raw_label == \"match\" else [0, 1]\n",
    "                #print(\"I=%s T=%s _L=%s L=%s\" % (img_name, text, raw_label, label)) \n",
    "\n",
    "\t\t\t\t# get sentence embeddings (of textual captions)\n",
    "                text_sentence_embedding = self.sentence_embeddings[text]\n",
    "                text_sentence_embedding = tf.constant(text_sentence_embedding)\n",
    "\n",
    "                image_data.append(img_name)\n",
    "                embeddings_data.append(text_sentence_embedding)\n",
    "                text_data.append(text)\n",
    "                label_data.append(label)\n",
    "\n",
    "        print(\"|image_data|=\"+str(len(image_data)))\n",
    "        print(\"|text_data|=\"+str(len(text_data)))\n",
    "        print(\"|label_data|=\"+str(len(label_data)))\n",
    "\t\t\n",
    "        # prepare a tensorflow dataset using the lists generated above\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_data, embeddings_data, text_data, label_data))\n",
    "        dataset = dataset.shuffle(self.BATCH_SIZE * 8)\n",
    "        dataset = dataset.map(self.process_input, num_parallel_calls=self.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.BATCH_SIZE).prefetch(self.AUTOTUNE)\n",
    "        self.print_data_samples(dataset)\n",
    "        return dataset\n",
    "\n",
    "    def print_data_samples(self, dataset):\n",
    "        print(\"PRINTING data samples...\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        for features_batch, label_batch in dataset.take(1):\n",
    "            for i in range(1):\n",
    "                print(f'Image pixels: {features_batch[\"image_input\"]}')\n",
    "                print(f'Sentence embeddings: {features_batch[\"text_embedding\"]}')\n",
    "                print(f'Caption: {features_batch[\"caption\"].numpy()}')\n",
    "                label = label_batch.numpy()[i]\n",
    "                print(f'Label : {label}')\n",
    "        print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class for the Image-Text Matching (ITM) task\n",
    "\n",
    "class ITM_Classifier(ITM_DataLoader):\n",
    "    epochs = 10\n",
    "    learning_rate = 3e-5\n",
    "    class_names = {'match', 'no-match'}\n",
    "    num_classes = len(class_names)\n",
    "    classifier_model = None\n",
    "    history = None\n",
    "    classifier_model_name = 'ITM_Classifier-flickr'\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_classifier_model()\n",
    "        self.train_classifier_model()\n",
    "        self.test_classifier_model()\n",
    "\n",
    "    # return learnt feature representations of input data (images)\n",
    "    def create_vision_encoder(self, num_projection_layers, projection_dims, dropout_rate):\n",
    "        img_input = layers.Input(shape=self.IMAGE_SHAPE, name=\"image_input\")\n",
    "        cnn_layer = layers.Conv2D(16, 3, padding='same', activation='relu')(img_input)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(32, 3, padding='same', activation='relu')(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(64, 3, padding='same', activation='relu')(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Dropout(dropout_rate)(cnn_layer)\n",
    "        cnn_layer = layers.Flatten()(cnn_layer)\n",
    "        outputs = self.project_embeddings(cnn_layer, num_projection_layers, projection_dims, dropout_rate)\n",
    "        return img_input, outputs\n",
    "\n",
    "    # return learnt feature representations based on dense layers, dropout, and layer normalisation\n",
    "    def project_embeddings(self, embeddings, num_projection_layers, projection_dims, dropout_rate):\n",
    "        projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "        for _ in range(num_projection_layers):\n",
    "            x = tf.nn.gelu(projected_embeddings)\n",
    "            x = layers.Dense(projection_dims)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "            x = layers.Add()([projected_embeddings, x])\n",
    "            projected_embeddings = layers.LayerNormalization()(x)\n",
    "        return projected_embeddings\n",
    "\n",
    "    # return learnt feature representations of input data (text embeddings in the form of dense vectors)\n",
    "    def create_text_encoder(self, num_projection_layers, projection_dims, dropout_rate):\n",
    "        text_input = keras.Input(shape=self.SENTENCE_EMBEDDING_SHAPE, name='text_embedding')\n",
    "        outputs = self.project_embeddings(text_input, num_projection_layers, projection_dims, dropout_rate)\n",
    "        return text_input, outputs\n",
    "\n",
    "    # put together the feature representations above to create the image-text (multimodal) deep learning model\n",
    "    def build_classifier_model(self):\n",
    "        print(f'BUILDING model')\n",
    "        img_input, vision_net = self.create_vision_encoder(num_projection_layers=1, projection_dims=128, dropout_rate=0.1)\n",
    "        text_input, text_net = self.create_text_encoder(num_projection_layers=1, projection_dims=128, dropout_rate=0.1)\n",
    "        net = tf.keras.layers.Concatenate(axis=1)([vision_net, text_net])\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(self.num_classes, activation='softmax', name=self.classifier_model_name)(net)\n",
    "        self.classifier_model = tf.keras.Model(inputs=[img_input, text_input], outputs=net)\n",
    "        self.classifier_model.summary()\n",
    "\t\n",
    "    def train_classifier_model(self):\n",
    "        print(f'TRAINING model')\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        num_warmup_steps = int(0.2*num_train_steps)\n",
    "\n",
    "        loss = tf.keras.losses.KLDivergence()\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "        optimizer = optimization.create_optimizer(init_lr=self.learning_rate,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "        self.classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # uncomment the next line if you wish to make use of early stopping during training\n",
    "        #callbacks = [tf.keras.callbacks.EarlyStopping(patience=11, restore_best_weights=True)]\n",
    "\n",
    "        self.history = self.classifier_model.fit(x=self.train_ds, validation_data=self.val_ds, epochs=self.epochs)#, callbacks=callbacks)\n",
    "        print(\"model trained!\")\n",
    "\n",
    "    def test_classifier_model(self):\n",
    "        print(\"TESTING classifier model (showing a sample of image-text-matching predictions)...\")\n",
    "        num_classifications = 0\n",
    "        num_correct_predictions = 0\n",
    "\n",
    "        # read test data for ITM classification\n",
    "        for features, groundtruth in self.test_ds:\n",
    "            groundtruth = groundtruth.numpy()\n",
    "            predictions = self.classifier_model(features)\n",
    "            predictions = predictions.numpy()\n",
    "            captions = features[\"caption\"].numpy()\n",
    "            file_names = features[\"file_name\"].numpy()\n",
    "\n",
    "            # read test data per batch\n",
    "            for batch_index in range(0, len(groundtruth)):\n",
    "                predicted_values = predictions[batch_index]\n",
    "                probability_match = predicted_values[0]\n",
    "                probability_nomatch = predicted_values[1]\n",
    "                predicted_class = \"[1 0]\" if probability_match > probability_nomatch else \"[0 1]\"\n",
    "                if str(groundtruth[batch_index]) == predicted_class: \n",
    "                    num_correct_predictions += 1\n",
    "                num_classifications += 1\n",
    "\n",
    "                # print a sample of predictions -- about 10% of all possible\n",
    "                if random.random() < 0.1:\n",
    "                    caption = captions[batch_index]\n",
    "                    file_name = file_names[batch_index].decode(\"utf-8\")\n",
    "                    print(\"ITM=%s PREDICTIONS: match=%s, no-match=%s \\t -> \\t %s\" % (caption, probability_match, probability_nomatch, file_name))\n",
    "\n",
    "        # reveal test performance using our own calculations above\n",
    "        accuracy = num_correct_predictions/num_classifications\n",
    "        print(\"TEST accuracy=%4f\" % (accuracy))\n",
    "\n",
    "        # reveal test performance using Tensorflow calculations\n",
    "        loss, accuracy = self.classifier_model.evaluate(self.test_ds)\n",
    "        print(f'Tensorflow test method: Loss: {loss}; ACCURACY: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING sentence embeddings...\n",
      "Done reading sentence_embeddings!\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.TrainImages.txt\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:03.128873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.129376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.129719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.264483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.265102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.265622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-14 22:24:03.266036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|image_data|=19386\n",
      "|text_data|=19386\n",
      "|label_data|=19386\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.09019608 0.09019608 0.04313726]\n",
      "   [0.10196079 0.10196079 0.05490196]\n",
      "   [0.10980392 0.11372549 0.05882353]\n",
      "   ...\n",
      "   [0.34509805 0.38431373 0.41960785]\n",
      "   [0.34901962 0.3882353  0.42352942]\n",
      "   [0.34901962 0.3882353  0.42352942]]\n",
      "\n",
      "  [[0.09803922 0.09019608 0.04313726]\n",
      "   [0.10588235 0.10980392 0.05490196]\n",
      "   [0.1254902  0.11764706 0.06666667]\n",
      "   ...\n",
      "   [0.3137255  0.34901962 0.3764706 ]\n",
      "   [0.32156864 0.35686275 0.39215687]\n",
      "   [0.3254902  0.36078432 0.3882353 ]]\n",
      "\n",
      "  [[0.09019608 0.07450981 0.02745098]\n",
      "   [0.10196079 0.09411765 0.03529412]\n",
      "   [0.1254902  0.11372549 0.05490196]\n",
      "   ...\n",
      "   [0.27058825 0.29803923 0.32156864]\n",
      "   [0.2784314  0.30588236 0.3372549 ]\n",
      "   [0.28235295 0.30980393 0.33333334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39215687 0.2784314  0.14509805]\n",
      "   [0.36862746 0.25490198 0.12156863]\n",
      "   [0.3882353  0.27450982 0.14117648]\n",
      "   ...\n",
      "   [0.3764706  0.30980393 0.2       ]\n",
      "   [0.35686275 0.29803923 0.18431373]\n",
      "   [0.33333334 0.2784314  0.16470589]]\n",
      "\n",
      "  [[0.36862746 0.25490198 0.12156863]\n",
      "   [0.36078432 0.24705882 0.11372549]\n",
      "   [0.3764706  0.27450982 0.14509805]\n",
      "   ...\n",
      "   [0.34901962 0.2784314  0.18431373]\n",
      "   [0.35686275 0.2784314  0.18039216]\n",
      "   [0.34117648 0.2627451  0.16470589]]\n",
      "\n",
      "  [[0.3372549  0.22352941 0.09019608]\n",
      "   [0.3372549  0.22352941 0.09019608]\n",
      "   [0.32941177 0.22745098 0.09803922]\n",
      "   ...\n",
      "   [0.33333334 0.2509804  0.16862746]\n",
      "   [0.39215687 0.30588236 0.21568628]\n",
      "   [0.34901962 0.25490198 0.16078432]]]\n",
      "\n",
      "\n",
      " [[[0.7882353  0.80784315 0.7921569 ]\n",
      "   [0.7921569  0.8117647  0.79607844]\n",
      "   [0.8        0.81960785 0.8039216 ]\n",
      "   ...\n",
      "   [0.7411765  0.7490196  0.7294118 ]\n",
      "   [0.7411765  0.7490196  0.7294118 ]\n",
      "   [0.73333335 0.7411765  0.72156864]]\n",
      "\n",
      "  [[0.7882353  0.80784315 0.7921569 ]\n",
      "   [0.7882353  0.80784315 0.7921569 ]\n",
      "   [0.7921569  0.8117647  0.79607844]\n",
      "   ...\n",
      "   [0.75686276 0.7647059  0.74509805]\n",
      "   [0.75686276 0.7647059  0.74509805]\n",
      "   [0.7529412  0.7607843  0.7411765 ]]\n",
      "\n",
      "  [[0.7921569  0.8117647  0.79607844]\n",
      "   [0.7921569  0.8117647  0.79607844]\n",
      "   [0.7882353  0.80784315 0.7921569 ]\n",
      "   ...\n",
      "   [0.7764706  0.78431374 0.77254903]\n",
      "   [0.7764706  0.78431374 0.77254903]\n",
      "   [0.7764706  0.78431374 0.77254903]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7019608  0.7058824  0.6745098 ]\n",
      "   [0.69803923 0.7019608  0.67058825]\n",
      "   [0.68235296 0.6862745  0.654902  ]\n",
      "   ...\n",
      "   [0.7529412  0.7764706  0.7372549 ]\n",
      "   [0.7254902  0.7490196  0.70980394]\n",
      "   [0.74509805 0.76862746 0.7294118 ]]\n",
      "\n",
      "  [[0.64705884 0.654902   0.6117647 ]\n",
      "   [0.627451   0.63529414 0.5921569 ]\n",
      "   [0.65882355 0.6666667  0.62352943]\n",
      "   ...\n",
      "   [0.6627451  0.6666667  0.6431373 ]\n",
      "   [0.7490196  0.7529412  0.7294118 ]\n",
      "   [0.7607843  0.7647059  0.7411765 ]]\n",
      "\n",
      "  [[0.6117647  0.61960787 0.5764706 ]\n",
      "   [0.6627451  0.67058825 0.627451  ]\n",
      "   [0.64705884 0.654902   0.6117647 ]\n",
      "   ...\n",
      "   [0.7254902  0.72156864 0.7019608 ]\n",
      "   [0.75686276 0.7529412  0.73333335]\n",
      "   [0.7411765  0.7372549  0.7176471 ]]]\n",
      "\n",
      "\n",
      " [[[0.9490196  0.94509804 0.8745098 ]\n",
      "   [0.9529412  0.9490196  0.8784314 ]\n",
      "   [0.9607843  0.95686275 0.8862745 ]\n",
      "   ...\n",
      "   [0.972549   0.94509804 0.83137256]\n",
      "   [0.9647059  0.94509804 0.83137256]\n",
      "   [0.9607843  0.9411765  0.827451  ]]\n",
      "\n",
      "  [[0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   ...\n",
      "   [0.9647059  0.99215686 0.92156863]\n",
      "   [0.9607843  0.9882353  0.91764706]\n",
      "   [0.9607843  0.9882353  0.91764706]]\n",
      "\n",
      "  [[1.         1.         0.98039216]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   ...\n",
      "   [0.6431373  0.7647059  0.7764706 ]\n",
      "   [0.6392157  0.7607843  0.77254903]\n",
      "   [0.627451   0.7607843  0.76862746]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5647059  0.5372549  0.5058824 ]\n",
      "   [0.5882353  0.56078434 0.5294118 ]\n",
      "   [0.59607846 0.5686275  0.5372549 ]\n",
      "   ...\n",
      "   [0.72156864 0.70980394 0.68235296]\n",
      "   [0.6784314  0.6784314  0.6392157 ]\n",
      "   [0.7294118  0.7294118  0.6901961 ]]\n",
      "\n",
      "  [[0.5921569  0.5647059  0.53333336]\n",
      "   [0.6039216  0.5764706  0.54509807]\n",
      "   [0.6117647  0.58431375 0.5529412 ]\n",
      "   ...\n",
      "   [0.7019608  0.6901961  0.6627451 ]\n",
      "   [0.7137255  0.7137255  0.68235296]\n",
      "   [0.69411767 0.69411767 0.6627451 ]]\n",
      "\n",
      "  [[0.59607846 0.5686275  0.5372549 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   ...\n",
      "   [0.67058825 0.65882355 0.6313726 ]\n",
      "   [0.7372549  0.7372549  0.7058824 ]\n",
      "   [0.68235296 0.68235296 0.6509804 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.24313726 0.27450982 0.22352941]\n",
      "   [0.19215687 0.22352941 0.17254902]\n",
      "   [0.14901961 0.1764706  0.14509805]\n",
      "   ...\n",
      "   [0.54901963 0.61960787 0.7058824 ]\n",
      "   [0.54901963 0.61960787 0.7058824 ]\n",
      "   [0.5647059  0.63529414 0.72156864]]\n",
      "\n",
      "  [[0.20784314 0.21960784 0.1764706 ]\n",
      "   [0.20784314 0.21960784 0.1764706 ]\n",
      "   [0.20784314 0.21960784 0.18431373]\n",
      "   ...\n",
      "   [0.56078434 0.6313726  0.7254902 ]\n",
      "   [0.5647059  0.63529414 0.7294118 ]\n",
      "   [0.5372549  0.6156863  0.70980394]]\n",
      "\n",
      "  [[0.24705882 0.23137255 0.1882353 ]\n",
      "   [0.19607843 0.18039216 0.13725491]\n",
      "   [0.14509805 0.13725491 0.09019608]\n",
      "   ...\n",
      "   [0.53333336 0.6117647  0.70980394]\n",
      "   [0.5411765  0.61960787 0.7176471 ]\n",
      "   [0.53333336 0.61960787 0.7137255 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.38039216 0.38039216 0.3882353 ]\n",
      "   [0.44313726 0.44705883 0.45490196]\n",
      "   [0.2627451  0.2784314  0.2901961 ]\n",
      "   ...\n",
      "   [0.4745098  0.47843137 0.45882353]\n",
      "   [0.45882353 0.46666667 0.4627451 ]\n",
      "   [0.5137255  0.52156866 0.5176471 ]]\n",
      "\n",
      "  [[0.26666668 0.27450982 0.27058825]\n",
      "   [0.29803923 0.30588236 0.3019608 ]\n",
      "   [0.3254902  0.3254902  0.33333334]\n",
      "   ...\n",
      "   [0.53333336 0.5529412  0.5294118 ]\n",
      "   [0.6        0.60784316 0.6039216 ]\n",
      "   [0.49411765 0.49411765 0.5019608 ]]\n",
      "\n",
      "  [[0.19607843 0.20392157 0.19215687]\n",
      "   [0.20392157 0.21176471 0.2       ]\n",
      "   [0.38039216 0.37254903 0.3764706 ]\n",
      "   ...\n",
      "   [0.49411765 0.5176471  0.5019608 ]\n",
      "   [0.47843137 0.4862745  0.48235294]\n",
      "   [0.45490196 0.45490196 0.4627451 ]]]\n",
      "\n",
      "\n",
      " [[[0.19215687 0.4117647  0.23529412]\n",
      "   [0.07058824 0.27058825 0.10196079]\n",
      "   [0.10588235 0.25490198 0.09411765]\n",
      "   ...\n",
      "   [0.41568628 0.6666667  0.7137255 ]\n",
      "   [0.5058824  0.654902   0.69803923]\n",
      "   [0.8039216  0.8980392  0.9372549 ]]\n",
      "\n",
      "  [[0.25490198 0.44705883 0.32156864]\n",
      "   [0.30980393 0.49411765 0.36078432]\n",
      "   [0.27450982 0.43529412 0.3019608 ]\n",
      "   ...\n",
      "   [0.28627452 0.53333336 0.56078434]\n",
      "   [0.65882355 0.8352941  0.85882354]\n",
      "   [0.85490197 1.         1.        ]]\n",
      "\n",
      "  [[0.28627452 0.44313726 0.40784314]\n",
      "   [0.58431375 0.7490196  0.69411767]\n",
      "   [0.5176471  0.6862745  0.60784316]\n",
      "   ...\n",
      "   [0.21176471 0.45490196 0.43529412]\n",
      "   [0.4509804  0.6862745  0.6862745 ]\n",
      "   [0.53333336 0.76862746 0.77254903]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5647059  0.6901961  0.20784314]\n",
      "   [0.4745098  0.6        0.10980392]\n",
      "   [0.42745098 0.5529412  0.05490196]\n",
      "   ...\n",
      "   [0.6        0.7294118  0.28627452]\n",
      "   [0.627451   0.75686276 0.30588236]\n",
      "   [0.54901963 0.6784314  0.21960784]]\n",
      "\n",
      "  [[0.48235294 0.63529414 0.13725491]\n",
      "   [0.43137255 0.58431375 0.07843138]\n",
      "   [0.5019608  0.64705884 0.13333334]\n",
      "   ...\n",
      "   [0.61960787 0.73333335 0.26666668]\n",
      "   [0.54901963 0.6666667  0.15686275]\n",
      "   [0.5529412  0.67058825 0.14509805]]\n",
      "\n",
      "  [[0.49803922 0.65882355 0.15686275]\n",
      "   [0.5568628  0.7176471  0.20784314]\n",
      "   [0.5647059  0.72156864 0.2       ]\n",
      "   ...\n",
      "   [0.6039216  0.7137255  0.23137255]\n",
      "   [0.5686275  0.6784314  0.14117648]\n",
      "   [0.5372549  0.6509804  0.08627451]]]\n",
      "\n",
      "\n",
      " [[[0.89411765 0.90588236 0.8784314 ]\n",
      "   [0.8862745  0.8980392  0.87058824]\n",
      "   [0.87058824 0.8901961  0.8666667 ]\n",
      "   ...\n",
      "   [0.5019608  0.6784314  0.8392157 ]\n",
      "   [0.53333336 0.6862745  0.85490197]\n",
      "   [0.22745098 0.37254903 0.5372549 ]]\n",
      "\n",
      "  [[0.8784314  0.8901961  0.8627451 ]\n",
      "   [0.87058824 0.88235295 0.85490197]\n",
      "   [0.85490197 0.8745098  0.8509804 ]\n",
      "   ...\n",
      "   [0.50980395 0.68235296 0.8352941 ]\n",
      "   [0.5176471  0.6666667  0.81960785]\n",
      "   [0.43137255 0.5686275  0.7176471 ]]\n",
      "\n",
      "  [[0.84705883 0.8666667  0.84313726]\n",
      "   [0.8392157  0.85882354 0.8352941 ]\n",
      "   [0.83137256 0.8509804  0.827451  ]\n",
      "   ...\n",
      "   [0.49803922 0.654902   0.79607844]\n",
      "   [0.5294118  0.6627451  0.8       ]\n",
      "   [0.5411765  0.67058825 0.8       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07843138 0.1254902  0.04705882]\n",
      "   [0.05490196 0.10196079 0.01568628]\n",
      "   [0.07843138 0.1254902  0.03921569]\n",
      "   ...\n",
      "   [0.04705882 0.09803922 0.02745098]\n",
      "   [0.02745098 0.07843138 0.00784314]\n",
      "   [0.03529412 0.08627451 0.01568628]]\n",
      "\n",
      "  [[0.09411765 0.14117648 0.04705882]\n",
      "   [0.09803922 0.14901961 0.04705882]\n",
      "   [0.10980392 0.16078432 0.05882353]\n",
      "   ...\n",
      "   [0.05490196 0.10588235 0.03921569]\n",
      "   [0.04313726 0.09411765 0.02745098]\n",
      "   [0.05490196 0.10588235 0.03921569]]\n",
      "\n",
      "  [[0.14509805 0.19607843 0.09411765]\n",
      "   [0.12156863 0.17254902 0.0627451 ]\n",
      "   [0.2        0.2509804  0.14117648]\n",
      "   ...\n",
      "   [0.0627451  0.11372549 0.04705882]\n",
      "   [0.05490196 0.10588235 0.03921569]\n",
      "   [0.05098039 0.10196079 0.03529412]]]]\n",
      "Sentence embeddings: [[ 1.2208384e-02 -5.2623399e-02 -9.3614738e-03 ... -3.2091763e-02\n",
      "   2.5363766e-02 -1.4322941e-03]\n",
      " [-1.5139986e-02 -7.4908659e-02  8.1043534e-02 ...  6.9767781e-02\n",
      "   3.7843358e-02  2.8422039e-02]\n",
      " [-3.6273547e-02  1.5329803e-02  1.1830366e-02 ...  2.3695936e-02\n",
      "   2.8661715e-02  3.7398800e-02]\n",
      " ...\n",
      " [-2.2531865e-02 -5.8216717e-02 -2.2133118e-02 ... -3.8170382e-02\n",
      "   5.4412704e-02  1.1244480e-01]\n",
      " [ 1.8274562e-02  6.1207364e-05  6.1923057e-02 ...  3.8880739e-02\n",
      "   4.2701736e-02  4.2903353e-02]\n",
      " [ 4.7231829e-03  4.1818358e-02  4.7877044e-03 ...  1.3663455e-02\n",
      "   4.1929707e-03  4.3261625e-02]]\n",
      "Caption: [b'A little girl with red hair and a teal tracksuit on a swing .'\n",
      " b'Two dogs are making a turn on a soft sand beach .'\n",
      " b'Two smiling boys with goggles on play in an inflatable swimming pool with water up to their waists .'\n",
      " b'A wet black dog is carrying a green toy through the grass .'\n",
      " b'Two different breeds of brown and white dogs play on the beach .'\n",
      " b'Pedestrians walk on a sidewalk next to a grassy , wooded field .'\n",
      " b'a young woman wearing a purple hat with a pink feather in it'\n",
      " b'A black dog and a brown dog play with a red toy on a courtyard .'\n",
      " b'a black and white dog jumping in the air to get a toy .'\n",
      " b'A woman crouches near three dogs in a field .'\n",
      " b'Some people are fishing off the wall beside the ocean .'\n",
      " b'Several climbers in a row are climbing the rock while the man in red watches and holds the line .'\n",
      " b'Three people rest on a ledge above the moutains .'\n",
      " b'A brown dog is running after the black dog .'\n",
      " b'a brown dog plays with the hose .'\n",
      " b'People in orange vests are rowing with great effort .']\n",
      "Label : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:10.083656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [19386]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-03-14 22:24:10.084767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [19386]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.DevImages.txt\n",
      "=========================================\n",
      "|image_data|=1164\n",
      "|text_data|=1164\n",
      "|label_data|=1164\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.2784314  0.2509804  0.1882353 ]\n",
      "   [0.28627452 0.25882354 0.19607843]\n",
      "   [0.33333334 0.29803923 0.23921569]\n",
      "   ...\n",
      "   [0.21176471 0.17254902 0.16470589]\n",
      "   [0.21176471 0.17254902 0.16470589]\n",
      "   [0.19607843 0.15686275 0.14901961]]\n",
      "\n",
      "  [[0.30980393 0.28235295 0.21960784]\n",
      "   [0.32156864 0.29411766 0.23137255]\n",
      "   [0.3372549  0.3019608  0.24313726]\n",
      "   ...\n",
      "   [0.21568628 0.18431373 0.17254902]\n",
      "   [0.20392157 0.17254902 0.16078432]\n",
      "   [0.19215687 0.16078432 0.14901961]]\n",
      "\n",
      "  [[0.3254902  0.29803923 0.22745098]\n",
      "   [0.3372549  0.30980393 0.23921569]\n",
      "   [0.34901962 0.3137255  0.24705882]\n",
      "   ...\n",
      "   [0.21176471 0.2        0.18039216]\n",
      "   [0.2        0.1882353  0.16862746]\n",
      "   [0.19607843 0.18431373 0.16470589]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6509804  0.6431373  0.5921569 ]\n",
      "   [0.6431373  0.63529414 0.58431375]\n",
      "   [0.62352943 0.6156863  0.5647059 ]\n",
      "   ...\n",
      "   [0.4392157  0.4117647  0.37254903]\n",
      "   [0.42745098 0.39215687 0.35686275]\n",
      "   [0.43137255 0.39607844 0.36078432]]\n",
      "\n",
      "  [[0.63529414 0.627451   0.5764706 ]\n",
      "   [0.627451   0.61960787 0.5686275 ]\n",
      "   [0.6117647  0.6039216  0.5529412 ]\n",
      "   ...\n",
      "   [0.40392157 0.38039216 0.33333334]\n",
      "   [0.41960785 0.3882353  0.34509805]\n",
      "   [0.42745098 0.39607844 0.3529412 ]]\n",
      "\n",
      "  [[0.60784316 0.6        0.54901963]\n",
      "   [0.59607846 0.5882353  0.5372549 ]\n",
      "   [0.5921569  0.58431375 0.53333336]\n",
      "   ...\n",
      "   [0.43137255 0.40784314 0.36078432]\n",
      "   [0.4117647  0.38039216 0.3372549 ]\n",
      "   [0.3764706  0.34509805 0.3019608 ]]]\n",
      "\n",
      "\n",
      " [[[0.5764706  0.5568628  0.47058824]\n",
      "   [0.5647059  0.54509807 0.45882353]\n",
      "   [0.5764706  0.5686275  0.4862745 ]\n",
      "   ...\n",
      "   [0.7058824  0.72156864 0.6627451 ]\n",
      "   [0.7058824  0.72156864 0.6627451 ]\n",
      "   [0.69803923 0.7137255  0.654902  ]]\n",
      "\n",
      "  [[0.6039216  0.59607846 0.5137255 ]\n",
      "   [0.5921569  0.58431375 0.5019608 ]\n",
      "   [0.6        0.5882353  0.5137255 ]\n",
      "   ...\n",
      "   [0.7137255  0.7294118  0.67058825]\n",
      "   [0.72156864 0.7372549  0.6784314 ]\n",
      "   [0.73333335 0.7490196  0.6901961 ]]\n",
      "\n",
      "  [[0.5882353  0.58431375 0.5058824 ]\n",
      "   [0.5921569  0.5882353  0.50980395]\n",
      "   [0.6117647  0.60784316 0.5372549 ]\n",
      "   ...\n",
      "   [0.7411765  0.75686276 0.69803923]\n",
      "   [0.7294118  0.74509805 0.6862745 ]\n",
      "   [0.7137255  0.7294118  0.67058825]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.59607846 0.61960787 0.6117647 ]\n",
      "   [0.6039216  0.627451   0.61960787]\n",
      "   [0.58431375 0.60784316 0.6       ]\n",
      "   ...\n",
      "   [0.5372549  0.5568628  0.5294118 ]\n",
      "   [0.5058824  0.5254902  0.49803922]\n",
      "   [0.4745098  0.49411765 0.46666667]]\n",
      "\n",
      "  [[0.5411765  0.5647059  0.5568628 ]\n",
      "   [0.57254905 0.59607846 0.5882353 ]\n",
      "   [0.5647059  0.5882353  0.5803922 ]\n",
      "   ...\n",
      "   [0.45882353 0.47058824 0.44313726]\n",
      "   [0.39607844 0.40784314 0.38039216]\n",
      "   [0.40784314 0.41960785 0.39215687]]\n",
      "\n",
      "  [[0.54901963 0.57254905 0.5647059 ]\n",
      "   [0.53333336 0.5568628  0.54901963]\n",
      "   [0.56078434 0.58431375 0.5764706 ]\n",
      "   ...\n",
      "   [0.49803922 0.50980395 0.48235294]\n",
      "   [0.5764706  0.5882353  0.56078434]\n",
      "   [0.49019608 0.5019608  0.4745098 ]]]\n",
      "\n",
      "\n",
      " [[[0.19215687 0.36862746 0.20784314]\n",
      "   [0.16862746 0.34509805 0.1764706 ]\n",
      "   [0.18431373 0.36078432 0.19215687]\n",
      "   ...\n",
      "   [0.20392157 0.3529412  0.19215687]\n",
      "   [0.18431373 0.32941177 0.16078432]\n",
      "   [0.1882353  0.33333334 0.16470589]]\n",
      "\n",
      "  [[0.14901961 0.3254902  0.16470589]\n",
      "   [0.16078432 0.3372549  0.1764706 ]\n",
      "   [0.15686275 0.33333334 0.16470589]\n",
      "   ...\n",
      "   [0.21176471 0.36078432 0.2       ]\n",
      "   [0.18431373 0.32941177 0.16078432]\n",
      "   [0.16078432 0.30588236 0.13725491]]\n",
      "\n",
      "  [[0.14117648 0.31764707 0.16470589]\n",
      "   [0.08235294 0.25882354 0.09803922]\n",
      "   [0.07843138 0.25490198 0.09411765]\n",
      "   ...\n",
      "   [0.23137255 0.38039216 0.21960784]\n",
      "   [0.20392157 0.34901962 0.18039216]\n",
      "   [0.2        0.34509805 0.1764706 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10196079 0.28235295 0.09803922]\n",
      "   [0.09019608 0.27058825 0.08627451]\n",
      "   [0.14509805 0.3137255  0.13725491]\n",
      "   ...\n",
      "   [0.03921569 0.13725491 0.02352941]\n",
      "   [0.07450981 0.19215687 0.05098039]\n",
      "   [0.14117648 0.26666668 0.10588235]]\n",
      "\n",
      "  [[0.08235294 0.26666668 0.0627451 ]\n",
      "   [0.09803922 0.28235295 0.07843138]\n",
      "   [0.09019608 0.27058825 0.07843138]\n",
      "   ...\n",
      "   [0.11764706 0.1882353  0.08627451]\n",
      "   [0.1764706  0.27058825 0.12941177]\n",
      "   [0.1254902  0.23529412 0.07450981]]\n",
      "\n",
      "  [[0.11372549 0.29803923 0.08627451]\n",
      "   [0.06666667 0.2509804  0.03921569]\n",
      "   [0.05098039 0.23529412 0.03137255]\n",
      "   ...\n",
      "   [0.11372549 0.16862746 0.07058824]\n",
      "   [0.15686275 0.24313726 0.10196079]\n",
      "   [0.08235294 0.1882353  0.02745098]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.07450981 0.13725491 0.3372549 ]\n",
      "   [0.08235294 0.14509805 0.34509805]\n",
      "   [0.07450981 0.14117648 0.34509805]\n",
      "   ...\n",
      "   [0.14117648 0.23921569 0.4509804 ]\n",
      "   [0.13333334 0.23921569 0.44705883]\n",
      "   [0.13333334 0.23921569 0.44705883]]\n",
      "\n",
      "  [[0.07843138 0.14117648 0.34117648]\n",
      "   [0.08627451 0.14901961 0.34901962]\n",
      "   [0.07843138 0.14509805 0.34901962]\n",
      "   ...\n",
      "   [0.14509805 0.24313726 0.45490196]\n",
      "   [0.13725491 0.24313726 0.4509804 ]\n",
      "   [0.13725491 0.24313726 0.4509804 ]]\n",
      "\n",
      "  [[0.08235294 0.14509805 0.34509805]\n",
      "   [0.09019608 0.15294118 0.3529412 ]\n",
      "   [0.08235294 0.14901961 0.3529412 ]\n",
      "   ...\n",
      "   [0.14509805 0.24313726 0.45490196]\n",
      "   [0.13725491 0.24313726 0.4509804 ]\n",
      "   [0.13725491 0.24313726 0.4509804 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3882353  0.44313726 0.54509807]\n",
      "   [0.37254903 0.42745098 0.5294118 ]\n",
      "   [0.36862746 0.42352942 0.5254902 ]\n",
      "   ...\n",
      "   [0.6039216  0.6313726  0.7019608 ]\n",
      "   [0.5882353  0.6156863  0.6862745 ]\n",
      "   [0.5294118  0.5568628  0.627451  ]]\n",
      "\n",
      "  [[0.36078432 0.41568628 0.5176471 ]\n",
      "   [0.3764706  0.43137255 0.53333336]\n",
      "   [0.40392157 0.45882353 0.56078434]\n",
      "   ...\n",
      "   [0.59607846 0.62352943 0.69411767]\n",
      "   [0.57254905 0.6        0.67058825]\n",
      "   [0.5882353  0.6156863  0.6862745 ]]\n",
      "\n",
      "  [[0.34509805 0.4        0.5019608 ]\n",
      "   [0.32941177 0.38431373 0.4862745 ]\n",
      "   [0.39607844 0.4509804  0.5529412 ]\n",
      "   ...\n",
      "   [0.5686275  0.59607846 0.6666667 ]\n",
      "   [0.5764706  0.6039216  0.6745098 ]\n",
      "   [0.5686275  0.59607846 0.6666667 ]]]\n",
      "\n",
      "\n",
      " [[[0.23921569 0.2901961  0.1882353 ]\n",
      "   [0.16078432 0.21176471 0.10980392]\n",
      "   [0.13333334 0.18039216 0.09411765]\n",
      "   ...\n",
      "   [0.01568628 0.04705882 0.00392157]\n",
      "   [0.02352941 0.05098039 0.01960784]\n",
      "   [0.02352941 0.05098039 0.01960784]]\n",
      "\n",
      "  [[0.21176471 0.2627451  0.16078432]\n",
      "   [0.15294118 0.2        0.10588235]\n",
      "   [0.13333334 0.18039216 0.09411765]\n",
      "   ...\n",
      "   [0.01960784 0.05098039 0.00784314]\n",
      "   [0.02745098 0.05490196 0.02352941]\n",
      "   [0.02352941 0.05098039 0.01960784]]\n",
      "\n",
      "  [[0.14509805 0.19215687 0.09803922]\n",
      "   [0.12941177 0.1764706  0.08235294]\n",
      "   [0.13725491 0.18431373 0.09803922]\n",
      "   ...\n",
      "   [0.01568628 0.05490196 0.01960784]\n",
      "   [0.03137255 0.0627451  0.01960784]\n",
      "   [0.01960784 0.05098039 0.00784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.72156864 0.72156864 0.7137255 ]\n",
      "   [0.7411765  0.7411765  0.73333335]\n",
      "   [0.76862746 0.76862746 0.7607843 ]\n",
      "   ...\n",
      "   [0.73333335 0.73333335 0.7254902 ]\n",
      "   [0.72156864 0.72156864 0.7137255 ]\n",
      "   [0.7137255  0.7137255  0.7058824 ]]\n",
      "\n",
      "  [[0.7490196  0.7490196  0.7411765 ]\n",
      "   [0.74509805 0.74509805 0.7372549 ]\n",
      "   [0.7529412  0.7529412  0.74509805]\n",
      "   ...\n",
      "   [0.7490196  0.7490196  0.7411765 ]\n",
      "   [0.73333335 0.73333335 0.7254902 ]\n",
      "   [0.73333335 0.73333335 0.7254902 ]]\n",
      "\n",
      "  [[0.7490196  0.7490196  0.7411765 ]\n",
      "   [0.74509805 0.74509805 0.7372549 ]\n",
      "   [0.75686276 0.75686276 0.7490196 ]\n",
      "   ...\n",
      "   [0.74509805 0.74509805 0.7372549 ]\n",
      "   [0.7294118  0.7294118  0.72156864]\n",
      "   [0.73333335 0.73333335 0.7254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.8039216  0.8627451  0.8901961 ]\n",
      "   [0.9137255  0.9647059  1.        ]\n",
      "   [0.77254903 0.8039216  0.95686275]\n",
      "   ...\n",
      "   [0.25490198 0.29803923 0.28235295]\n",
      "   [0.4117647  0.45490196 0.4392157 ]\n",
      "   [0.38431373 0.43137255 0.41568628]]\n",
      "\n",
      "  [[0.9019608  0.972549   1.        ]\n",
      "   [0.5882353  0.654902   0.7254902 ]\n",
      "   [0.3764706  0.42745098 0.56078434]\n",
      "   ...\n",
      "   [0.6784314  0.7137255  0.70980394]\n",
      "   [0.7921569  0.83137256 0.827451  ]\n",
      "   [0.91764706 0.9647059  0.95686275]]\n",
      "\n",
      "  [[0.49803922 0.59607846 0.6745098 ]\n",
      "   [0.4        0.4862745  0.5686275 ]\n",
      "   [0.67058825 0.7529412  0.8352941 ]\n",
      "   ...\n",
      "   [0.9098039  0.9411765  0.9490196 ]\n",
      "   [0.92156863 0.9529412  0.9647059 ]\n",
      "   [0.91764706 0.95686275 0.9647059 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.96862745 0.96862745 0.9372549 ]\n",
      "   [0.92156863 0.9098039  0.88235295]\n",
      "   [0.972549   0.95686275 0.92156863]\n",
      "   ...\n",
      "   [0.43137255 0.41568628 0.40392157]\n",
      "   [0.40784314 0.39215687 0.38039216]\n",
      "   [0.4117647  0.4        0.38039216]]\n",
      "\n",
      "  [[0.8901961  0.8901961  0.85882354]\n",
      "   [0.9372549  0.9254902  0.8980392 ]\n",
      "   [0.9529412  0.9372549  0.9019608 ]\n",
      "   ...\n",
      "   [0.40784314 0.40392157 0.3882353 ]\n",
      "   [0.42352942 0.41960785 0.40392157]\n",
      "   [0.40784314 0.40392157 0.3882353 ]]\n",
      "\n",
      "  [[0.9137255  0.9137255  0.88235295]\n",
      "   [0.94509804 0.93333334 0.90588236]\n",
      "   [0.9490196  0.93333334 0.8980392 ]\n",
      "   ...\n",
      "   [0.4509804  0.44705883 0.42745098]\n",
      "   [0.45882353 0.45490196 0.4392157 ]\n",
      "   [0.5176471  0.5137255  0.49803922]]]]\n",
      "Sentence embeddings: [[-0.01924886 -0.04983495  0.02390168 ... -0.01874775 -0.01021892\n",
      "   0.06192378]\n",
      " [-0.01024691 -0.07889348 -0.01601243 ...  0.03797647 -0.01025998\n",
      "  -0.06776505]\n",
      " [-0.00246642 -0.03642585  0.10078622 ...  0.04120639  0.04220693\n",
      "  -0.01602921]\n",
      " ...\n",
      " [-0.03695896  0.05832066  0.04418658 ... -0.09812529 -0.042173\n",
      "   0.02829306]\n",
      " [ 0.01592533 -0.05751145  0.08143938 ... -0.02427499  0.11183865\n",
      "   0.09481718]\n",
      " [-0.0010619   0.00993424  0.03795077 ... -0.01331415 -0.09827287\n",
      "   0.03613993]]\n",
      "Caption: [b'A man is playing tug of war with his dog .'\n",
      " b'A group of kids are playing on a tire swing .'\n",
      " b'A muddy dog prances through the grass .'\n",
      " b'Two hikers climbing a snowy hill .' b'Kid guards face from soccer ball'\n",
      " b'Dog is jumping down a ramp .'\n",
      " b'A black dog is standing in front of a waterfall .'\n",
      " b'two woman looking into a glass case .'\n",
      " b'A person is sitting at a computer working while people wait .'\n",
      " b'A shirtless man standing on a rock overlooking a hillside .'\n",
      " b'A tan dog runs on a sandy beach .'\n",
      " b'A group of protesters picket in the road .'\n",
      " b'a brown and black dog running through a grassy field'\n",
      " b'The person wearing tennis shoes is standing on the sand .'\n",
      " b'A light blonde dog is running on the shoreline .'\n",
      " b'A boy wearing a blue t-shirt is jumping up in the air on a city street .']\n",
      "Label : [1 0]\n",
      "-----------------------------------------\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.TestImages.txt\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:10.692785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1164]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-03-14 22:24:10.693814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [1164,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|image_data|=1161\n",
      "|text_data|=1161\n",
      "|label_data|=1161\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.40392157 0.57254905 0.7882353 ]\n",
      "   [0.4        0.5686275  0.78431374]\n",
      "   [0.4        0.5686275  0.78431374]\n",
      "   ...\n",
      "   [0.1882353  0.21176471 0.15686275]\n",
      "   [0.17254902 0.18039216 0.13725491]\n",
      "   [0.12156863 0.1254902  0.09411765]]\n",
      "\n",
      "  [[0.40392157 0.57254905 0.7882353 ]\n",
      "   [0.4        0.5686275  0.78431374]\n",
      "   [0.4        0.5686275  0.78431374]\n",
      "   ...\n",
      "   [0.09411765 0.12156863 0.05098039]\n",
      "   [0.04705882 0.05882353 0.01568628]\n",
      "   [0.12941177 0.13333334 0.10196079]]\n",
      "\n",
      "  [[0.40392157 0.57254905 0.7882353 ]\n",
      "   [0.40392157 0.57254905 0.7882353 ]\n",
      "   [0.4        0.5686275  0.78431374]\n",
      "   ...\n",
      "   [0.03529412 0.06666667 0.        ]\n",
      "   [0.17254902 0.1882353  0.13333334]\n",
      "   [0.20784314 0.21960784 0.18431373]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.48235294 0.43529412 0.2784314 ]\n",
      "   [0.43529412 0.4        0.24705882]\n",
      "   [0.38039216 0.34509805 0.22352941]\n",
      "   ...\n",
      "   [0.33333334 0.39215687 0.23137255]\n",
      "   [0.20784314 0.27450982 0.09803922]\n",
      "   [0.42352942 0.49411765 0.30588236]]\n",
      "\n",
      "  [[0.58431375 0.5294118  0.38431373]\n",
      "   [0.31764707 0.27058825 0.12156863]\n",
      "   [0.5686275  0.54901963 0.4       ]\n",
      "   ...\n",
      "   [0.25490198 0.29803923 0.16470589]\n",
      "   [0.20392157 0.2627451  0.10196079]\n",
      "   [0.3529412  0.41568628 0.23921569]]\n",
      "\n",
      "  [[0.43529412 0.38039216 0.23529412]\n",
      "   [0.47843137 0.43137255 0.28235295]\n",
      "   [0.5647059  0.54509807 0.3882353 ]\n",
      "   ...\n",
      "   [0.21176471 0.25490198 0.13725491]\n",
      "   [0.19215687 0.23921569 0.09019608]\n",
      "   [0.13725491 0.19607843 0.02745098]]]\n",
      "\n",
      "\n",
      " [[[0.4862745  0.5137255  0.21176471]\n",
      "   [0.46666667 0.49803922 0.21176471]\n",
      "   [0.47058824 0.5137255  0.24705882]\n",
      "   ...\n",
      "   [0.57254905 0.6117647  0.3254902 ]\n",
      "   [0.5647059  0.5921569  0.32941177]\n",
      "   [0.5686275  0.5921569  0.34901962]]\n",
      "\n",
      "  [[0.49411765 0.52156866 0.21960784]\n",
      "   [0.48235294 0.5137255  0.21960784]\n",
      "   [0.48235294 0.5254902  0.25882354]\n",
      "   ...\n",
      "   [0.5764706  0.6156863  0.32941177]\n",
      "   [0.57254905 0.6        0.3372549 ]\n",
      "   [0.57254905 0.59607846 0.3529412 ]]\n",
      "\n",
      "  [[0.5058824  0.53333336 0.22745098]\n",
      "   [0.5019608  0.53333336 0.23921569]\n",
      "   [0.49411765 0.5372549  0.27058825]\n",
      "   ...\n",
      "   [0.58431375 0.627451   0.32941177]\n",
      "   [0.5803922  0.6039216  0.3529412 ]\n",
      "   [0.5803922  0.6039216  0.36862746]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.4117647  0.5019608  0.15686275]\n",
      "   [0.4392157  0.5294118  0.1764706 ]\n",
      "   [0.42352942 0.5058824  0.13333334]\n",
      "   ...\n",
      "   [0.5647059  0.5921569  0.31764707]\n",
      "   [0.56078434 0.5529412  0.3137255 ]\n",
      "   [0.5568628  0.5372549  0.30980393]]\n",
      "\n",
      "  [[0.4        0.47058824 0.14117648]\n",
      "   [0.38039216 0.4509804  0.12156863]\n",
      "   [0.40784314 0.47843137 0.15686275]\n",
      "   ...\n",
      "   [0.5921569  0.63529414 0.3372549 ]\n",
      "   [0.47058824 0.49019608 0.22745098]\n",
      "   [0.52156866 0.5294118  0.27450982]]\n",
      "\n",
      "  [[0.3882353  0.44705883 0.12941177]\n",
      "   [0.4392157  0.49411765 0.18431373]\n",
      "   [0.4745098  0.5294118  0.22745098]\n",
      "   ...\n",
      "   [0.53333336 0.58431375 0.27058825]\n",
      "   [0.52156866 0.56078434 0.28235295]\n",
      "   [0.49803922 0.5254902  0.25882354]]]\n",
      "\n",
      "\n",
      " [[[0.4627451  0.4627451  0.3529412 ]\n",
      "   [0.47843137 0.49019608 0.36862746]\n",
      "   [0.3254902  0.3647059  0.23137255]\n",
      "   ...\n",
      "   [0.43529412 0.5137255  0.5176471 ]\n",
      "   [0.5647059  0.6313726  0.65882355]\n",
      "   [0.4745098  0.5294118  0.5647059 ]]\n",
      "\n",
      "  [[0.31764707 0.3372549  0.21960784]\n",
      "   [0.30980393 0.3372549  0.21568628]\n",
      "   [0.2901961  0.33333334 0.20784314]\n",
      "   ...\n",
      "   [0.36078432 0.44705883 0.4392157 ]\n",
      "   [0.47843137 0.54901963 0.5647059 ]\n",
      "   [0.76862746 0.8352941  0.8627451 ]]\n",
      "\n",
      "  [[0.34509805 0.40392157 0.28235295]\n",
      "   [0.28627452 0.34509805 0.23137255]\n",
      "   [0.4        0.4627451  0.35686275]\n",
      "   ...\n",
      "   [0.36078432 0.44705883 0.43529412]\n",
      "   [0.43137255 0.50980395 0.5058824 ]\n",
      "   [0.4862745  0.5647059  0.56078434]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.29411766 0.43529412 0.28627452]\n",
      "   [0.2        0.34509805 0.18431373]\n",
      "   [0.25490198 0.4        0.23137255]\n",
      "   ...\n",
      "   [0.24313726 0.38039216 0.21568628]\n",
      "   [0.23137255 0.37254903 0.2       ]\n",
      "   [0.23921569 0.38039216 0.2       ]]\n",
      "\n",
      "  [[0.2784314  0.42352942 0.2627451 ]\n",
      "   [0.24705882 0.39215687 0.23137255]\n",
      "   [0.23529412 0.38039216 0.21960784]\n",
      "   ...\n",
      "   [0.2        0.3372549  0.18039216]\n",
      "   [0.22352941 0.3647059  0.19215687]\n",
      "   [0.17254902 0.3137255  0.13333334]]\n",
      "\n",
      "  [[0.25882354 0.40392157 0.24313726]\n",
      "   [0.24705882 0.39215687 0.23137255]\n",
      "   [0.26666668 0.40784314 0.25882354]\n",
      "   ...\n",
      "   [0.1764706  0.3137255  0.15686275]\n",
      "   [0.22745098 0.36862746 0.19607843]\n",
      "   [0.20784314 0.34901962 0.16862746]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.19215687 0.24705882 0.34901962]\n",
      "   [0.2        0.25490198 0.35686275]\n",
      "   [0.2        0.2627451  0.36078432]\n",
      "   ...\n",
      "   [0.29411766 0.35686275 0.45490196]\n",
      "   [0.2901961  0.3529412  0.4509804 ]\n",
      "   [0.28627452 0.34901962 0.44705883]]\n",
      "\n",
      "  [[0.19215687 0.24705882 0.34901962]\n",
      "   [0.19607843 0.2509804  0.3529412 ]\n",
      "   [0.2        0.2627451  0.36078432]\n",
      "   ...\n",
      "   [0.2901961  0.3529412  0.4509804 ]\n",
      "   [0.28627452 0.34901962 0.44705883]\n",
      "   [0.28627452 0.34901962 0.44705883]]\n",
      "\n",
      "  [[0.1882353  0.2509804  0.34901962]\n",
      "   [0.19215687 0.25490198 0.3529412 ]\n",
      "   [0.19607843 0.25882354 0.35686275]\n",
      "   ...\n",
      "   [0.2901961  0.3529412  0.4509804 ]\n",
      "   [0.28235295 0.34509805 0.44313726]\n",
      "   [0.28235295 0.34509805 0.44313726]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06666667 0.0627451  0.09411765]\n",
      "   [0.06666667 0.06666667 0.09803922]\n",
      "   [0.0627451  0.0627451  0.09411765]\n",
      "   ...\n",
      "   [0.07450981 0.05490196 0.07843138]\n",
      "   [0.07450981 0.05490196 0.07843138]\n",
      "   [0.07058824 0.05098039 0.07450981]]\n",
      "\n",
      "  [[0.07843138 0.07843138 0.11764706]\n",
      "   [0.05098039 0.05098039 0.08235294]\n",
      "   [0.08235294 0.08235294 0.11372549]\n",
      "   ...\n",
      "   [0.0627451  0.05490196 0.07450981]\n",
      "   [0.0627451  0.05490196 0.07450981]\n",
      "   [0.05882353 0.05098039 0.07058824]]\n",
      "\n",
      "  [[0.04313726 0.04313726 0.08235294]\n",
      "   [0.07843138 0.07843138 0.11764706]\n",
      "   [0.03529412 0.04705882 0.07450981]\n",
      "   ...\n",
      "   [0.05882353 0.05098039 0.07058824]\n",
      "   [0.05882353 0.05098039 0.07058824]\n",
      "   [0.05490196 0.04705882 0.06666667]]]\n",
      "\n",
      "\n",
      " [[[0.4627451  0.4627451  0.3529412 ]\n",
      "   [0.47843137 0.49019608 0.36862746]\n",
      "   [0.3254902  0.3647059  0.23137255]\n",
      "   ...\n",
      "   [0.43529412 0.5137255  0.5176471 ]\n",
      "   [0.5647059  0.6313726  0.65882355]\n",
      "   [0.4745098  0.5294118  0.5647059 ]]\n",
      "\n",
      "  [[0.31764707 0.3372549  0.21960784]\n",
      "   [0.30980393 0.3372549  0.21568628]\n",
      "   [0.2901961  0.33333334 0.20784314]\n",
      "   ...\n",
      "   [0.36078432 0.44705883 0.4392157 ]\n",
      "   [0.47843137 0.54901963 0.5647059 ]\n",
      "   [0.76862746 0.8352941  0.8627451 ]]\n",
      "\n",
      "  [[0.34509805 0.40392157 0.28235295]\n",
      "   [0.28627452 0.34509805 0.23137255]\n",
      "   [0.4        0.4627451  0.35686275]\n",
      "   ...\n",
      "   [0.36078432 0.44705883 0.43529412]\n",
      "   [0.43137255 0.50980395 0.5058824 ]\n",
      "   [0.4862745  0.5647059  0.56078434]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.29411766 0.43529412 0.28627452]\n",
      "   [0.2        0.34509805 0.18431373]\n",
      "   [0.25490198 0.4        0.23137255]\n",
      "   ...\n",
      "   [0.24313726 0.38039216 0.21568628]\n",
      "   [0.23137255 0.37254903 0.2       ]\n",
      "   [0.23921569 0.38039216 0.2       ]]\n",
      "\n",
      "  [[0.2784314  0.42352942 0.2627451 ]\n",
      "   [0.24705882 0.39215687 0.23137255]\n",
      "   [0.23529412 0.38039216 0.21960784]\n",
      "   ...\n",
      "   [0.2        0.3372549  0.18039216]\n",
      "   [0.22352941 0.3647059  0.19215687]\n",
      "   [0.17254902 0.3137255  0.13333334]]\n",
      "\n",
      "  [[0.25882354 0.40392157 0.24313726]\n",
      "   [0.24705882 0.39215687 0.23137255]\n",
      "   [0.26666668 0.40784314 0.25882354]\n",
      "   ...\n",
      "   [0.1764706  0.3137255  0.15686275]\n",
      "   [0.22745098 0.36862746 0.19607843]\n",
      "   [0.20784314 0.34901962 0.16862746]]]\n",
      "\n",
      "\n",
      " [[[0.5921569  0.62352943 0.32156864]\n",
      "   [0.5372549  0.57254905 0.2627451 ]\n",
      "   [0.5294118  0.5647059  0.25490198]\n",
      "   ...\n",
      "   [0.10980392 0.18431373 0.20784314]\n",
      "   [0.10980392 0.1882353  0.22352941]\n",
      "   [0.0627451  0.14117648 0.1764706 ]]\n",
      "\n",
      "  [[0.6117647  0.6862745  0.36862746]\n",
      "   [0.52156866 0.59607846 0.2784314 ]\n",
      "   [0.6666667  0.7411765  0.43137255]\n",
      "   ...\n",
      "   [0.07058824 0.14509805 0.16862746]\n",
      "   [0.08235294 0.15686275 0.18039216]\n",
      "   [0.05882353 0.14117648 0.16078432]]\n",
      "\n",
      "  [[0.5176471  0.6745098  0.32941177]\n",
      "   [0.4745098  0.627451   0.3019608 ]\n",
      "   [0.39215687 0.53333336 0.24313726]\n",
      "   ...\n",
      "   [0.06666667 0.13725491 0.15294118]\n",
      "   [0.06666667 0.14509805 0.14901961]\n",
      "   [0.06666667 0.14509805 0.14117648]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6862745  0.72156864 0.78039217]\n",
      "   [0.6901961  0.72156864 0.77254903]\n",
      "   [0.69411767 0.7176471  0.77254903]\n",
      "   ...\n",
      "   [0.6745098  0.76862746 0.8156863 ]\n",
      "   [0.654902   0.7490196  0.79607844]\n",
      "   [0.6666667  0.77254903 0.8156863 ]]\n",
      "\n",
      "  [[0.6666667  0.72156864 0.77254903]\n",
      "   [0.67058825 0.7176471  0.77254903]\n",
      "   [0.6862745  0.7176471  0.7921569 ]\n",
      "   ...\n",
      "   [0.6862745  0.7529412  0.8156863 ]\n",
      "   [0.65882355 0.74509805 0.79607844]\n",
      "   [0.6901961  0.78431374 0.8235294 ]]\n",
      "\n",
      "  [[0.6627451  0.7254902  0.7764706 ]\n",
      "   [0.6627451  0.7137255  0.7764706 ]\n",
      "   [0.67058825 0.7137255  0.7921569 ]\n",
      "   ...\n",
      "   [0.65882355 0.72156864 0.78431374]\n",
      "   [0.6509804  0.7254902  0.78039217]\n",
      "   [0.64705884 0.73333335 0.7764706 ]]]]\n",
      "Sentence embeddings: [[-0.07381976  0.1177984  -0.11919367 ...  0.00717657 -0.01244774\n",
      "   0.05696921]\n",
      " [-0.05921592  0.01854063  0.00858868 ...  0.01693322 -0.02406584\n",
      "  -0.00106289]\n",
      " [-0.0546013  -0.07537599  0.02449377 ... -0.00634701 -0.06067372\n",
      "  -0.0146732 ]\n",
      " ...\n",
      " [ 0.00917028  0.12519929  0.02178715 ...  0.05763879  0.08066183\n",
      "  -0.0043311 ]\n",
      " [-0.00278127  0.02590902  0.00514585 ...  0.05739401  0.00454728\n",
      "   0.06957012]\n",
      " [ 0.00271643 -0.0476612   0.0227539  ...  0.05505701  0.05595688\n",
      "   0.01744771]]\n",
      "Caption: [b'A child turning a crank with benches behind him .'\n",
      " b'Two young girls are taking a picture of themselves with a camera .'\n",
      " b'A group of people on skis with two dogs .'\n",
      " b'Dog jumps to get orange ball on his head .'\n",
      " b'Two children in an enclosed dog bed with the dog .'\n",
      " b'Dog with big collar running .'\n",
      " b'An elder man overlooks a balcony facing a street .'\n",
      " b'Dog looks toward a shadow'\n",
      " b'A dog is walking on a beach with the sun on the horizon .'\n",
      " b'Two puppies are wrestling on green grass .'\n",
      " b'The woman wearing the pink jacket has thrown a Frisbee for the dog to catch .'\n",
      " b'Man on bike in mountains' b'Girls are doing somersaults .'\n",
      " b'The small boy is using his blue shirt to wipe his face , exposing his belly .'\n",
      " b'Two boys preparing to jump off a pier located on a large body of water .'\n",
      " b'The dog does an obstacle course with his trainer .']\n",
      "Label : [0 1]\n",
      "-----------------------------------------\n",
      "done loading data...\n",
      "BUILDING model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:11.249325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1161]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-14 22:24:11.250206: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1161]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 16  448         ['image_input[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 28, 28, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 50176)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " text_embedding (InputLayer)    [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          6422656     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          49280       ['text_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " tf.nn.gelu (TFOpLambda)        (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.nn.gelu_1 (TFOpLambda)      (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['tf.nn.gelu[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['tf.nn.gelu_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128)          0           ['dense[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 128)          0           ['dense_2[0][0]',                \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128)         256         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 128)         256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['layer_normalization[0][0]',    \n",
      "                                                                  'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " ITM_Classifier-flickr (Dense)  (None, 2)            514         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,529,570\n",
      "Trainable params: 6,529,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "TRAINING model\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:12.681799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [19386,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2024-03-14 22:24:12.682810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [19386,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x73ab4230cee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rinzler/Github/Image-Text-Matching/env/lib/python3.10/site-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['caption', 'file_name'] which did not match any model input. They will be ignored by the model.\n",
      "2024-03-14 22:24:14.823447: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-03-14 22:24:15.706925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-03-14 22:24:15.773287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212/1212 [==============================] - ETA: 0s - loss: 0.8071 - binary_accuracy: 0.5471WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:24:57.828787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1164,384]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-03-14 22:24:57.829238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [1164,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x73ab27fc0e50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1212/1212 [==============================] - 47s 33ms/step - loss: 0.8071 - binary_accuracy: 0.5471 - val_loss: 0.6839 - val_binary_accuracy: 0.6057\n",
      "Epoch 2/10\n",
      "1212/1212 [==============================] - 37s 31ms/step - loss: 0.6802 - binary_accuracy: 0.6299 - val_loss: 0.6445 - val_binary_accuracy: 0.6400\n",
      "Epoch 3/10\n",
      "1212/1212 [==============================] - 38s 31ms/step - loss: 0.6547 - binary_accuracy: 0.6477 - val_loss: 0.6537 - val_binary_accuracy: 0.6546\n",
      "Epoch 4/10\n",
      "1212/1212 [==============================] - 38s 31ms/step - loss: 0.6446 - binary_accuracy: 0.6488 - val_loss: 0.6487 - val_binary_accuracy: 0.6581\n",
      "Epoch 5/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6369 - binary_accuracy: 0.6585 - val_loss: 0.6536 - val_binary_accuracy: 0.6581\n",
      "Epoch 6/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6347 - binary_accuracy: 0.6618 - val_loss: 0.6280 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6314 - binary_accuracy: 0.6640 - val_loss: 0.6311 - val_binary_accuracy: 0.6675\n",
      "Epoch 8/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6319 - binary_accuracy: 0.6663 - val_loss: 0.6359 - val_binary_accuracy: 0.6658\n",
      "Epoch 9/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6279 - binary_accuracy: 0.6666 - val_loss: 0.6318 - val_binary_accuracy: 0.6718\n",
      "Epoch 10/10\n",
      "1212/1212 [==============================] - 39s 32ms/step - loss: 0.6254 - binary_accuracy: 0.6681 - val_loss: 0.6311 - val_binary_accuracy: 0.6692\n",
      "model trained!\n",
      "TESTING classifier model (showing a sample of image-text-matching predictions)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 22:30:49.007340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [1161,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2024-03-14 22:30:49.008258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1161]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITM=b'A hockey player guards the goal .' PREDICTIONS: match=0.15341786, no-match=0.8465821 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/121800200_bef08fae5f.jpg\n",
      "ITM=b'A brown and a black and brown dog are playing in the water and the black one is carrying a long stick in its mouth .' PREDICTIONS: match=0.725681, no-match=0.274319 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1130017585_1a219257ac.jpg\n",
      "ITM=b'The small boy is using his blue shirt to wipe his face , exposing his belly .' PREDICTIONS: match=0.16239181, no-match=0.83760816 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1089755335_0bfbfd30e6.jpg\n",
      "ITM=b'Black dog jumping to catch tennis ball' PREDICTIONS: match=0.7035701, no-match=0.29642987 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1679565118_d36f0d6d52.jpg\n",
      "ITM=b'The Irish setter with the safety vest is running ahead of the Rottwieler and the Dalmation .' PREDICTIONS: match=0.38018498, no-match=0.61981505 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1522787272_5a31497ef2.jpg\n",
      "ITM=b'A wet dog walks out of the water .' PREDICTIONS: match=0.6677668, no-match=0.33223322 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/123997871_6a9ca987b1.jpg\n",
      "ITM=b'A dog races through the woods .' PREDICTIONS: match=0.83544755, no-match=0.16455239 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1056338697_4f7d7ce270.jpg\n",
      "ITM=b'A dog is walking on a beach with the sun on the horizon .' PREDICTIONS: match=0.6562523, no-match=0.34374774 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/109202756_b97fcdc62c.jpg\n",
      "ITM=b'A boy wearing a blue hood holds a baby animal and smiles .' PREDICTIONS: match=0.4410498, no-match=0.5589502 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1685990174_09c4fb7df8.jpg\n",
      "ITM=b'Small child looking at a colorful children s amuseument ride .' PREDICTIONS: match=0.23387663, no-match=0.76612335 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1670592963_39731a3dac.jpg\n",
      "ITM=b'Four brothers and one sister posing for a picture , smiling .' PREDICTIONS: match=0.2593933, no-match=0.7406067 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1149179852_acad4d7300.jpg\n",
      "ITM=b'Boy skateboarding on residential street , falling farward with hands on the ground .' PREDICTIONS: match=0.28347412, no-match=0.7165259 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1688699579_2f72328c7e.jpg\n",
      "ITM=b'A group of women wearing bikinis are playing beach volleyball .' PREDICTIONS: match=0.14673491, no-match=0.8532651 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1511807116_41c3645e8c.jpg\n",
      "ITM=b'A skier catches air over the snow .' PREDICTIONS: match=0.4224747, no-match=0.5775253 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2100816230_ff866fb352.jpg\n",
      "ITM=b'Some people on a pier at night with one girl fishing off it .' PREDICTIONS: match=0.32260647, no-match=0.6773935 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1089755335_0bfbfd30e6.jpg\n",
      "ITM=b'A boy in blue is blowing bubbles .' PREDICTIONS: match=0.12552506, no-match=0.87447494 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/191003285_edd8d0cf58.jpg\n",
      "ITM=b'A white dog plays outside in a fenced yard while it snows .' PREDICTIONS: match=0.6979549, no-match=0.30204508 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2100909581_b7dde5b704.jpg\n",
      "ITM=b'A young child is standing alone on some jagged rocks .' PREDICTIONS: match=0.60933244, no-match=0.3906676 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/109671650_f7bbc297fa.jpg\n",
      "ITM=b'Two children playing on a statue' PREDICTIONS: match=0.27420813, no-match=0.7257919 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2040941056_7f5fd50794.jpg\n",
      "ITM=b'A man skiing down a hill .' PREDICTIONS: match=0.6656269, no-match=0.33437315 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2229179070_dc8ea8582e.jpg\n",
      "ITM=b'A player sits on the bench while watching his teammates play ice hockey .' PREDICTIONS: match=0.08746015, no-match=0.91253984 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2203615439_3c7cdc39dc.jpg\n",
      "ITM=b'two women on a red two seater bike looking at a painting on wall' PREDICTIONS: match=0.245156, no-match=0.754844 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2315807231_6948b3f3a5.jpg\n",
      "ITM=b'A dog is backlit buy the sun as he jumps up to catch a tennis ball .' PREDICTIONS: match=0.73080826, no-match=0.26919177 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/162743064_bb242faa31.jpg\n",
      "ITM=b'A man dressed in a red outfit .' PREDICTIONS: match=0.36120197, no-match=0.63879806 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/177302997_5b2d770a0a.jpg\n",
      "ITM=b'A black and a tan dog .' PREDICTIONS: match=0.8123485, no-match=0.18765147 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2367317953_503317493e.jpg\n",
      "ITM=b'A big tan dog runs on grass with a big stick in his mouth .' PREDICTIONS: match=0.7296604, no-match=0.27033955 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2233426944_0959835ced.jpg\n",
      "ITM=b'A girl prepares to kick a soccer ball while a boy looks on .' PREDICTIONS: match=0.2441149, no-match=0.7558851 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2173312932_269f9786fc.jpg\n",
      "ITM=b'A young girl is diving into a pile of brown leaves in the yard .' PREDICTIONS: match=0.44932467, no-match=0.55067533 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2260649048_ae45d17e68.jpg\n",
      "ITM=b'A dog treads through a shallow area of water located on a rocky mountainside .' PREDICTIONS: match=0.83961713, no-match=0.1603829 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2435685480_a79d42e564.jpg\n",
      "ITM=b'A baby in a bouncy seat and a standing boy surrounded by toys .' PREDICTIONS: match=0.2401679, no-match=0.7598321 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1387785218_cee67735f5.jpg\n",
      "ITM=b'A young girl in pigtails plays in the water .' PREDICTIONS: match=0.29237318, no-match=0.7076268 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2233426944_0959835ced.jpg\n",
      "ITM=b'Two small dogs play on the lawn .' PREDICTIONS: match=0.6911441, no-match=0.30885586 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2419221084_01a14176b4.jpg\n",
      "ITM=b'a skateboarder jumps a staircase .' PREDICTIONS: match=0.17254497, no-match=0.827455 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/177302997_5b2d770a0a.jpg\n",
      "ITM=b'The child is running through a puddle in a street .' PREDICTIONS: match=0.40339178, no-match=0.5966083 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2441354291_b32e00e5a6.jpg\n",
      "ITM=b'Man pulling a cart in the street .' PREDICTIONS: match=0.54752254, no-match=0.4524775 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2199250692_a16b0c2ae1.jpg\n",
      "ITM=b'A white dog with a collar and leash is about to chew on a stick .' PREDICTIONS: match=0.6047839, no-match=0.39521605 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2543247940_083f1b7969.jpg\n",
      "ITM=b'A man in a grey suit kneels in front of a woman in a white dress .' PREDICTIONS: match=0.34816206, no-match=0.65183794 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2522230304_1581d52961.jpg\n",
      "ITM=b'A man wearing a yellow jacket throws a yellow Frisbee .' PREDICTIONS: match=0.29870558, no-match=0.7012945 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/254901702_67ada9867c.jpg\n",
      "ITM=b'Three spotted dogs outside a house .' PREDICTIONS: match=0.7526418, no-match=0.2473582 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2089539651_9e518ec7de.jpg\n",
      "ITM=b'A woman in red is sitting on the edge of a steep rock .' PREDICTIONS: match=0.7115571, no-match=0.28844288 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/248174959_2522871152.jpg\n",
      "ITM=b'Three girls walking along an arched garden pathway .' PREDICTIONS: match=0.47127908, no-match=0.5287209 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/1510078253_96e9ec50e7.jpg\n",
      "ITM=b'Five people are sitting in a bar , while a tv plays nearby .' PREDICTIONS: match=0.13537027, no-match=0.8646297 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2602306033_2b3100d36b.jpg\n",
      "ITM=b'Two workers in yellow vests try to fix something .' PREDICTIONS: match=0.07767032, no-match=0.9223297 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2656749876_e32495bd8c.jpg\n",
      "ITM=b'People at a distance trying to climb a cliff .' PREDICTIONS: match=0.6587817, no-match=0.3412183 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/121800200_bef08fae5f.jpg\n",
      "ITM=b'A tri-colored dog is jumping over obstacles .' PREDICTIONS: match=0.75067747, no-match=0.24932258 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2682194299_92005b26c6.jpg\n",
      "ITM=b'An oriental man and woman are sitting in a subway train .' PREDICTIONS: match=0.31110966, no-match=0.68889034 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2559114800_17310f3015.jpg\n",
      "ITM=b'Man with black hat , coat , and pants sitting next to the door of a building .' PREDICTIONS: match=0.34520283, no-match=0.6547972 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2467850190_07a74d89b7.jpg\n",
      "ITM=b'A young woman stands in front of some shrubs .' PREDICTIONS: match=0.59715563, no-match=0.40284434 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2496399593_a24954a5ca.jpg\n",
      "ITM=b'Six kids splash in water' PREDICTIONS: match=0.17665744, no-match=0.8233426 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2330536645_2d36b516e1.jpg\n",
      "ITM=b'Four people in a kitchen' PREDICTIONS: match=0.06485089, no-match=0.9351491 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2367317953_503317493e.jpg\n",
      "ITM=b'Two dogs play with a green ball on a wooden deck .' PREDICTIONS: match=0.65208155, no-match=0.3479184 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/275401000_8829250eb3.jpg\n",
      "ITM=b'Inside a bar there are people with red shirts .' PREDICTIONS: match=0.11744452, no-match=0.8825555 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2635483351_bc1a8273aa.jpg\n",
      "ITM=b'A skateboarder wearing an orange shirt and orange helmet .' PREDICTIONS: match=0.11529601, no-match=0.88470393 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2680619645_ab6645218d.jpg\n",
      "ITM=b'A person skis down a snowy and tree-filled hill .' PREDICTIONS: match=0.6706981, no-match=0.3293019 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2432038587_5e4148e277.jpg\n",
      "ITM=b'Two children riding a blue rollercoaster smile .' PREDICTIONS: match=0.158026, no-match=0.841974 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2836703077_fa9c736203.jpg\n",
      "ITM=b'A black dog running in a race .' PREDICTIONS: match=0.6715415, no-match=0.3284585 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2330536645_2d36b516e1.jpg\n",
      "ITM=b'The girl with brown hair swam in the water .' PREDICTIONS: match=0.2461097, no-match=0.7538903 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2256218522_53b92bcbb2.jpg\n",
      "ITM=b'A man maneuvers a motorcycle through a rocky stream .' PREDICTIONS: match=0.3632498, no-match=0.63675016 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2280354512_c0d035d53f.jpg\n",
      "ITM=b'A man with a beard and sunglasses is standing in front of tree-covered hills .' PREDICTIONS: match=0.7057181, no-match=0.2942819 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/265528702_8653eab9fa.jpg\n",
      "ITM=b'A person in a red hat with a huge backpack going hiking .' PREDICTIONS: match=0.6548901, no-match=0.34510988 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2129430111_338a94f8fb.jpg\n",
      "ITM=b'A man laying on the ground with a wet spot on his pants and a white and red hat .' PREDICTIONS: match=0.3223757, no-match=0.6776243 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2855727603_e917ded363.jpg\n",
      "ITM=b'A dog s head is in the lap of a person eating off a small plate .' PREDICTIONS: match=0.4404848, no-match=0.55951524 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2591486448_48d5438343.jpg\n",
      "ITM=b'A young couple holding drinks and smiling .' PREDICTIONS: match=0.12380978, no-match=0.8761902 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2909955251_4b326a46a7.jpg\n",
      "ITM=b'A greyhound is active in a grassy field .' PREDICTIONS: match=0.7979511, no-match=0.20204885 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2965604928_435dc93bf7.jpg\n",
      "ITM=b'a little boy spilled his milk from the green cup .' PREDICTIONS: match=0.13149934, no-match=0.86850065 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2804851816_9aae9071ca.jpg\n",
      "ITM=b'A man throwing a red stick for a dog to fetch .' PREDICTIONS: match=0.7413088, no-match=0.25869122 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2789688929_9424fceed1.jpg\n",
      "ITM=b'Two little girls sitting on the edge of a street eating corn on the cob .' PREDICTIONS: match=0.58031344, no-match=0.41968662 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2828583747_8cfb7217af.jpg\n",
      "ITM=b'A man and a woman are laid back relaxing on the couch .' PREDICTIONS: match=0.23393998, no-match=0.76606 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2902269566_419d9f1d8e.jpg\n",
      "ITM=b'Parade of men on horses with brightly colored flags .' PREDICTIONS: match=0.60204124, no-match=0.39795876 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2917057791_3d68a055ca.jpg\n",
      "ITM=b'A dog walks through a field .' PREDICTIONS: match=0.75452894, no-match=0.24547106 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/304408047_98bab3ea64.jpg\n",
      "ITM=b'A little girl runs down a summer street with no shoes and a lunchbox .' PREDICTIONS: match=0.4712939, no-match=0.5287061 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2599903773_0f724d8f63.jpg\n",
      "ITM=b'Doberman leaping through the water .' PREDICTIONS: match=0.53372335, no-match=0.46627668 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2637959357_dd64a03efa.jpg\n",
      "ITM=b'A female lionist jumping in a green field with a green mountain in the background .' PREDICTIONS: match=0.6235375, no-match=0.3764625 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2987328689_96a2d814f1.jpg\n",
      "ITM=b'Two girls , one running away from the wall .' PREDICTIONS: match=0.27576804, no-match=0.72423196 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2965604928_435dc93bf7.jpg\n",
      "ITM=b'A black and white dog with a blue collar walks through the grass .' PREDICTIONS: match=0.8028025, no-match=0.1971975 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3091338773_9cf10467b4.jpg\n",
      "ITM=b'A close-up shot of a long haired man playing a red electric guitar .' PREDICTIONS: match=0.38843134, no-match=0.6115686 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3128164023_ebe8da4c32.jpg\n",
      "ITM=b'A man with an orange hat in a yellow canoe paddles along a river in a wooded , mountainous area .' PREDICTIONS: match=0.47212845, no-match=0.5278716 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2909955251_4b326a46a7.jpg\n",
      "ITM=b'An athletic girl in an orange uniform is on a playing field of green grass and swinging at a ball .' PREDICTIONS: match=0.24188885, no-match=0.7581112 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3021318991_fa28e3bca7.jpg\n",
      "ITM=b'A man admires a rock formation on the water .' PREDICTIONS: match=0.57294303, no-match=0.42705694 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3091338773_9cf10467b4.jpg\n",
      "ITM=b'A man stands on a street corner with a small child looking at a sign .' PREDICTIONS: match=0.4763439, no-match=0.52365613 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3203453897_6317aac6ff.jpg\n",
      "ITM=b'Two women with a baby stroller in a fancy restaurant .' PREDICTIONS: match=0.3087372, no-match=0.6912628 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3069282021_e05e1829f3.jpg\n",
      "ITM=b'A dog jumps of a Frisbee with a woman looking on .' PREDICTIONS: match=0.57581973, no-match=0.42418027 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3236677456_75821e3583.jpg\n",
      "ITM=b'A woman is sitting on a man s lap on a public transportation system .' PREDICTIONS: match=0.15066233, no-match=0.84933764 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3074617663_2f2634081d.jpg\n",
      "ITM=b'A girl wearing a white coat standing in a fountain .' PREDICTIONS: match=0.3164729, no-match=0.6835271 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2842032768_9d9ce04385.jpg\n",
      "ITM=b'A person is skijoring with a dog in the mountains .' PREDICTIONS: match=0.8436324, no-match=0.15636764 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3259883609_6a1b46919e.jpg\n",
      "ITM=b'A black and white dog walking over a blue dog ramp' PREDICTIONS: match=0.7990619, no-match=0.2009381 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3259222980_04fb62df97.jpg\n",
      "ITM=b'The two dogs are standing with their heads entwined around each other .' PREDICTIONS: match=0.6432034, no-match=0.35679665 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3259222980_04fb62df97.jpg\n",
      "ITM=b'Two men sit together beside stone steps in an urban setting .' PREDICTIONS: match=0.46100748, no-match=0.5389925 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2650568697_ffb79bf2ea.jpg\n",
      "ITM=b'Two dogs running in the woods .' PREDICTIONS: match=0.73718745, no-match=0.26281258 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2998504949_1022fec53b.jpg\n",
      "ITM=b'Some people in building as seen from the street at night .' PREDICTIONS: match=0.5646092, no-match=0.43539083 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3215081286_d55541aa6b.jpg\n",
      "ITM=b'A dog wearing a muzzle is racing around a corner .' PREDICTIONS: match=0.77261317, no-match=0.22738682 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3201594926_cd2009eb13.jpg\n",
      "ITM=b'man getting thrown in the air while bull riding' PREDICTIONS: match=0.63706094, no-match=0.36293903 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3254662117_b2e7dede6e.jpg\n",
      "ITM=b'A little girl blows bubbles in a courtyard with a ship in the background .' PREDICTIONS: match=0.12279724, no-match=0.8772028 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3339747039_1a8455c210.jpg\n",
      "ITM=b'Two white dogs play on the green grass .' PREDICTIONS: match=0.6693341, no-match=0.33066586 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3242354561_54e5a34925.jpg\n",
      "ITM=b'Two men wearing black' PREDICTIONS: match=0.29700232, no-match=0.7029976 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3246190363_68d903bfcb.jpg\n",
      "ITM=b'A boy in a green shirt is riding his skateboard in a park while three boys watch .' PREDICTIONS: match=0.3051006, no-match=0.6948994 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3274879561_74997bbfff.jpg\n",
      "ITM=b'The lady is holding a purple ribbon .' PREDICTIONS: match=0.3739329, no-match=0.6260671 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3362871440_6c0f27c480.jpg\n",
      "ITM=b'A dog above snow .' PREDICTIONS: match=0.7447762, no-match=0.25522375 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3188319076_71724fcc07.jpg\n",
      "ITM=b'A group of young children sit on the edge of a cement ledge .' PREDICTIONS: match=0.38456964, no-match=0.6154304 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3264397357_72f084cac1.jpg\n",
      "ITM=b'People sitting in a well-lit restaurant .' PREDICTIONS: match=0.09039324, no-match=0.90960675 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3366571152_20afb88ac1.jpg\n",
      "ITM=b'A boy wearing red crocs climbing a tree .' PREDICTIONS: match=0.7976623, no-match=0.20233767 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3215081286_d55541aa6b.jpg\n",
      "ITM=b'A woman wearing a white shirt and red pants is writing something down at a museum .' PREDICTIONS: match=0.1356471, no-match=0.8643529 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3192311620_99bda27fbd.jpg\n",
      "ITM=b'The man is sitting outside on the street under a purple umbrella .' PREDICTIONS: match=0.69888264, no-match=0.3011174 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/2685139184_4ff45e0f76.jpg\n",
      "ITM=b'A child plays on playground equipment .' PREDICTIONS: match=0.18754965, no-match=0.8124503 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3354075558_3b67eaa502.jpg\n",
      "ITM=b'A dog with a stick in its mouth runs through the rocks in shallow water .' PREDICTIONS: match=0.79387116, no-match=0.20612885 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3382105769_b1a4e4c60d.jpg\n",
      "ITM=b'Two dogs are wrestling in the park .' PREDICTIONS: match=0.62223625, no-match=0.37776378 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3242354561_54e5a34925.jpg\n",
      "ITM=b'Dog on its back rolling around in the grass .' PREDICTIONS: match=0.7769513, no-match=0.22304866 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3393394134_0caac47e1c.jpg\n",
      "ITM=b'A girl stands in a dimly lit area .' PREDICTIONS: match=0.116714545, no-match=0.88328546 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3415589320_71a5bf64cf.jpg\n",
      "ITM=b'Two men are sitting on a rock near the ocean with another man standing nearby .' PREDICTIONS: match=0.5185857, no-match=0.48141426 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3399312265_9c74378692.jpg\n",
      "ITM=b'A runner is sliding into home while the cathcer covers the plate in a softball game .' PREDICTIONS: match=0.32532462, no-match=0.67467535 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3482974845_db4f16befa.jpg\n",
      "ITM=b'Two children are playing at a water park .' PREDICTIONS: match=0.28000167, no-match=0.71999836 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3502563726_30d1ce29c8.jpg\n",
      "ITM=b'A woman in an orange-hooded outfit is sitting with her hand on her face .' PREDICTIONS: match=0.12575075, no-match=0.8742493 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3487979741_5f244c0c4b.jpg\n",
      "ITM=b'Two dogs playing with a stick in the water .' PREDICTIONS: match=0.55781126, no-match=0.44218868 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3476237185_9389c536a3.jpg\n",
      "ITM=b'A Doberman Pinscher at night' PREDICTIONS: match=0.6776545, no-match=0.3223455 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3385246141_a263d1053e.jpg\n",
      "ITM=b'A black dog and a brown dog touching noses in a grassy field .' PREDICTIONS: match=0.8168751, no-match=0.18312488 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3188044631_ca3a9cc737.jpg\n",
      "ITM=b'A small child is jumping on a bed .' PREDICTIONS: match=0.24930988, no-match=0.75069016 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3512033861_a357bb58b6.jpg\n",
      "ITM=b'A man smiles outdoors .' PREDICTIONS: match=0.5579679, no-match=0.44203207 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3512033861_a357bb58b6.jpg\n",
      "ITM=b'A toddler with a look of fear on his face is on playground equipment .' PREDICTIONS: match=0.14274871, no-match=0.85725135 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3420064875_0349a75d69.jpg\n",
      "ITM=b'The boy is wearing a blue shirt , and the girl is wearing black clothes .' PREDICTIONS: match=0.3185579, no-match=0.6814421 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3493255026_5fdaa52cbe.jpg\n",
      "ITM=b'A dog is jumping over a hurdle .' PREDICTIONS: match=0.72913307, no-match=0.27086696 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3474999131_788cbf253f.jpg\n",
      "ITM=b'A brown and white dog is playing with a toy in a field of green grass and clover .' PREDICTIONS: match=0.7754223, no-match=0.22457771 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3301822808_f2ccff86f4.jpg\n",
      "ITM=b'An elderly man is sitting on a bench .' PREDICTIONS: match=0.16381489, no-match=0.8361851 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3437315443_ba2263f92e.jpg\n",
      "ITM=b'In a fenced yard with a white house in the background , a white dog jumps in the air beside a brown dog .' PREDICTIONS: match=0.69053143, no-match=0.3094686 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3437693401_202afef348.jpg\n",
      "ITM=b'A run way model removes a tan coat to show off a fancy dress .' PREDICTIONS: match=0.47800285, no-match=0.52199715 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3437693401_202afef348.jpg\n",
      "ITM=b'A person on a bike is midair , twisting his body around the handlebars , with graffiti behind him .' PREDICTIONS: match=0.18790743, no-match=0.8120926 \t -> \t /home/rinzler/Github/Image-Text-Matching/data/images/3452982513_36f2bc81fa.jpg\n",
      "TEST accuracy=0.638243\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.6362 - binary_accuracy: 0.6382\n",
      "Tensorflow test method: Loss: 0.6362444758415222; ACCURACY: 0.6382429003715515\n"
     ]
    }
   ],
   "source": [
    "# Let's create an instance of the main class\n",
    "itm = ITM_Classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
