{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import einops\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from official.nlp import optimization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading image and text data\n",
    "\n",
    "class ITM_DataLoader:\n",
    "    BATCH_SIZE = 16\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    IMAGE_SHAPE = (224, 224, 3)\n",
    "    MAX_SENTENCE_LENGTH = 50\n",
    "    SENTENCE_EMBEDDING_SHAPE = 384\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    DATA_PATH = \"D:\\_GITHUB_\\Image-Text-Matching\\data\"\n",
    "    IMAGES_PATH = DATA_PATH + \"/images\"\n",
    "    train_data_file = DATA_PATH + \"/flickr8k.TrainImages.txt\"\n",
    "    dev_data_file = DATA_PATH + \"/flickr8k.DevImages.txt\"\n",
    "    test_data_file = DATA_PATH + \"/flickr8k.TestImages.txt\"\n",
    "    sentence_embeddings_file = DATA_PATH + \"/flickr8k.cmp9137.sentence_transformers.pkl\"\n",
    "    sentence_embeddings = {}\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    test_ds = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentence_embeddings = self.load_sentence_embeddings()\n",
    "        self.train_ds = self.load_classifier_data(self.train_data_file)\n",
    "        self.val_ds = self.load_classifier_data(self.dev_data_file)\n",
    "        self.test_ds = self.load_classifier_data(self.test_data_file)\n",
    "        print(\"done loading data...\")\n",
    "\n",
    "    # Sentence embeddings are dense vectors representing text data, one vector per sentence.\n",
    "    # Sentences with similar vectors would mean sentences with equivalent meanning.\n",
    "    # They are useful here to provide text-based features of questions in the data.\n",
    "    # Note: sentence embeddings don't include label info, they are solely based on captions.\n",
    "    def load_sentence_embeddings(self):\n",
    "        sentence_embeddings = {}\n",
    "        print(\"READING sentence embeddings...\")\n",
    "        with open(self.sentence_embeddings_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            for sentence, dense_vector in data.items():\n",
    "                # print(\"*sentence=\",sentence)\n",
    "                sentence_embeddings[sentence] = dense_vector\n",
    "        print(\"Done reading sentence_embeddings!\")\n",
    "        return sentence_embeddings\n",
    "\n",
    "    # In contrast to text-data based on pre-trained features, image data does not use\n",
    "    # any form of pre-training in this program. Instead, it makes use of raw pixels.\n",
    "    # Notes that input features to the classifier are only pixels and sentence embeddings.\n",
    "    def process_input(self, img_path, text_input_ids, text_attention_mask, label, caption):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.IMAGE_SIZE)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32) / 255.0\n",
    "        file_name = tf.strings.split(img_path, os.path.sep)[-1]\n",
    "        features = {\n",
    "            \"image_input\": img,\n",
    "            \"text_input_ids\": text_input_ids,\n",
    "            \"text_attention_mask\": text_attention_mask,\n",
    "            \"caption\": caption,\n",
    "            \"file_name\": file_name\n",
    "            }\n",
    "        return features, label\n",
    "\n",
    "    # This method loads the multimodal data, which comes from the following sources:\n",
    "    # (1) image files in IMAGES_PATH, and (2) files with pattern flickr8k.*Images.txt\n",
    "    # The data is stored in a tensorflow data structure to make it easy to use by\n",
    "    # the tensorflow model during training, validation and test. This method was\n",
    "    # carefully prepared to load the data rapidly, i.e., by loading already created\n",
    "    # sentence embeddings (text features) rather than creating them at runtime.\n",
    "    def load_classifier_data(self, data_files):\n",
    "        print(\"LOADING data from \" + str(data_files))\n",
    "        image_data = []\n",
    "        text_input_ids = []\n",
    "        text_attention_masks = []\n",
    "        label_data = []\n",
    "        captions = []\n",
    "\n",
    "        with open(data_files) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                img_name, text, raw_label = line.split(\"\\t\")\n",
    "                img_name = os.path.join(self.IMAGES_PATH, img_name.strip())\n",
    "                label = [1, 0] if raw_label == \"match\" else [0, 1]\n",
    "\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.SENTENCE_EMBEDDING_SHAPE,  # Ensure this attribute is defined\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"tf\",\n",
    "                )\n",
    "\n",
    "                image_data.append(img_name)\n",
    "                text_input_ids.append(encoding[\"input_ids\"][0])  # [0] to unpack from batch\n",
    "                text_attention_masks.append(encoding[\"attention_mask\"][0])  # [0] to unpack from batch\n",
    "                label_data.append(label)\n",
    "                captions.append(text)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_data, text_input_ids, text_attention_masks, label_data, captions))\n",
    "        dataset = dataset.map(self.process_input, num_parallel_calls=self.AUTOTUNE)\n",
    "        dataset = (dataset.shuffle(self.BATCH_SIZE * 8).batch(self.BATCH_SIZE).prefetch(self.AUTOTUNE))\n",
    "        return dataset\n",
    "\n",
    "    def print_data_samples(self, dataset):\n",
    "        print(\"PRINTING data samples...\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        for features_batch, label_batch in dataset.take(1):\n",
    "            for i in range(1):\n",
    "                print(f'Image pixels: {features_batch[\"image_input\"]}')\n",
    "                print(f'Caption: {features_batch[\"caption\"].numpy()}')\n",
    "                label = label_batch.numpy()[i]\n",
    "                print(f\"Label : {label}\")\n",
    "        print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class for the Image-Text Matching (ITM) task\n",
    "\n",
    "class ITM_Classifier(ITM_DataLoader):\n",
    "    epochs = 1\n",
    "    learning_rate = 4e-5\n",
    "    class_names = {\"match\", \"no-match\"}\n",
    "    num_classes = len(class_names)\n",
    "    classifier_model = None\n",
    "    history = None\n",
    "    classifier_model_name = \"ITM_Classifier-flickr\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_classifier_model()\n",
    "        self.train_classifier_model()\n",
    "        self.test_classifier_model()\n",
    "\n",
    "    # return learnt feature representations of input data (images)\n",
    "    def create_vision_encoder(\n",
    "        self, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        img_input = layers.Input(shape=self.IMAGE_SHAPE, name=\"image_input\")\n",
    "\n",
    "        # Use InceptionV3 with ImageNet weights, excluding the top (fully connected) layer\n",
    "        base_model = InceptionV3(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=img_input,\n",
    "            input_shape=self.IMAGE_SHAPE,\n",
    "        )\n",
    "        # Avoid training the base model to retain learned features\n",
    "        base_model.trainable = False\n",
    "\n",
    "        # Continue from where the base model leaves off\n",
    "        cnn_layer = base_model.output\n",
    "        cnn_layer = layers.GlobalAveragePooling2D()(\n",
    "            cnn_layer\n",
    "        )  # Added to reduce dimensions\n",
    "        cnn_layer = layers.Dropout(dropout_rate)(cnn_layer)\n",
    "\n",
    "        outputs = self.project_embeddings(\n",
    "            cnn_layer, num_projection_layers, projection_dims, dropout_rate\n",
    "        )\n",
    "        return img_input, outputs\n",
    "\n",
    "    # return learnt feature representations based on dense layers, dropout, and layer normalisation\n",
    "    def project_embeddings(\n",
    "        self, embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "        for _ in range(num_projection_layers):\n",
    "            x = tf.nn.gelu(projected_embeddings)\n",
    "            x = layers.Dense(projection_dims)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "            x = layers.Add()([projected_embeddings, x])\n",
    "            projected_embeddings = layers.LayerNormalization()(x)\n",
    "        return projected_embeddings\n",
    "\n",
    "    # return learnt feature representations of input data (text embeddings in the form of dense vectors)\n",
    "    def create_text_encoder(\n",
    "        self, num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "    ):\n",
    "        bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        bert_model.trainable = (\n",
    "            False  # Set to False to freeze BERT weights, or True to fine-tune\n",
    "        )\n",
    "\n",
    "        # Define the inputs for the BERT model\n",
    "        text_input_ids = tf.keras.Input(\n",
    "            shape=(self.SENTENCE_EMBEDDING_SHAPE,),\n",
    "            dtype=tf.int32,\n",
    "            name=\"text_input_ids\",\n",
    "        )\n",
    "        text_attention_mask = tf.keras.Input(\n",
    "            shape=(self.SENTENCE_EMBEDDING_SHAPE,),\n",
    "            dtype=tf.int32,\n",
    "            name=\"text_attention_mask\",\n",
    "        )\n",
    "\n",
    "        # Getting the output from BERT\n",
    "        bert_output = bert_model(text_input_ids, attention_mask=text_attention_mask)\n",
    "        text_features = bert_output.last_hidden_state\n",
    "        text_features = tf.keras.layers.GlobalAveragePooling1D()(text_features)\n",
    "\n",
    "        # Project the BERT outputs to the desired dimensionality\n",
    "        projected_embeddings = tf.keras.layers.Dense(\n",
    "            projection_dims, activation=\"relu\"\n",
    "        )(text_features)\n",
    "        for _ in range(\n",
    "            1, num_projection_layers\n",
    "        ):  # start from 1 because we already added one Dense layer\n",
    "            x = tf.keras.layers.Dense(projection_dims, activation=\"relu\")(\n",
    "                projected_embeddings\n",
    "            )\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "            projected_embeddings = tf.keras.layers.Add()(\n",
    "                [projected_embeddings, x]\n",
    "            )  # Element-wise addition\n",
    "            projected_embeddings = tf.keras.layers.LayerNormalization()(\n",
    "                projected_embeddings\n",
    "            )\n",
    "\n",
    "        return text_input_ids, text_attention_mask, projected_embeddings\n",
    "\n",
    "    # put together the feature representations above to create the image-text (multimodal) deep learning model\n",
    "    def build_classifier_model(self):\n",
    "        print(\"BUILDING model\")\n",
    "        # Create the vision model part\n",
    "        img_input, vision_net = self.create_vision_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "\n",
    "        # Create the text model part\n",
    "        text_input_ids, text_attention_mask, text_net = self.create_text_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "\n",
    "        # Combine the outputs from both text and vision parts\n",
    "        combined_features = tf.keras.layers.Concatenate(axis=1)([vision_net, text_net])\n",
    "        combined_features = tf.keras.layers.Dense(512, activation=\"relu\")(\n",
    "            combined_features\n",
    "        )\n",
    "        combined_features = tf.keras.layers.Dropout(0.1)(combined_features)\n",
    "        combined_features = tf.keras.layers.Dense(512, activation=\"relu\")(\n",
    "            combined_features\n",
    "        )\n",
    "        combined_features = tf.keras.layers.LayerNormalization()(combined_features)\n",
    "\n",
    "        # Classifier layer\n",
    "        final_output = tf.keras.layers.Dense(\n",
    "            self.num_classes, activation=\"softmax\", name=self.classifier_model_name\n",
    "        )(combined_features)\n",
    "\n",
    "        # Create the full model\n",
    "        self.classifier_model = tf.keras.Model(\n",
    "            inputs=[img_input, text_input_ids, text_attention_mask],\n",
    "            outputs=final_output,\n",
    "        )\n",
    "        self.classifier_model.summary()\n",
    "\n",
    "    def train_classifier_model(self):\n",
    "        print(f\"TRAINING model\")\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        num_warmup_steps = int(0.2 * num_train_steps)\n",
    "\n",
    "        loss = tf.keras.losses.KLDivergence()\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=self.learning_rate,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type=\"adamw\",\n",
    "        )\n",
    "\n",
    "        self.classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # uncomment the next line if you wish to make use of early stopping during training\n",
    "        # callbacks = [tf.keras.callbacks.EarlyStopping(patience=11, restore_best_weights=True)]\n",
    "\n",
    "        self.history = self.classifier_model.fit(\n",
    "            x=self.train_ds, validation_data=self.val_ds, epochs=self.epochs\n",
    "        )  # , callbacks=callbacks)\n",
    "        print(\"model trained!\")\n",
    "\n",
    "    def test_classifier_model(self):\n",
    "        print(\n",
    "            \"TESTING classifier model (showing a sample of image-text-matching predictions)...\"\n",
    "        )\n",
    "        num_classifications = 0\n",
    "        num_correct_predictions = 0\n",
    "\n",
    "        # read test data for ITM classification\n",
    "        for features, groundtruth in self.test_ds:\n",
    "            groundtruth = groundtruth.numpy()\n",
    "            predictions = self.classifier_model(features)\n",
    "            predictions = predictions.numpy()\n",
    "            captions = features[\"caption\"].numpy()\n",
    "            file_names = features[\"file_name\"].numpy()\n",
    "\n",
    "            # read test data per batch\n",
    "            for batch_index in range(0, len(groundtruth)):\n",
    "                predicted_values = predictions[batch_index]\n",
    "                probability_match = predicted_values[0]\n",
    "                probability_nomatch = predicted_values[1]\n",
    "                predicted_class = (\n",
    "                    \"[1 0]\" if probability_match > probability_nomatch else \"[0 1]\"\n",
    "                )\n",
    "                if str(groundtruth[batch_index]) == predicted_class:\n",
    "                    num_correct_predictions += 1\n",
    "                num_classifications += 1\n",
    "\n",
    "                # print a sample of predictions -- about 10% of all possible\n",
    "                if random.random() < 0.1:\n",
    "                    caption = captions[batch_index]\n",
    "                    file_name = file_names[batch_index].decode(\"utf-8\")\n",
    "                    print(\n",
    "                        \"ITM=%s PREDICTIONS: match=%s, no-match=%s \\t -> \\t %s\"\n",
    "                        % (caption, probability_match, probability_nomatch, file_name)\n",
    "                    )\n",
    "\n",
    "        # reveal test performance using our own calculations above\n",
    "        accuracy = num_correct_predictions / num_classifications\n",
    "        print(\"TEST accuracy=%4f\" % (accuracy))\n",
    "\n",
    "        # reveal test performance using Tensorflow calculations\n",
    "        loss, accuracy = self.classifier_model.evaluate(self.test_ds)\n",
    "        print(f\"Tensorflow test method: Loss: {loss}; ACCURACY: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Let's create an instance of the main class\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING sentence embeddings...\n",
      "Done reading sentence_embeddings!\n",
      "LOADING data from D:\\_GITHUB_\\Image-Text-Matching\\data/flickr8k.TrainImages.txt\n",
      "LOADING data from D:\\_GITHUB_\\Image-Text-Matching\\data/flickr8k.DevImages.txt\n",
      "LOADING data from D:\\_GITHUB_\\Image-Text-Matching\\data/flickr8k.TestImages.txt\n",
      "done loading data...\n",
      "BUILDING model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 111, 111, 32  864         ['image_input[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " tf.nn.gelu (TFOpLambda)        (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['tf.nn.gelu[0][0]']             \n",
      "                                                                                                  \n",
      " text_input_ids (InputLayer)    [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " text_attention_mask (InputLaye  [(None, 384)]       0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['text_input_ids[0][0]',         \n",
      "                                thPoolingAndCrossAt               'text_attention_mask[0][0]']    \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 384,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128)          0           ['dense[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128)         256         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          98432       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['layer_normalization[0][0]',    \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          131584      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 512)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          262656      ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 512)         1024        ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " ITM_Classifier-flickr (Dense)  (None, 2)            1026        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 132,058,786\n",
      "Trainable params: 773,762\n",
      "Non-trainable params: 131,285,024\n",
      "__________________________________________________________________________________________________\n",
      "TRAINING model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\functional.py:637: UserWarning: Input dict contained keys ['caption', 'file_name'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212/1212 [==============================] - 861s 694ms/step - loss: 0.7223 - binary_accuracy: 0.5555 - val_loss: 0.6566 - val_binary_accuracy: 0.6194\n",
      "model trained!\n",
      "TESTING classifier model (showing a sample of image-text-matching predictions)...\n",
      "ITM=b'Brown dog trying to bite a white ball with yellow , green and blue puppy toes' PREDICTIONS: match=0.7090225, no-match=0.29097745 \t -> \t 1510078253_96e9ec50e7.jpg\n",
      "ITM=b'The woman wearing the pink jacket has thrown a Frisbee for the dog to catch .' PREDICTIONS: match=0.4677226, no-match=0.5322774 \t -> \t 1240297429_c36ae0c58f.jpg\n",
      "ITM=b'A white and tan dog leaps through the air .' PREDICTIONS: match=0.6716198, no-match=0.32838026 \t -> \t 1240297429_c36ae0c58f.jpg\n",
      "ITM=b'People are walking through a snow covered field with a mountain the background .' PREDICTIONS: match=0.5886695, no-match=0.4113305 \t -> \t 1655781989_b15ab4cbff.jpg\n",
      "ITM=b'A grey dog walks in the green grass , tongue hanging out .' PREDICTIONS: match=0.7369533, no-match=0.26304665 \t -> \t 1659358141_0433c9bf99.jpg\n",
      "ITM=b'Lady in a stuffed animal store .' PREDICTIONS: match=0.39200294, no-match=0.60799706 \t -> \t 1674612291_7154c5ab61.jpg\n",
      "ITM=b'A crowd of people in colorful dresses .' PREDICTIONS: match=0.25505456, no-match=0.7449454 \t -> \t 1510078253_96e9ec50e7.jpg\n",
      "ITM=b'Some people on a pier at night with one girl fishing off it .' PREDICTIONS: match=0.35031465, no-match=0.6496854 \t -> \t 1089755335_0bfbfd30e6.jpg\n",
      "ITM=b'A large black and tan dog is coming out of the water .' PREDICTIONS: match=0.5926965, no-match=0.4073035 \t -> \t 148512773_bae6901fd6.jpg\n",
      "ITM=b'A wet dog walks out of the water .' PREDICTIONS: match=0.66922307, no-match=0.33077693 \t -> \t 123997871_6a9ca987b1.jpg\n",
      "ITM=b'A man in a red shirt climbs a rock while another man stands behind to help him .' PREDICTIONS: match=0.39025888, no-match=0.60974115 \t -> \t 103205630_682ca7285b.jpg\n",
      "ITM=b'A black dog is running in snow .' PREDICTIONS: match=0.54263926, no-match=0.4573607 \t -> \t 1897025969_0c41688fa6.jpg\n",
      "ITM=b'A skier looks at framed pictures in the snow next to trees .' PREDICTIONS: match=0.44873187, no-match=0.5512681 \t -> \t 101669240_b2d3e7f17b.jpg\n",
      "ITM=b'The black dog is jumping over the white pole in the grass .' PREDICTIONS: match=0.705939, no-match=0.294061 \t -> \t 2040941056_7f5fd50794.jpg\n",
      "ITM=b'Dog with big collar running .' PREDICTIONS: match=0.7871684, no-match=0.2128316 \t -> \t 1552065993_b4dcd2eadf.jpg\n",
      "ITM=b'A brown dog biting a gray dogs ear .' PREDICTIONS: match=0.6688272, no-match=0.33117288 \t -> \t 2058124718_89822bc96e.jpg\n",
      "ITM=b'A fat dog sitting in a boat' PREDICTIONS: match=0.46878108, no-match=0.5312189 \t -> \t 1965278563_8279e408de.jpg\n",
      "ITM=b'A little girl in bright yellow with a group of kids .' PREDICTIONS: match=0.3257839, no-match=0.6742161 \t -> \t 2110898123_07729c1461.jpg\n",
      "ITM=b'A girl playing with a dog near a police car .' PREDICTIONS: match=0.5706514, no-match=0.42934856 \t -> \t 166507476_9be5b9852a.jpg\n",
      "ITM=b'A brown and a black and brown dog are playing in the water and the black one is carrying a long stick in its mouth .' PREDICTIONS: match=0.70478016, no-match=0.29521984 \t -> \t 1130017585_1a219257ac.jpg\n",
      "ITM=b'four kids playfully pose in unusual architectural structure' PREDICTIONS: match=0.6495856, no-match=0.35041437 \t -> \t 1357689954_72588dfdc4.jpg\n",
      "ITM=b'A woman in a pink bikini is laying on a deck lounge chair that is covered with a pink towel .' PREDICTIONS: match=0.28248957, no-match=0.7175104 \t -> \t 1124448967_2221af8dc5.jpg\n",
      "ITM=b'People jump over a mountain crevasse on a rope .' PREDICTIONS: match=0.5853274, no-match=0.41467255 \t -> \t 1130017585_1a219257ac.jpg\n",
      "ITM=b'christmas tree lights hang on the ceiling .' PREDICTIONS: match=0.43336195, no-match=0.56663805 \t -> \t 2097398349_ff178b3f1b.jpg\n",
      "ITM=b'A woman rides a bike on a trail through a field .' PREDICTIONS: match=0.57076335, no-match=0.42923662 \t -> \t 209605542_ca9cc52e7b.jpg\n",
      "ITM=b'A young girl is diving into a pile of brown leaves in the yard .' PREDICTIONS: match=0.56958485, no-match=0.43041515 \t -> \t 2260649048_ae45d17e68.jpg\n",
      "ITM=b'A person throwing a yellow ball in the air .' PREDICTIONS: match=0.41756698, no-match=0.58243304 \t -> \t 224273695_0b517bd0eb.jpg\n",
      "ITM=b'A baby in a bouncy seat and a standing boy surrounded by toys .' PREDICTIONS: match=0.55493796, no-match=0.445062 \t -> \t 1387785218_cee67735f5.jpg\n",
      "ITM=b'A woman in orange sunglasses jogs .' PREDICTIONS: match=0.53805393, no-match=0.46194607 \t -> \t 2214132302_80064fd79d.jpg\n",
      "ITM=b'A little girl in a red dress and cape holds a large tennis racquet .' PREDICTIONS: match=0.29842004, no-match=0.70158 \t -> \t 1965278563_8279e408de.jpg\n",
      "ITM=b'A couple ride bikes next to an orange fence by the ocean .' PREDICTIONS: match=0.4133566, no-match=0.5866434 \t -> \t 2346629210_8d6668d22d.jpg\n",
      "ITM=b'Two dogs , one large and one small , are playing together in the grass .' PREDICTIONS: match=0.76021373, no-match=0.2397863 \t -> \t 2260649048_ae45d17e68.jpg\n",
      "ITM=b'A man runs on a field with the ball and a man in a striped shirt is on the ground .' PREDICTIONS: match=0.45619562, no-match=0.5438044 \t -> \t 2206960564_325ed0c7ae.jpg\n",
      "ITM=b'A man hikes on a dirt path high above a city .' PREDICTIONS: match=0.49128777, no-match=0.50871223 \t -> \t 2089539651_9e518ec7de.jpg\n",
      "ITM=b'A person standing on a frozen lake .' PREDICTIONS: match=0.45058802, no-match=0.549412 \t -> \t 102351840_323e3de834.jpg\n",
      "ITM=b'A woman in a bikini is running on rocks in a stream .' PREDICTIONS: match=0.38175505, no-match=0.61824495 \t -> \t 1924234308_c9ddcf206d.jpg\n",
      "ITM=b'A girl sits on the beach under a bright pink sunshade .' PREDICTIONS: match=0.20352538, no-match=0.79647464 \t -> \t 1552065993_b4dcd2eadf.jpg\n",
      "ITM=b'A dog jumps of a surfboard' PREDICTIONS: match=0.53023225, no-match=0.46976772 \t -> \t 2445783904_e6c38a3a3d.jpg\n",
      "ITM=b'A girls wearing jeans and a pink shirt runs .' PREDICTIONS: match=0.29128233, no-match=0.7087177 \t -> \t 241109594_3cb90fe2a3.jpg\n",
      "ITM=b'Girl walking along the tops of wooden posts set into sand on a beach .' PREDICTIONS: match=0.58005834, no-match=0.41994166 \t -> \t 2360194369_d2fd03b337.jpg\n",
      "ITM=b'Two dogs wade in the water .' PREDICTIONS: match=0.53085846, no-match=0.46914154 \t -> \t 2220175999_081aa9cce8.jpg\n",
      "ITM=b'People sit a tables while a man speaks with a microphone .' PREDICTIONS: match=0.21216956, no-match=0.7878304 \t -> \t 2534502836_7a75305655.jpg\n",
      "ITM=b'A group of people pose for a picture .' PREDICTIONS: match=0.26406506, no-match=0.735935 \t -> \t 2333584535_1eaf9baf3e.jpg\n",
      "ITM=b'A dog races through the woods .' PREDICTIONS: match=0.7032909, no-match=0.29670912 \t -> \t 1056338697_4f7d7ce270.jpg\n",
      "ITM=b'Basketball player holding the ball .' PREDICTIONS: match=0.33445624, no-match=0.66554374 \t -> \t 2555535057_007501dae5.jpg\n",
      "ITM=b'A person flies backward off a blue raft near rapids .' PREDICTIONS: match=0.4894095, no-match=0.5105905 \t -> \t 2092870249_90e3f1855b.jpg\n",
      "ITM=b'A young , blonde girl picking flowers in a grassy field .' PREDICTIONS: match=0.3199351, no-match=0.6800649 \t -> \t 2405978603_6221b0c2e7.jpg\n",
      "ITM=b'Two dogs running in the surf .' PREDICTIONS: match=0.51394534, no-match=0.48605466 \t -> \t 2564888404_b57f89d3c7.jpg\n",
      "ITM=b'A dog jumps to catch a ball in a large field .' PREDICTIONS: match=0.50849175, no-match=0.49150825 \t -> \t 2543247940_083f1b7969.jpg\n",
      "ITM=b'Man pulling a cart in the street .' PREDICTIONS: match=0.5882674, no-match=0.41173267 \t -> \t 2199250692_a16b0c2ae1.jpg\n",
      "ITM=b'The two-tone dog is running down the trail .' PREDICTIONS: match=0.56589735, no-match=0.43410265 \t -> \t 2496399593_a24954a5ca.jpg\n",
      "ITM=b'Kids jumping with one boy in midair .' PREDICTIONS: match=0.4404743, no-match=0.5595257 \t -> \t 2439031566_2e0c0d3550.jpg\n",
      "ITM=b'girl hanging upside down on blue monkey bars' PREDICTIONS: match=0.2771144, no-match=0.72288567 \t -> \t 2582390123_71120edb0c.jpg\n",
      "ITM=b'Three young people pose by a snowman in a red tie .' PREDICTIONS: match=0.26517498, no-match=0.734825 \t -> \t 2442243868_abe8f74fb4.jpg\n",
      "ITM=b'The black dog in front of the tree has a green toy in its mouth .' PREDICTIONS: match=0.6467143, no-match=0.3532856 \t -> \t 251792066_b5233b3d86.jpg\n",
      "ITM=b'A playful dog running across the snowy field with a stick in its mouth .' PREDICTIONS: match=0.6537482, no-match=0.3462518 \t -> \t 2622971954_59f192922d.jpg\n",
      "ITM=b'Two dogs are playing with a tennis ball in snow near a tree .' PREDICTIONS: match=0.6884311, no-match=0.3115689 \t -> \t 2522230304_1581d52961.jpg\n",
      "ITM=b'A man in a crowd raises his arms pleadingly .' PREDICTIONS: match=0.3864144, no-match=0.6135856 \t -> \t 2622971954_59f192922d.jpg\n",
      "ITM=b'A man crouching down on some rocks in the ocean .' PREDICTIONS: match=0.406364, no-match=0.593636 \t -> \t 2559114800_17310f3015.jpg\n",
      "ITM=b'A man with a beard and sunglasses is standing in front of tree-covered hills .' PREDICTIONS: match=0.44750175, no-match=0.5524983 \t -> \t 265528702_8653eab9fa.jpg\n",
      "ITM=b'A man on a motorcycle steers through swampy terrain' PREDICTIONS: match=0.5642332, no-match=0.43576682 \t -> \t 2808098783_c56b44befa.jpg\n",
      "ITM=b'Two dogs play with a green ball on a wooden deck .' PREDICTIONS: match=0.64849067, no-match=0.3515093 \t -> \t 275401000_8829250eb3.jpg\n",
      "ITM=b'The boy has orange paint on him .' PREDICTIONS: match=0.48152858, no-match=0.5184714 \t -> \t 2548777800_d7b9cf1c2b.jpg\n",
      "ITM=b'Two racing dogs run in the mud .' PREDICTIONS: match=0.64084, no-match=0.35916007 \t -> \t 2839789830_89668775a4.jpg\n",
      "ITM=b'Bike rider doing a high jump over hilly track , water in background .' PREDICTIONS: match=0.36686438, no-match=0.6331356 \t -> \t 2738077433_10e6264b6f.jpg\n",
      "ITM=b'A little girl is riding on the front of a shopping cart in a store .' PREDICTIONS: match=0.71206725, no-match=0.28793272 \t -> \t 2369452202_8b0e8e25ca.jpg\n",
      "ITM=b'A dog runs along a forest lane .' PREDICTIONS: match=0.7602731, no-match=0.23972689 \t -> \t 2818735880_68b3dfe1f5.jpg\n",
      "ITM=b'A woman hugging a man at a formal occassion .' PREDICTIONS: match=0.2688585, no-match=0.7311415 \t -> \t 2405978603_6221b0c2e7.jpg\n",
      "ITM=b'A small grey dog is in the grass with a brown cow .' PREDICTIONS: match=0.8234498, no-match=0.17655018 \t -> \t 2582390123_71120edb0c.jpg\n",
      "ITM=b'A white dog with a collar and leash is about to chew on a stick .' PREDICTIONS: match=0.58586997, no-match=0.41413006 \t -> \t 2543247940_083f1b7969.jpg\n",
      "ITM=b'A man throwing a red stick for a dog to fetch .' PREDICTIONS: match=0.53184825, no-match=0.46815175 \t -> \t 2789688929_9424fceed1.jpg\n",
      "ITM=b'A boy tosses a rock across a river .' PREDICTIONS: match=0.64841574, no-match=0.35158426 \t -> \t 2987328689_96a2d814f1.jpg\n",
      "ITM=b'a woman enjoying her reading at a coffee shop' PREDICTIONS: match=0.27749062, no-match=0.7225094 \t -> \t 3070031806_3d587c2a66.jpg\n",
      "ITM=b'Two boys eating apples playing on a cement car barrier' PREDICTIONS: match=0.49361366, no-match=0.5063863 \t -> \t 2525716531_e6dedee421.jpg\n",
      "ITM=b'Boy in red shirt getting ready to hit the pinata .' PREDICTIONS: match=0.45884973, no-match=0.54115033 \t -> \t 2599444370_9e40103027.jpg\n",
      "ITM=b'A person in a blue jacket follows two donkeys along a mountain trail .' PREDICTIONS: match=0.6978385, no-match=0.3021615 \t -> \t 2892467862_52a3c67418.jpg\n",
      "ITM=b'Two dogs run through the brush .' PREDICTIONS: match=0.6365485, no-match=0.36345145 \t -> \t 300274198_eefd8e057e.jpg\n",
      "ITM=b'A boy walks across a rope structure on a playground .' PREDICTIONS: match=0.442128, no-match=0.55787206 \t -> \t 2604825598_593a825b5b.jpg\n",
      "ITM=b'A bearded man wears a roughly sewn hooded costume emblazoned with images of Spiderman .' PREDICTIONS: match=0.40435445, no-match=0.5956455 \t -> \t 3051998298_38da5746fa.jpg\n",
      "ITM=b'three people walking on rocks near a stream' PREDICTIONS: match=0.46911782, no-match=0.5308822 \t -> \t 3156113206_53c2a7b5d8.jpg\n",
      "ITM=b'a couple stadning with their children getting baptized by a priest .' PREDICTIONS: match=0.34937492, no-match=0.65062505 \t -> \t 3161044966_27bf6f9dec.jpg\n",
      "ITM=b'A woman in black is throwing a stick for a brown dog to run after .' PREDICTIONS: match=0.39581063, no-match=0.60418934 \t -> \t 3110614694_fecc23ca65.jpg\n",
      "ITM=b'A rock climber hangs from a ledge while others look on .' PREDICTIONS: match=0.34533787, no-match=0.65466213 \t -> \t 3175446111_681a89f873.jpg\n",
      "ITM=b'Four young Asian women are posing in front of a window' PREDICTIONS: match=0.22537023, no-match=0.7746297 \t -> \t 2944362789_aebbc22db4.jpg\n",
      "ITM=b'A girl in a pink jacket is going headfirst down a red slide .' PREDICTIONS: match=0.40102956, no-match=0.5989704 \t -> \t 2471447879_6554cefb16.jpg\n",
      "ITM=b'Surfer wearing a wetsuit at the crest of a wave .' PREDICTIONS: match=0.347876, no-match=0.6521239 \t -> \t 3143982558_9e2d44c155.jpg\n",
      "ITM=b'A man is jumping a rock on an orange dirt bike .' PREDICTIONS: match=0.44074318, no-match=0.5592568 \t -> \t 2992808092_5f677085b7.jpg\n",
      "ITM=b'a little girl is sitting at a table with a jug of juice and some watermelon slices .' PREDICTIONS: match=0.39243677, no-match=0.60756326 \t -> \t 3085357792_efcf297c71.jpg\n",
      "ITM=b'A man wearing a life jacket and helmet is water rafting down a river .' PREDICTIONS: match=0.5306493, no-match=0.46935076 \t -> \t 3099091086_f75f0ce09d.jpg\n",
      "ITM=b'a man dressed in a batman costume .' PREDICTIONS: match=0.17871073, no-match=0.82128924 \t -> \t 3223973114_6c15538ce9.jpg\n",
      "ITM=b'A man wearing white walks passed a shuttered building with an advertising banner over the door .' PREDICTIONS: match=0.25561798, no-match=0.744382 \t -> \t 3074617663_2f2634081d.jpg\n",
      "ITM=b'The dog on the beach has gotten a hold of something .' PREDICTIONS: match=0.6173514, no-match=0.38264862 \t -> \t 3286620180_4b00e93e8e.jpg\n",
      "ITM=b'A small black and white dog carries a stick while swimming .' PREDICTIONS: match=0.72084224, no-match=0.27915773 \t -> \t 3257277774_aba333a94c.jpg\n",
      "ITM=b'A young boy dressed as a pirate and running .' PREDICTIONS: match=0.37620598, no-match=0.623794 \t -> \t 3304556387_203b9d4db0.jpg\n",
      "ITM=b'Some people in building as seen from the street at night .' PREDICTIONS: match=0.3456991, no-match=0.65430087 \t -> \t 3215081286_d55541aa6b.jpg\n",
      "ITM=b'A man wearing black boxing shorts and white boxing gloves and a man in white boxing shorts and white boxing gloves are fighting in the ring .' PREDICTIONS: match=0.486092, no-match=0.513908 \t -> \t 3295418287_5d590dac43.jpg\n",
      "ITM=b'A black and white dog walking over a blue dog ramp' PREDICTIONS: match=0.57600534, no-match=0.42399463 \t -> \t 3259222980_04fb62df97.jpg\n",
      "ITM=b'A kid doing a trick on his skateboard .' PREDICTIONS: match=0.35344392, no-match=0.6465561 \t -> \t 3382105769_b1a4e4c60d.jpg\n",
      "ITM=b'A girl leaps through the air while running on the riverbank .' PREDICTIONS: match=0.39115468, no-match=0.60884535 \t -> \t 3106857210_07a92577fc.jpg\n",
      "ITM=b'A woman is using Frisbees to play with a dog in front of a stadium crowd and a group of baseball players .' PREDICTIONS: match=0.2375081, no-match=0.7624919 \t -> \t 3110614694_fecc23ca65.jpg\n",
      "ITM=b'A brown dog is jumping over a tree limb in a wooded area .' PREDICTIONS: match=0.6968553, no-match=0.3031447 \t -> \t 317109978_cb557802e1.jpg\n",
      "ITM=b'A paraskier is landing on a mountain .' PREDICTIONS: match=0.7364451, no-match=0.26355484 \t -> \t 3402081035_a54cfab1d9.jpg\n",
      "ITM=b'A dog runs on a snowy field .' PREDICTIONS: match=0.7065516, no-match=0.29344842 \t -> \t 3407317539_68765a3375.jpg\n",
      "ITM=b'A person paints Asian characters on a banner .' PREDICTIONS: match=0.26811987, no-match=0.7318801 \t -> \t 3209966887_5b744bd050.jpg\n",
      "ITM=b'Two dogs are playing in a grassy area .' PREDICTIONS: match=0.61282784, no-match=0.38717213 \t -> \t 3415589320_71a5bf64cf.jpg\n",
      "ITM=b'A snowboarder performs a jump in the snow .' PREDICTIONS: match=0.30808386, no-match=0.69191617 \t -> \t 3070485870_eab1a75c6f.jpg\n",
      "ITM=b'A man holding money , standing in front of a street band and a store .' PREDICTIONS: match=0.41080815, no-match=0.58919185 \t -> \t 3439982121_0afc6d5973.jpg\n",
      "ITM=b'Five people wear name tags on a necklace and pose together .' PREDICTIONS: match=0.15261199, no-match=0.84738797 \t -> \t 3362049454_ea0c22e57b.jpg\n",
      "ITM=b'A woman sits and reads on the front stoop of her building .' PREDICTIONS: match=0.50959873, no-match=0.49040127 \t -> \t 3195701071_81879257f5.jpg\n",
      "ITM=b'A dog and cat laying down together .' PREDICTIONS: match=0.5999787, no-match=0.4000213 \t -> \t 351876121_c7c0221928.jpg\n",
      "ITM=b'A dog with golden fur is chest deep in water .' PREDICTIONS: match=0.8096073, no-match=0.1903927 \t -> \t 343073813_df822aceac.jpg\n",
      "ITM=b'A man and woman blow bubbles .' PREDICTIONS: match=0.25672567, no-match=0.74327433 \t -> \t 3203878596_cbb307ce3b.jpg\n",
      "ITM=b'The hiker pokes out of her tent to find that snow is everywhere .' PREDICTIONS: match=0.6007369, no-match=0.39926308 \t -> \t 3349451628_4249a21c8f.jpg\n",
      "ITM=b'A dog jumps over a red and white gate .' PREDICTIONS: match=0.68009126, no-match=0.31990877 \t -> \t 3455920874_6fbec43194.jpg\n",
      "ITM=b'A snowboarder performs a trick on a ledge , with pristine snowscapes surrounding him .' PREDICTIONS: match=0.5010484, no-match=0.49895164 \t -> \t 3335692531_dd4a995f91.jpg\n",
      "ITM=b'Dogs playing in the snow' PREDICTIONS: match=0.70193154, no-match=0.29806846 \t -> \t 3289433994_4c67aab384.jpg\n",
      "ITM=b'A woman sitting down checking her cellphone .' PREDICTIONS: match=0.28345805, no-match=0.71654195 \t -> \t 345684566_235e8dfcc1.jpg\n",
      "ITM=b'Dogs chase each other .' PREDICTIONS: match=0.677275, no-match=0.32272503 \t -> \t 3303648823_53cf750acd.jpg\n",
      "ITM=b'A black dog runs through the water carrying a stick .' PREDICTIONS: match=0.6681472, no-match=0.33185285 \t -> \t 3495453699_1c9faedf3c.jpg\n",
      "ITM=b'Three dogs run through the grass while wearing colored shirts .' PREDICTIONS: match=0.5325579, no-match=0.46744207 \t -> \t 3436395540_63bc8f2fe0.jpg\n",
      "ITM=b'A pair of children in uniforms running through a flock of pigeons .' PREDICTIONS: match=0.4308134, no-match=0.56918657 \t -> \t 3487261028_30791528ec.jpg\n",
      "ITM=b'Two people are riding on a ski lift' PREDICTIONS: match=0.52822256, no-match=0.4717775 \t -> \t 342872408_04a2832a1b.jpg\n",
      "ITM=b'Two men , one of which is bald , in a bathroom .' PREDICTIONS: match=0.24183144, no-match=0.75816864 \t -> \t 3357708906_fb3a54dd78.jpg\n",
      "TEST accuracy=0.631352\n",
      "55/73 [=====================>........] - ETA: 10s - loss: 0.6512 - binary_accuracy: 0.6318"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m itm \u001b[38;5;241m=\u001b[39m \u001b[43mITM_Classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mITM_Classifier.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_classifier_model()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_classifier_model()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_classifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 207\u001b[0m, in \u001b[0;36mITM_Classifier.test_classifier_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST accuracy=\u001b[39m\u001b[38;5;132;01m%4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# reveal test performance using Tensorflow calculations\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow test method: Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; ACCURACY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "itm = ITM_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history.history['binary_accuracy']\n",
    "    val_acc = history.history['val_binary_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(itm.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
