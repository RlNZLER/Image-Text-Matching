{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import einops\n",
    "import pickle\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from official.nlp import optimization\n",
    "import matplotlib.pyplot as plt\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-1 # 1e-2, 1e-3, 1e-4, 3e-5, 1e-5, 1e-6\n",
    "EPOCHS = 5\n",
    "G_BATCH_SIZE = 8\n",
    "OPTIMIZER_TYPE = 'adamw' # Common optimizers include Adam, SGD, RMSprop,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = 0\n",
    "Loss = 0\n",
    "Validation_accuracy = 0\n",
    "Validation_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n",
      "Using GPU: GPU /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Verify TensorFlow can detect the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if len(gpus) > 0:\n",
    "    print(f\"Using GPU: {gpus[0].device_type} {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dict_to_csv(row_dict, csv_file_name):\n",
    "    # Open the file in append mode (or create it if it doesn't exist)\n",
    "    with open(csv_file_name, mode='a', newline='', encoding='utf-8') as csv_file:\n",
    "        # Create a writer object\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=row_dict.keys())\n",
    "        \n",
    "        # Write the data row\n",
    "        writer.writerow(row_dict)\n",
    "\n",
    "\n",
    "def insert_image_in_pdf(image_path, pdf_canvas, x, y, width=224, height=224):\n",
    "    \"\"\"Insert an image into the PDF canvas.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image by 50%\n",
    "    new_width = int(width * 0.5)\n",
    "    new_height = int(height * 0.5)\n",
    "    img = img.resize((new_width, new_height))\n",
    "    \n",
    "    # Convert PIL Image to a data stream compatible with reportlab\n",
    "    img_buffer = io.BytesIO()\n",
    "    img.save(img_buffer, format='PNG')\n",
    "    img_buffer.seek(0)\n",
    "    \n",
    "    pdf_canvas.drawImage(ImageReader(img_buffer), x, y, new_width, new_height)\n",
    "\n",
    "\n",
    "def generate_pdf_from_csv(csv_file_name, output_file_name):\n",
    "    c = canvas.Canvas(output_file_name, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Define table headers\n",
    "    headers = [\"S/N\", \"Image\", \"Caption\", \"Match\", \"Un-match\"]\n",
    "    \n",
    "    # Starting positions\n",
    "    x = 50\n",
    "    y = height - 50  # Start from the top of the page\n",
    "    row_height = 150  # Adjusted for image height\n",
    "    col_widths = [30, 180, 180, 80, 80]  # Adjust the column widths as needed\n",
    "    \n",
    "    # Draw Table Header\n",
    "    for idx, header in enumerate(headers):\n",
    "        c.drawString(x + sum(col_widths[:idx]), y, header)\n",
    "    \n",
    "    y -= row_height\n",
    "    \n",
    "    # Read data from CSV and fill in the table rows\n",
    "    with open(csv_file_name, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for sn, row in enumerate(reader, start=1):\n",
    "            c.drawString(x, y + (row_height - 12) / 2, str(sn))\n",
    "            \n",
    "            # Insert image\n",
    "            insert_image_in_pdf(row[\"Image\"], c, x + col_widths[0], y)\n",
    "            \n",
    "            # Text columns\n",
    "            # Remove the \"b'\" characters from the start of the caption\n",
    "            caption = row[\"Caption\"].lstrip(\"b'\")\n",
    "\n",
    "            # Split caption into multiple lines if it's too long\n",
    "            caption_lines = [caption[i:i+25] for i in range(0, len(caption), 25)]\n",
    "            for idx, line in enumerate(caption_lines):\n",
    "                c.drawString(x + sum(col_widths[:2]), y + (row_height - 12) / 2 - (idx * 12 * 0.8), line)\n",
    "            \n",
    "            c.drawString(x + sum(col_widths[:3]), y + (row_height - 12) / 2, row[\"Match\"])\n",
    "            c.drawString(x + sum(col_widths[:4]), y + (row_height - 12) / 2, row[\"Un-match\"])\n",
    "            \n",
    "            y -= row_height\n",
    "            if y < 100:  # Check for page end\n",
    "                c.showPage()  # Start a new page\n",
    "                y = height - 50  # Reset y position\n",
    "                # Re-draw Table Header on new page\n",
    "                for idx, header in enumerate(headers):\n",
    "                    c.drawString(x + sum(col_widths[:idx]), y, header)\n",
    "                y -= row_height\n",
    "    \n",
    "    c.save()\n",
    "    subprocess.Popen(['xdg-open', output_file_name])\n",
    "    \n",
    "    \n",
    "def plot_training_history(history):\n",
    "    acc = history.history['binary_accuracy']\n",
    "    val_acc = history.history['val_binary_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading image and text data\n",
    "\n",
    "class ITM_DataLoader():\n",
    "    BATCH_SIZE = G_BATCH_SIZE\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    IMAGE_SHAPE = (224, 224, 3)\n",
    "    SENTENCE_EMBEDDING_SHAPE = (384)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    IMAGES_PATH = \"data/images\"\n",
    "    IMAGES_PATH = \"/home/rinzler/Github/Image-Text-Matching/data/images\"\n",
    "    train_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.TrainImages.txt\"\n",
    "    dev_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.DevImages.txt\"\n",
    "    test_data_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.TestImages.txt\"\n",
    "    sentence_embeddings_file = \"/home/rinzler/Github/Image-Text-Matching/data/flickr8k.cmp9137.sentence_transformers.pkl\"\n",
    "    sentence_embeddings = {}\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    test_ds = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentence_embeddings = self.load_sentence_embeddings()\n",
    "        self.train_ds = self.load_classifier_data(self.train_data_file)\n",
    "        self.val_ds = self.load_classifier_data(self.dev_data_file)\n",
    "        self.test_ds = self.load_classifier_data(self.test_data_file)\n",
    "        print(\"done loading data...\")\n",
    "\n",
    "    # Sentence embeddings are dense vectors representing text data, one vector per sentence. \n",
    "    # Sentences with similar vectors would mean sentences with equivalent meanning.  \n",
    "\t# They are useful here to provide text-based features of questions in the data.\n",
    "    # Note: sentence embeddings don't include label info, they are solely based on captions.\n",
    "    def load_sentence_embeddings(self):\n",
    "        sentence_embeddings = {}\n",
    "        print(\"READING sentence embeddings...\")\n",
    "        with open(self.sentence_embeddings_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            for sentence, dense_vector in data.items():\n",
    "                sentence_embeddings[sentence] = dense_vector\n",
    "                #print(\"*sentence=\",sentence)\n",
    "        print(\"Done reading sentence_embeddings!\")\n",
    "        return sentence_embeddings\n",
    "\n",
    "    # In contrast to text-data based on pre-trained features, image data does not use\n",
    "    # any form of pre-training in this program. Instead, it makes use of raw pixels.\n",
    "    # Notes that input features to the classifier are only pixels and sentence embeddings.\n",
    "    def process_input(self, img_path, dense_vector, text, label):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.IMAGE_SIZE)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.cast(img, tf.float32) / 255\n",
    "        features = {}\n",
    "        features[\"image_input\"] = img\n",
    "        features[\"text_embedding\"] = dense_vector\n",
    "        features[\"caption\"] = text\n",
    "        features[\"file_name\"] = img_path\n",
    "        return features, label\n",
    "\n",
    "    # This method loads the multimodal data, which comes from the following sources:\n",
    "    # (1) image files in IMAGES_PATH, and (2) files with pattern flickr8k.*Images.txt\n",
    "    # The data is stored in a tensorflow data structure to make it easy to use by\n",
    "    # the tensorflow model during training, validation and test. This method was \n",
    "    # carefully prepared to load the data rapidly, i.e., by loading already created\n",
    "    # sentence embeddings (text features) rather than creating them at runtime.\n",
    "    def load_classifier_data(self, data_files):\n",
    "        print(\"LOADING data from \"+str(data_files))\n",
    "        print(\"=========================================\")\n",
    "        image_data = []\n",
    "        text_data = []\n",
    "        embeddings_data = []\n",
    "        label_data = []\n",
    "\t\t\n",
    "        # get image, text, label of image_files\n",
    "        with open(data_files) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                img_name, text, raw_label = line.split(\"\t\")\n",
    "                img_name = os.path.join(self.IMAGES_PATH, img_name.strip())\n",
    "\n",
    "                # get binary labels from match/no-match answers\n",
    "                label = [1, 0] if raw_label == \"match\" else [0, 1]\n",
    "                #print(\"I=%s T=%s _L=%s L=%s\" % (img_name, text, raw_label, label)) \n",
    "\n",
    "\t\t\t\t# get sentence embeddings (of textual captions)\n",
    "                text_sentence_embedding = self.sentence_embeddings[text]\n",
    "                text_sentence_embedding = tf.constant(text_sentence_embedding)\n",
    "\n",
    "                image_data.append(img_name)\n",
    "                embeddings_data.append(text_sentence_embedding)\n",
    "                text_data.append(text)\n",
    "                label_data.append(label)\n",
    "\n",
    "        print(\"|image_data|=\"+str(len(image_data)))\n",
    "        print(\"|text_data|=\"+str(len(text_data)))\n",
    "        print(\"|label_data|=\"+str(len(label_data)))\n",
    "\t\t\n",
    "        # prepare a tensorflow dataset using the lists generated above\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_data, embeddings_data, text_data, label_data))\n",
    "        dataset = dataset.shuffle(self.BATCH_SIZE * 8)\n",
    "        dataset = dataset.map(self.process_input, num_parallel_calls=self.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.BATCH_SIZE).prefetch(self.AUTOTUNE)\n",
    "        self.print_data_samples(dataset)\n",
    "        return dataset\n",
    "\n",
    "    def print_data_samples(self, dataset):\n",
    "        print(\"PRINTING data samples...\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        for features_batch, label_batch in dataset.take(1):\n",
    "            for i in range(1):\n",
    "                print(f'Image pixels: {features_batch[\"image_input\"]}')\n",
    "                print(f'Sentence embeddings: {features_batch[\"text_embedding\"]}')\n",
    "                print(f'Caption: {features_batch[\"caption\"].numpy()}')\n",
    "                label = label_batch.numpy()[i]\n",
    "                print(f'Label : {label}')\n",
    "        print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class for the Image-Text Matching (ITM) task\n",
    "\n",
    "class ITM_Classifier(ITM_DataLoader):\n",
    "    epochs = EPOCHS\n",
    "    learning_rate = Learning_Rate\n",
    "    class_names = {'match', 'no-match'}\n",
    "    num_classes = len(class_names)\n",
    "    classifier_model = None\n",
    "    history = None\n",
    "    classifier_model_name = 'ITM_Classifier-flickr'\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_classifier_model()\n",
    "        self.train_classifier_model()\n",
    "        self.test_classifier_model()\n",
    "\n",
    "    # return learnt feature representations of input data (images)\n",
    "    def create_vision_encoder(self, num_projection_layers, projection_dims, dropout_rate):\n",
    "        img_input = layers.Input(shape=self.IMAGE_SHAPE, name=\"image_input\")\n",
    "        cnn_layer = layers.Conv2D(16, 3, padding='same', activation='relu')(img_input)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(32, 3, padding='same', activation='relu')(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(64, 3, padding='same', activation='relu')(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Dropout(dropout_rate)(cnn_layer)\n",
    "        cnn_layer = layers.Flatten()(cnn_layer)\n",
    "        outputs = self.project_embeddings(cnn_layer, num_projection_layers, projection_dims, dropout_rate)\n",
    "        return img_input, outputs\n",
    "\n",
    "    # return learnt feature representations based on dense layers, dropout, and layer normalisation\n",
    "    def project_embeddings(self, embeddings, num_projection_layers, projection_dims, dropout_rate):\n",
    "        projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "        for _ in range(num_projection_layers):\n",
    "            x = tf.nn.gelu(projected_embeddings)\n",
    "            x = layers.Dense(projection_dims)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "            x = layers.Add()([projected_embeddings, x])\n",
    "            projected_embeddings = layers.LayerNormalization()(x)\n",
    "        return projected_embeddings\n",
    "\n",
    "    # return learnt feature representations of input data (text embeddings in the form of dense vectors)\n",
    "    def create_text_encoder(self, num_projection_layers, projection_dims, dropout_rate):\n",
    "        text_input = keras.Input(shape=self.SENTENCE_EMBEDDING_SHAPE, name='text_embedding')\n",
    "        outputs = self.project_embeddings(text_input, num_projection_layers, projection_dims, dropout_rate)\n",
    "        return text_input, outputs\n",
    "\n",
    "    # put together the feature representations above to create the image-text (multimodal) deep learning model\n",
    "    def build_classifier_model(self):\n",
    "        print(f'BUILDING model')\n",
    "        img_input, vision_net = self.create_vision_encoder(num_projection_layers=1, projection_dims=128, dropout_rate=0.1)\n",
    "        text_input, text_net = self.create_text_encoder(num_projection_layers=1, projection_dims=128, dropout_rate=0.1)\n",
    "        net = tf.keras.layers.Concatenate(axis=1)([vision_net, text_net])\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(self.num_classes, activation='softmax', name=self.classifier_model_name)(net)\n",
    "        self.classifier_model = tf.keras.Model(inputs=[img_input, text_input], outputs=net)\n",
    "        self.classifier_model.summary()\n",
    "\t\n",
    "    def train_classifier_model(self):\n",
    "        global Accuracy, Loss\n",
    "        \n",
    "        print(f'TRAINING model')\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        num_warmup_steps = int(0.2*num_train_steps)\n",
    "\n",
    "        loss = tf.keras.losses.KLDivergence()\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "        optimizer = optimization.create_optimizer(init_lr=self.learning_rate,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type=OPTIMIZER_TYPE)\n",
    "\n",
    "        self.classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # uncomment the next line if you wish to make use of early stopping during training\n",
    "        #callbacks = [tf.keras.callbacks.EarlyStopping(patience=11, restore_best_weights=True)]\n",
    "\n",
    "        self.history = self.classifier_model.fit(x=self.train_ds, validation_data=self.val_ds, epochs=self.epochs)#, callbacks=callbacks)\n",
    "        \n",
    "        # Update global variables with final training metrics\n",
    "        Accuracy = self.history.history['binary_accuracy'][-1]\n",
    "        Loss = self.history.history['loss'][-1]\n",
    "        \n",
    "        print(\"model trained!\")\n",
    "\n",
    "    def test_classifier_model(self):\n",
    "        global Validation_accuracy, Validation_loss\n",
    "        \n",
    "        print(\"TESTING classifier model (showing a sample of image-text-matching predictions)...\")\n",
    "        num_classifications = 0\n",
    "        num_correct_predictions = 0\n",
    "        \n",
    "        fieldnames = [\"Image\", \"Caption\", \"Match\", \"Un-match\"]\n",
    "        filename = \"output/Test_sample.csv\"\n",
    "\n",
    "        # Delete the existing file if it exists\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "        # with open(filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        #     writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        #     writer.writeheader()\n",
    "\n",
    "        # read test data for ITM classification\n",
    "        for features, groundtruth in self.test_ds:\n",
    "            groundtruth = groundtruth.numpy()\n",
    "            predictions = self.classifier_model(features)\n",
    "            predictions = predictions.numpy()\n",
    "            captions = features[\"caption\"].numpy()\n",
    "            file_names = features[\"file_name\"].numpy()\n",
    "\n",
    "            # read test data per batch\n",
    "            for batch_index in range(0, len(groundtruth)):\n",
    "                predicted_values = predictions[batch_index]\n",
    "                probability_match = predicted_values[0]\n",
    "                probability_nomatch = predicted_values[1]\n",
    "                predicted_class = \"[1 0]\" if probability_match > probability_nomatch else \"[0 1]\"\n",
    "                if str(groundtruth[batch_index]) == predicted_class: \n",
    "                    num_correct_predictions += 1\n",
    "                num_classifications += 1\n",
    "\n",
    "                # print a sample of predictions -- about 10% of all possible\n",
    "                if random.random() < 0.1:\n",
    "                    caption = captions[batch_index]\n",
    "                    file_name = file_names[batch_index].decode(\"utf-8\")\n",
    "                    print(\"ITM=%s PREDICTIONS: match=%s, no-match=%s \\t -> \\t %s\" % (caption, probability_match, probability_nomatch, file_name))\n",
    "                    # data = {\n",
    "                    #             \"file_name\": file_name,\n",
    "                    #             \"caption\": caption,\n",
    "                    #             \"match\": probability_match,\n",
    "                    #             \"unmatch\": probability_nomatch\n",
    "                    #         }\n",
    "                    # append_dict_to_csv(data, \"output/Test_sample.csv\")\n",
    "                    \n",
    "        # reveal test performance using our own calculations above\n",
    "        accuracy = num_correct_predictions/num_classifications\n",
    "        print(\"TEST accuracy=%4f\" % (accuracy))\n",
    "\n",
    "        # reveal test performance using Tensorflow calculations\n",
    "        loss, accuracy = self.classifier_model.evaluate(self.test_ds)\n",
    "        Validation_loss = loss\n",
    "        Validation_accuracy = accuracy\n",
    "        print(f'Tensorflow test method: Loss: {loss}; ACCURACY: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING sentence embeddings...\n",
      "Done reading sentence_embeddings!\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.TrainImages.txt\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:00:11.326553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.328122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.328920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.482780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.483281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.483701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-18 19:00:11.483963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|image_data|=19386\n",
      "|text_data|=19386\n",
      "|label_data|=19386\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.9490196  0.94509804 0.8745098 ]\n",
      "   [0.9529412  0.9490196  0.8784314 ]\n",
      "   [0.9607843  0.95686275 0.8862745 ]\n",
      "   ...\n",
      "   [0.972549   0.94509804 0.83137256]\n",
      "   [0.9647059  0.94509804 0.83137256]\n",
      "   [0.9607843  0.9411765  0.827451  ]]\n",
      "\n",
      "  [[0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   ...\n",
      "   [0.9647059  0.99215686 0.92156863]\n",
      "   [0.9607843  0.9882353  0.91764706]\n",
      "   [0.9607843  0.9882353  0.91764706]]\n",
      "\n",
      "  [[1.         1.         0.98039216]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   ...\n",
      "   [0.6431373  0.7647059  0.7764706 ]\n",
      "   [0.6392157  0.7607843  0.77254903]\n",
      "   [0.627451   0.7607843  0.76862746]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5647059  0.5372549  0.5058824 ]\n",
      "   [0.5882353  0.56078434 0.5294118 ]\n",
      "   [0.59607846 0.5686275  0.5372549 ]\n",
      "   ...\n",
      "   [0.72156864 0.70980394 0.68235296]\n",
      "   [0.6784314  0.6784314  0.6392157 ]\n",
      "   [0.7294118  0.7294118  0.6901961 ]]\n",
      "\n",
      "  [[0.5921569  0.5647059  0.53333336]\n",
      "   [0.6039216  0.5764706  0.54509807]\n",
      "   [0.6117647  0.58431375 0.5529412 ]\n",
      "   ...\n",
      "   [0.7019608  0.6901961  0.6627451 ]\n",
      "   [0.7137255  0.7137255  0.68235296]\n",
      "   [0.69411767 0.69411767 0.6627451 ]]\n",
      "\n",
      "  [[0.59607846 0.5686275  0.5372549 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   ...\n",
      "   [0.67058825 0.65882355 0.6313726 ]\n",
      "   [0.7372549  0.7372549  0.7058824 ]\n",
      "   [0.68235296 0.68235296 0.6509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.972549   0.98039216 0.9764706 ]\n",
      "   [0.9764706  0.9843137  0.98039216]\n",
      "   [0.9764706  0.9843137  0.98039216]\n",
      "   ...\n",
      "   [0.8039216  0.8980392  0.9372549 ]\n",
      "   [0.79607844 0.8901961  0.92941177]\n",
      "   [0.7921569  0.8862745  0.9254902 ]]\n",
      "\n",
      "  [[0.9764706  0.9843137  0.98039216]\n",
      "   [0.98039216 0.9882353  0.9843137 ]\n",
      "   [0.98039216 0.9882353  0.9843137 ]\n",
      "   ...\n",
      "   [0.8156863  0.9019608  0.94509804]\n",
      "   [0.8117647  0.8980392  0.9411765 ]\n",
      "   [0.8039216  0.8980392  0.9372549 ]]\n",
      "\n",
      "  [[0.98039216 0.9882353  0.9843137 ]\n",
      "   [0.9843137  0.99215686 0.9882353 ]\n",
      "   [0.9843137  0.99215686 0.9882353 ]\n",
      "   ...\n",
      "   [0.8352941  0.9137255  0.9490196 ]\n",
      "   [0.83137256 0.9098039  0.94509804]\n",
      "   [0.81960785 0.9098039  0.9411765 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.13333334 0.14901961 0.19607843]\n",
      "   [0.13725491 0.15294118 0.2       ]\n",
      "   [0.14509805 0.16078432 0.20784314]\n",
      "   ...\n",
      "   [0.07058824 0.12156863 0.14509805]\n",
      "   [0.09803922 0.15686275 0.18431373]\n",
      "   [0.10980392 0.16862746 0.19607843]]\n",
      "\n",
      "  [[0.12941177 0.14509805 0.1882353 ]\n",
      "   [0.13725491 0.15294118 0.19607843]\n",
      "   [0.14509805 0.16078432 0.20392157]\n",
      "   ...\n",
      "   [0.12941177 0.18431373 0.21960784]\n",
      "   [0.11764706 0.1764706  0.20392157]\n",
      "   [0.10980392 0.16862746 0.19607843]]\n",
      "\n",
      "  [[0.13333334 0.14901961 0.18431373]\n",
      "   [0.1254902  0.14117648 0.1764706 ]\n",
      "   [0.12941177 0.14509805 0.1882353 ]\n",
      "   ...\n",
      "   [0.14901961 0.20392157 0.24705882]\n",
      "   [0.12941177 0.18431373 0.21960784]\n",
      "   [0.1254902  0.18431373 0.21176471]]]\n",
      "\n",
      "\n",
      " [[[0.         0.00392157 0.        ]\n",
      "   [0.01176471 0.01568628 0.        ]\n",
      "   [0.00784314 0.01176471 0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3647059  0.4117647  0.09019608]\n",
      "   [0.3764706  0.42745098 0.10588235]\n",
      "   [0.2627451  0.3372549  0.01568628]\n",
      "   ...\n",
      "   [0.31764707 0.41960785 0.03921569]\n",
      "   [0.34901962 0.43529412 0.05098039]\n",
      "   [0.34901962 0.43529412 0.05098039]]\n",
      "\n",
      "  [[0.2509804  0.32156864 0.        ]\n",
      "   [0.24705882 0.32156864 0.00392157]\n",
      "   [0.19607843 0.2901961  0.        ]\n",
      "   ...\n",
      "   [0.3529412  0.45882353 0.05490196]\n",
      "   [0.3882353  0.4745098  0.09019608]\n",
      "   [0.3372549  0.41568628 0.04313726]]\n",
      "\n",
      "  [[0.21960784 0.30588236 0.        ]\n",
      "   [0.1764706  0.26666668 0.        ]\n",
      "   [0.1764706  0.28235295 0.        ]\n",
      "   ...\n",
      "   [0.34117648 0.45490196 0.03921569]\n",
      "   [0.35686275 0.43529412 0.05490196]\n",
      "   [0.3254902  0.39215687 0.03137255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.09019608 0.09019608 0.04313726]\n",
      "   [0.10196079 0.10196079 0.05490196]\n",
      "   [0.10980392 0.11372549 0.05882353]\n",
      "   ...\n",
      "   [0.34509805 0.38431373 0.41960785]\n",
      "   [0.34901962 0.3882353  0.42352942]\n",
      "   [0.34901962 0.3882353  0.42352942]]\n",
      "\n",
      "  [[0.09803922 0.09019608 0.04313726]\n",
      "   [0.10588235 0.10980392 0.05490196]\n",
      "   [0.1254902  0.11764706 0.06666667]\n",
      "   ...\n",
      "   [0.3137255  0.34901962 0.3764706 ]\n",
      "   [0.32156864 0.35686275 0.39215687]\n",
      "   [0.3254902  0.36078432 0.3882353 ]]\n",
      "\n",
      "  [[0.09019608 0.07450981 0.02745098]\n",
      "   [0.10196079 0.09411765 0.03529412]\n",
      "   [0.1254902  0.11372549 0.05490196]\n",
      "   ...\n",
      "   [0.27058825 0.29803923 0.32156864]\n",
      "   [0.2784314  0.30588236 0.3372549 ]\n",
      "   [0.28235295 0.30980393 0.33333334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39215687 0.2784314  0.14509805]\n",
      "   [0.36862746 0.25490198 0.12156863]\n",
      "   [0.3882353  0.27450982 0.14117648]\n",
      "   ...\n",
      "   [0.3764706  0.30980393 0.2       ]\n",
      "   [0.35686275 0.29803923 0.18431373]\n",
      "   [0.33333334 0.2784314  0.16470589]]\n",
      "\n",
      "  [[0.36862746 0.25490198 0.12156863]\n",
      "   [0.36078432 0.24705882 0.11372549]\n",
      "   [0.3764706  0.27450982 0.14509805]\n",
      "   ...\n",
      "   [0.34901962 0.2784314  0.18431373]\n",
      "   [0.35686275 0.2784314  0.18039216]\n",
      "   [0.34117648 0.2627451  0.16470589]]\n",
      "\n",
      "  [[0.3372549  0.22352941 0.09019608]\n",
      "   [0.3372549  0.22352941 0.09019608]\n",
      "   [0.32941177 0.22745098 0.09803922]\n",
      "   ...\n",
      "   [0.33333334 0.2509804  0.16862746]\n",
      "   [0.39215687 0.30588236 0.21568628]\n",
      "   [0.34901962 0.25490198 0.16078432]]]\n",
      "\n",
      "\n",
      " [[[0.9490196  0.94509804 0.8745098 ]\n",
      "   [0.9529412  0.9490196  0.8784314 ]\n",
      "   [0.9607843  0.95686275 0.8862745 ]\n",
      "   ...\n",
      "   [0.972549   0.94509804 0.83137256]\n",
      "   [0.9647059  0.94509804 0.83137256]\n",
      "   [0.9607843  0.9411765  0.827451  ]]\n",
      "\n",
      "  [[0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   [0.99607843 0.9882353  0.9372549 ]\n",
      "   ...\n",
      "   [0.9647059  0.99215686 0.92156863]\n",
      "   [0.9607843  0.9882353  0.91764706]\n",
      "   [0.9607843  0.9882353  0.91764706]]\n",
      "\n",
      "  [[1.         1.         0.98039216]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   [0.99607843 0.99215686 0.972549  ]\n",
      "   ...\n",
      "   [0.6431373  0.7647059  0.7764706 ]\n",
      "   [0.6392157  0.7607843  0.77254903]\n",
      "   [0.627451   0.7607843  0.76862746]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5647059  0.5372549  0.5058824 ]\n",
      "   [0.5882353  0.56078434 0.5294118 ]\n",
      "   [0.59607846 0.5686275  0.5372549 ]\n",
      "   ...\n",
      "   [0.72156864 0.70980394 0.68235296]\n",
      "   [0.6784314  0.6784314  0.6392157 ]\n",
      "   [0.7294118  0.7294118  0.6901961 ]]\n",
      "\n",
      "  [[0.5921569  0.5647059  0.53333336]\n",
      "   [0.6039216  0.5764706  0.54509807]\n",
      "   [0.6117647  0.58431375 0.5529412 ]\n",
      "   ...\n",
      "   [0.7019608  0.6901961  0.6627451 ]\n",
      "   [0.7137255  0.7137255  0.68235296]\n",
      "   [0.69411767 0.69411767 0.6627451 ]]\n",
      "\n",
      "  [[0.59607846 0.5686275  0.5372549 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   [0.58431375 0.5568628  0.5254902 ]\n",
      "   ...\n",
      "   [0.67058825 0.65882355 0.6313726 ]\n",
      "   [0.7372549  0.7372549  0.7058824 ]\n",
      "   [0.68235296 0.68235296 0.6509804 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.00392157 0.        ]\n",
      "   [0.01176471 0.01568628 0.        ]\n",
      "   [0.00784314 0.01176471 0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3647059  0.4117647  0.09019608]\n",
      "   [0.3764706  0.42745098 0.10588235]\n",
      "   [0.2627451  0.3372549  0.01568628]\n",
      "   ...\n",
      "   [0.31764707 0.41960785 0.03921569]\n",
      "   [0.34901962 0.43529412 0.05098039]\n",
      "   [0.34901962 0.43529412 0.05098039]]\n",
      "\n",
      "  [[0.2509804  0.32156864 0.        ]\n",
      "   [0.24705882 0.32156864 0.00392157]\n",
      "   [0.19607843 0.2901961  0.        ]\n",
      "   ...\n",
      "   [0.3529412  0.45882353 0.05490196]\n",
      "   [0.3882353  0.4745098  0.09019608]\n",
      "   [0.3372549  0.41568628 0.04313726]]\n",
      "\n",
      "  [[0.21960784 0.30588236 0.        ]\n",
      "   [0.1764706  0.26666668 0.        ]\n",
      "   [0.1764706  0.28235295 0.        ]\n",
      "   ...\n",
      "   [0.34117648 0.45490196 0.03921569]\n",
      "   [0.35686275 0.43529412 0.05490196]\n",
      "   [0.3254902  0.39215687 0.03137255]]]]\n",
      "Sentence embeddings: [[-0.03627355  0.0153298   0.01183037 ...  0.02369594  0.02866171\n",
      "   0.0373988 ]\n",
      " [-0.02101246 -0.0366167   0.01827064 ... -0.00518686  0.06195755\n",
      "   0.00669024]\n",
      " [ 0.00985241  0.00949205 -0.02488936 ...  0.02873642  0.04211102\n",
      "   0.01230461]\n",
      " ...\n",
      " [ 0.06426259  0.05561872  0.01473222 ...  0.03493184  0.00440325\n",
      "   0.1322274 ]\n",
      " [-0.02136072  0.00136681  0.01090929 ...  0.03576885  0.00136346\n",
      "   0.00456475]\n",
      " [ 0.03992777  0.00893027 -0.02057084 ...  0.01751265  0.05899994\n",
      "   0.07427794]]\n",
      "Caption: [b'Two smiling boys with goggles on play in an inflatable swimming pool with water up to their waists .'\n",
      " b'a young woman wearing a purple hat with a pink feather in it'\n",
      " b'A black and white dog is running through the grass .'\n",
      " b'Large brown dog running away from the sprinkler in the grass .'\n",
      " b'A brown and white dog is running through the snow .'\n",
      " b'White dog with brown ears standing near water with head turned to one side .'\n",
      " b'A man lays on a bench while his dog sits by him .'\n",
      " b'A dog runs on the green grass near a wooden fence .']\n",
      "Label : [0 1]\n",
      "-----------------------------------------\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.DevImages.txt\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:00:18.147625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [19386,384]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-03-18 19:00:18.148116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [19386]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|image_data|=1164\n",
      "|text_data|=1164\n",
      "|label_data|=1164\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.53333336 0.7921569  0.99607843]\n",
      "   [0.5686275  0.827451   1.        ]\n",
      "   [0.50980395 0.77254903 0.98039216]\n",
      "   ...\n",
      "   [0.42745098 0.68235296 0.9490196 ]\n",
      "   [0.42352942 0.6784314  0.94509804]\n",
      "   [0.41568628 0.67058825 0.9372549 ]]\n",
      "\n",
      "  [[0.5254902  0.76862746 0.9607843 ]\n",
      "   [0.56078434 0.8039216  1.        ]\n",
      "   [0.5294118  0.7764706  0.9764706 ]\n",
      "   ...\n",
      "   [0.43137255 0.6862745  0.9529412 ]\n",
      "   [0.42745098 0.68235296 0.9490196 ]\n",
      "   [0.42352942 0.6784314  0.94509804]]\n",
      "\n",
      "  [[0.5764706  0.7882353  0.96862745]\n",
      "   [0.6039216  0.8156863  0.99607843]\n",
      "   [0.6039216  0.8235294  1.        ]\n",
      "   ...\n",
      "   [0.4392157  0.69411767 0.9607843 ]\n",
      "   [0.43529412 0.6901961  0.95686275]\n",
      "   [0.43137255 0.6862745  0.9529412 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39607844 0.3882353  0.22745098]\n",
      "   [0.40392157 0.39607844 0.23529412]\n",
      "   [0.39607844 0.3882353  0.22745098]\n",
      "   ...\n",
      "   [0.14509805 0.06666667 0.03921569]\n",
      "   [0.16470589 0.08627451 0.04313726]\n",
      "   [0.16862746 0.09411765 0.03921569]]\n",
      "\n",
      "  [[0.38431373 0.3764706  0.22352941]\n",
      "   [0.39215687 0.38431373 0.23137255]\n",
      "   [0.39607844 0.3882353  0.23529412]\n",
      "   ...\n",
      "   [0.22745098 0.1254902  0.05882353]\n",
      "   [0.17254902 0.08627451 0.03529412]\n",
      "   [0.16078432 0.09019608 0.04313726]]\n",
      "\n",
      "  [[0.40392157 0.39607844 0.24313726]\n",
      "   [0.4        0.39215687 0.23921569]\n",
      "   [0.39607844 0.3882353  0.23529412]\n",
      "   ...\n",
      "   [0.654902   0.54509807 0.45882353]\n",
      "   [0.52156866 0.43529412 0.38431373]\n",
      "   [0.26666668 0.19607843 0.15686275]]]\n",
      "\n",
      "\n",
      " [[[0.02352941 0.12941177 0.        ]\n",
      "   [0.01960784 0.13725491 0.00392157]\n",
      "   [0.06666667 0.18039216 0.0627451 ]\n",
      "   ...\n",
      "   [0.8666667  0.8980392  0.43137255]\n",
      "   [0.8784314  0.89411765 0.36078432]\n",
      "   [0.8745098  0.8862745  0.3254902 ]]\n",
      "\n",
      "  [[0.03137255 0.13725491 0.00784314]\n",
      "   [0.02745098 0.13333334 0.01176471]\n",
      "   [0.05490196 0.16862746 0.05882353]\n",
      "   ...\n",
      "   [0.89411765 0.9137255  0.44313726]\n",
      "   [0.77254903 0.78431374 0.2627451 ]\n",
      "   [0.8666667  0.8784314  0.3254902 ]]\n",
      "\n",
      "  [[0.05882353 0.16078432 0.05490196]\n",
      "   [0.07450981 0.1764706  0.07058824]\n",
      "   [0.03529412 0.14509805 0.04705882]\n",
      "   ...\n",
      "   [0.7176471  0.7254902  0.23529412]\n",
      "   [0.81960785 0.83137256 0.31764707]\n",
      "   [0.87058824 0.8862745  0.3529412 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34901962 0.5568628  0.6117647 ]\n",
      "   [0.40392157 0.6117647  0.6666667 ]\n",
      "   [0.3254902  0.54509807 0.6039216 ]\n",
      "   ...\n",
      "   [0.6509804  0.5529412  0.33333334]\n",
      "   [0.654902   0.5529412  0.3529412 ]\n",
      "   [0.654902   0.54509807 0.35686275]]\n",
      "\n",
      "  [[0.3764706  0.5803922  0.6313726 ]\n",
      "   [0.4        0.6117647  0.65882355]\n",
      "   [0.3647059  0.58431375 0.63529414]\n",
      "   ...\n",
      "   [0.6431373  0.54901963 0.36862746]\n",
      "   [0.6509804  0.5411765  0.38431373]\n",
      "   [0.62352943 0.5137255  0.36078432]]\n",
      "\n",
      "  [[0.3764706  0.5803922  0.62352943]\n",
      "   [0.3254902  0.5372549  0.5764706 ]\n",
      "   [0.36078432 0.5686275  0.62352943]\n",
      "   ...\n",
      "   [0.6627451  0.57254905 0.4117647 ]\n",
      "   [0.6784314  0.5647059  0.43137255]\n",
      "   [0.6392157  0.5254902  0.4       ]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8509804  0.92156863 0.9764706 ]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   ...\n",
      "   [0.84313726 0.9137255  0.9529412 ]\n",
      "   [0.83137256 0.9098039  0.9529412 ]\n",
      "   [0.8235294  0.9019608  0.94509804]]\n",
      "\n",
      "  [[0.8392157  0.9098039  0.9647059 ]\n",
      "   [0.84313726 0.9137255  0.96862745]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   ...\n",
      "   [0.84705883 0.9254902  0.96862745]\n",
      "   [0.8392157  0.91764706 0.9607843 ]\n",
      "   [0.8352941  0.9137255  0.95686275]]\n",
      "\n",
      "  [[0.84313726 0.9137255  0.96862745]\n",
      "   [0.84705883 0.91764706 0.972549  ]\n",
      "   [0.8509804  0.92156863 0.9764706 ]\n",
      "   ...\n",
      "   [0.8352941  0.9137255  0.95686275]\n",
      "   [0.8352941  0.9137255  0.95686275]\n",
      "   [0.8352941  0.9137255  0.95686275]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8509804  0.92156863 0.9764706 ]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   ...\n",
      "   [0.84313726 0.9137255  0.9529412 ]\n",
      "   [0.83137256 0.9098039  0.9529412 ]\n",
      "   [0.8235294  0.9019608  0.94509804]]\n",
      "\n",
      "  [[0.8392157  0.9098039  0.9647059 ]\n",
      "   [0.84313726 0.9137255  0.96862745]\n",
      "   [0.85490197 0.9254902  0.98039216]\n",
      "   ...\n",
      "   [0.84705883 0.9254902  0.96862745]\n",
      "   [0.8392157  0.91764706 0.9607843 ]\n",
      "   [0.8352941  0.9137255  0.95686275]]\n",
      "\n",
      "  [[0.84313726 0.9137255  0.96862745]\n",
      "   [0.84705883 0.91764706 0.972549  ]\n",
      "   [0.8509804  0.92156863 0.9764706 ]\n",
      "   ...\n",
      "   [0.8352941  0.9137255  0.95686275]\n",
      "   [0.8352941  0.9137255  0.95686275]\n",
      "   [0.8352941  0.9137255  0.95686275]]]\n",
      "\n",
      "\n",
      " [[[0.12941177 0.08235294 0.03529412]\n",
      "   [0.1254902  0.07450981 0.03921569]\n",
      "   [0.11372549 0.07058824 0.04705882]\n",
      "   ...\n",
      "   [0.0627451  0.02352941 0.01568628]\n",
      "   [0.05490196 0.02352941 0.01176471]\n",
      "   [0.05098039 0.01960784 0.00784314]]\n",
      "\n",
      "  [[0.12156863 0.07450981 0.02745098]\n",
      "   [0.10980392 0.05882353 0.02352941]\n",
      "   [0.09803922 0.05490196 0.03137255]\n",
      "   ...\n",
      "   [0.05490196 0.02352941 0.01176471]\n",
      "   [0.04705882 0.01568628 0.00392157]\n",
      "   [0.03529412 0.01568628 0.        ]]\n",
      "\n",
      "  [[0.12156863 0.06666667 0.03137255]\n",
      "   [0.10196079 0.05098039 0.01960784]\n",
      "   [0.08627451 0.04313726 0.01960784]\n",
      "   ...\n",
      "   [0.05098039 0.01960784 0.00784314]\n",
      "   [0.03529412 0.01568628 0.        ]\n",
      "   [0.02745098 0.01568628 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7490196  0.53333336 0.4117647 ]\n",
      "   [0.6901961  0.48235294 0.35686275]\n",
      "   [0.827451   0.63529414 0.5058824 ]\n",
      "   ...\n",
      "   [0.21960784 0.14117648 0.10588235]\n",
      "   [0.25490198 0.14901961 0.11372549]\n",
      "   [0.28235295 0.17254902 0.1254902 ]]\n",
      "\n",
      "  [[0.7529412  0.5294118  0.41568628]\n",
      "   [0.7058824  0.49803922 0.37254903]\n",
      "   [0.8117647  0.6313726  0.49803922]\n",
      "   ...\n",
      "   [0.24313726 0.15686275 0.11372549]\n",
      "   [0.2509804  0.14117648 0.09803922]\n",
      "   [0.25490198 0.14117648 0.08627451]]\n",
      "\n",
      "  [[0.7372549  0.5137255  0.4       ]\n",
      "   [0.7294118  0.52156866 0.4       ]\n",
      "   [0.81960785 0.6392157  0.5058824 ]\n",
      "   ...\n",
      "   [0.24705882 0.16078432 0.11764706]\n",
      "   [0.26666668 0.14901961 0.10588235]\n",
      "   [0.2901961  0.16470589 0.11372549]]]\n",
      "\n",
      "\n",
      " [[[0.         0.19215687 0.45490196]\n",
      "   [0.00392157 0.19607843 0.45882353]\n",
      "   [0.00392157 0.19607843 0.45882353]\n",
      "   ...\n",
      "   [0.00784314 0.2509804  0.5529412 ]\n",
      "   [0.00392157 0.24705882 0.54901963]\n",
      "   [0.00392157 0.24705882 0.54901963]]\n",
      "\n",
      "  [[0.00392157 0.19607843 0.45882353]\n",
      "   [0.00392157 0.19607843 0.45882353]\n",
      "   [0.00784314 0.2        0.4627451 ]\n",
      "   ...\n",
      "   [0.01568628 0.25882354 0.56078434]\n",
      "   [0.01176471 0.25490198 0.5568628 ]\n",
      "   [0.01176471 0.25490198 0.5568628 ]]\n",
      "\n",
      "  [[0.00392157 0.2        0.47058824]\n",
      "   [0.00784314 0.20392157 0.4745098 ]\n",
      "   [0.00784314 0.20392157 0.4745098 ]\n",
      "   ...\n",
      "   [0.01960784 0.2627451  0.5647059 ]\n",
      "   [0.01960784 0.2627451  0.5647059 ]\n",
      "   [0.01960784 0.2627451  0.5647059 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.57254905 0.6117647  0.6509804 ]\n",
      "   [0.57254905 0.6117647  0.6509804 ]\n",
      "   [0.5686275  0.60784316 0.64705884]\n",
      "   ...\n",
      "   [0.63529414 0.6627451  0.69411767]\n",
      "   [0.5803922  0.60784316 0.6392157 ]\n",
      "   [0.6862745  0.7137255  0.74509805]]\n",
      "\n",
      "  [[0.5647059  0.6039216  0.6431373 ]\n",
      "   [0.5647059  0.6039216  0.6431373 ]\n",
      "   [0.5803922  0.61960787 0.65882355]\n",
      "   ...\n",
      "   [0.67058825 0.69803923 0.7294118 ]\n",
      "   [0.62352943 0.65882355 0.6862745 ]\n",
      "   [0.46666667 0.5019608  0.5294118 ]]\n",
      "\n",
      "  [[0.5686275  0.60784316 0.64705884]\n",
      "   [0.5568628  0.59607846 0.63529414]\n",
      "   [0.57254905 0.6117647  0.6509804 ]\n",
      "   ...\n",
      "   [0.59607846 0.62352943 0.654902  ]\n",
      "   [0.5529412  0.5882353  0.6156863 ]\n",
      "   [0.54901963 0.58431375 0.6117647 ]]]]\n",
      "Sentence embeddings: [[-0.07213408 -0.02718696 -0.02381519 ... -0.08483882 -0.01102034\n",
      "   0.02472727]\n",
      " [ 0.01581124  0.07004684 -0.06182501 ... -0.0096993  -0.02714245\n",
      "  -0.00249444]\n",
      " [-0.01669362 -0.08603268  0.01884513 ...  0.01895648  0.054609\n",
      "   0.06335407]\n",
      " ...\n",
      " [-0.07796966 -0.0528924   0.03131704 ...  0.00981435  0.1000666\n",
      "  -0.0285379 ]\n",
      " [-0.07064815  0.07349901  0.04866007 ... -0.01777621  0.05042707\n",
      "   0.03486131]\n",
      " [-0.02329908  0.00637987  0.01156258 ... -0.02430007 -0.0420001\n",
      "   0.02565889]]\n",
      "Caption: [b'A group of people crossing ropes that are suspended over water .'\n",
      " b'The little boy wearing no shirt is running by a crowd of people .'\n",
      " b'There is a woman holding her baby daughter while the daughter claps .'\n",
      " b'A brown , fluffy dog jumping into a swimming pool after a red toy .'\n",
      " b'An ice skating park in winter , with many people .'\n",
      " b'Two horses are pulling a woman in a cart .'\n",
      " b'A young woman hugs a young man who s wearing a pink costume .'\n",
      " b'A skateboarder goes down a railing .']\n",
      "Label : [0 1]\n",
      "-----------------------------------------\n",
      "LOADING data from /home/rinzler/Github/Image-Text-Matching/data/flickr8k.TestImages.txt\n",
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:00:18.716896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1164]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-18 19:00:18.717771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1164]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|image_data|=1161\n",
      "|text_data|=1161\n",
      "|label_data|=1161\n",
      "PRINTING data samples...\n",
      "-----------------------------------------\n",
      "Image pixels: [[[[0.28235295 0.31764707 0.29803923]\n",
      "   [0.13725491 0.16862746 0.1764706 ]\n",
      "   [0.17254902 0.19607843 0.2509804 ]\n",
      "   ...\n",
      "   [0.45882353 0.5176471  0.5372549 ]\n",
      "   [0.5254902  0.5411765  0.58431375]\n",
      "   [0.16862746 0.16078432 0.21176471]]\n",
      "\n",
      "  [[0.23529412 0.27058825 0.2509804 ]\n",
      "   [0.12941177 0.16078432 0.16862746]\n",
      "   [0.2        0.22352941 0.27058825]\n",
      "   ...\n",
      "   [0.4509804  0.50980395 0.5294118 ]\n",
      "   [0.5254902  0.5372549  0.57254905]\n",
      "   [0.2627451  0.25490198 0.29803923]]\n",
      "\n",
      "  [[0.2509804  0.28627452 0.26666668]\n",
      "   [0.12156863 0.15686275 0.15294118]\n",
      "   [0.24705882 0.27450982 0.3137255 ]\n",
      "   ...\n",
      "   [0.4745098  0.53333336 0.5529412 ]\n",
      "   [0.5372549  0.54901963 0.58431375]\n",
      "   [0.32941177 0.31764707 0.3529412 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15686275 0.16470589 0.08235294]\n",
      "   [0.28235295 0.29803923 0.2       ]\n",
      "   [0.16078432 0.18039216 0.05490196]\n",
      "   ...\n",
      "   [0.4627451  0.5058824  0.19607843]\n",
      "   [0.48235294 0.5294118  0.23137255]\n",
      "   [0.43529412 0.49019608 0.19607843]]\n",
      "\n",
      "  [[0.19607843 0.19607843 0.10196079]\n",
      "   [0.22745098 0.23921569 0.13333334]\n",
      "   [0.18039216 0.2        0.08235294]\n",
      "   ...\n",
      "   [0.49019608 0.53333336 0.23529412]\n",
      "   [0.50980395 0.56078434 0.2901961 ]\n",
      "   [0.41568628 0.4745098  0.21960784]]\n",
      "\n",
      "  [[0.24705882 0.24705882 0.14509805]\n",
      "   [0.23137255 0.24313726 0.13725491]\n",
      "   [0.17254902 0.18431373 0.07058824]\n",
      "   ...\n",
      "   [0.54901963 0.5921569  0.29411766]\n",
      "   [0.4392157  0.4862745  0.23529412]\n",
      "   [0.5019608  0.5568628  0.31764707]]]\n",
      "\n",
      "\n",
      " [[[0.57254905 0.70980394 0.92941177]\n",
      "   [0.57254905 0.70980394 0.92941177]\n",
      "   [0.57254905 0.70980394 0.92941177]\n",
      "   ...\n",
      "   [0.53333336 0.6745098  0.91764706]\n",
      "   [0.5372549  0.6784314  0.92156863]\n",
      "   [0.5372549  0.6784314  0.92156863]]\n",
      "\n",
      "  [[0.5764706  0.7137255  0.93333334]\n",
      "   [0.5764706  0.7137255  0.93333334]\n",
      "   [0.5764706  0.7137255  0.93333334]\n",
      "   ...\n",
      "   [0.5411765  0.68235296 0.9254902 ]\n",
      "   [0.5411765  0.68235296 0.9254902 ]\n",
      "   [0.5411765  0.68235296 0.9254902 ]]\n",
      "\n",
      "  [[0.5882353  0.7176471  0.92941177]\n",
      "   [0.5882353  0.7176471  0.92941177]\n",
      "   [0.5803922  0.7176471  0.92941177]\n",
      "   ...\n",
      "   [0.5411765  0.68235296 0.91764706]\n",
      "   [0.54509807 0.6862745  0.92156863]\n",
      "   [0.54509807 0.6862745  0.92156863]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.4627451  0.4509804  0.27450982]\n",
      "   [0.41960785 0.41568628 0.23529412]\n",
      "   [0.46666667 0.48235294 0.28627452]\n",
      "   ...\n",
      "   [0.3529412  0.30588236 0.15686275]\n",
      "   [0.41960785 0.38431373 0.22352941]\n",
      "   [0.39215687 0.3647059  0.2       ]]\n",
      "\n",
      "  [[0.4627451  0.47058824 0.2784314 ]\n",
      "   [0.34901962 0.34509805 0.15686275]\n",
      "   [0.40784314 0.4        0.21176471]\n",
      "   ...\n",
      "   [0.3764706  0.32941177 0.18039216]\n",
      "   [0.35686275 0.3372549  0.17254902]\n",
      "   [0.4509804  0.4392157  0.2627451 ]]\n",
      "\n",
      "  [[0.49411765 0.50980395 0.30980393]\n",
      "   [0.41960785 0.42745098 0.23137255]\n",
      "   [0.33333334 0.30588236 0.1254902 ]\n",
      "   ...\n",
      "   [0.4627451  0.4117647  0.27450982]\n",
      "   [0.3647059  0.34901962 0.17254902]\n",
      "   [0.3764706  0.37254903 0.18431373]]]\n",
      "\n",
      "\n",
      " [[[0.13333334 0.13725491 0.21568628]\n",
      "   [0.14509805 0.18039216 0.24705882]\n",
      "   [0.11372549 0.19607843 0.2627451 ]\n",
      "   ...\n",
      "   [0.22745098 0.24705882 0.32156864]\n",
      "   [0.2627451  0.30980393 0.3647059 ]\n",
      "   [0.29803923 0.3647059  0.40392157]]\n",
      "\n",
      "  [[0.14509805 0.16470589 0.23921569]\n",
      "   [0.15294118 0.2        0.2627451 ]\n",
      "   [0.08627451 0.1764706  0.23137255]\n",
      "   ...\n",
      "   [0.26666668 0.2784314  0.3529412 ]\n",
      "   [0.29411766 0.34117648 0.39607844]\n",
      "   [0.30980393 0.3764706  0.41568628]]\n",
      "\n",
      "  [[0.1254902  0.17254902 0.23529412]\n",
      "   [0.13725491 0.2        0.25882354]\n",
      "   [0.11372549 0.20784314 0.25490198]\n",
      "   ...\n",
      "   [0.29411766 0.29803923 0.36862746]\n",
      "   [0.3137255  0.3529412  0.4       ]\n",
      "   [0.32156864 0.3764706  0.41960785]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08235294 0.12156863 0.16078432]\n",
      "   [0.03921569 0.07843138 0.11764706]\n",
      "   [0.05490196 0.08627451 0.12941177]\n",
      "   ...\n",
      "   [0.2784314  0.2784314  0.2784314 ]\n",
      "   [0.26666668 0.26666668 0.25882354]\n",
      "   [0.26666668 0.26666668 0.25882354]]\n",
      "\n",
      "  [[0.09019608 0.11372549 0.16862746]\n",
      "   [0.04313726 0.06666667 0.11372549]\n",
      "   [0.0627451  0.09019608 0.12941177]\n",
      "   ...\n",
      "   [0.25882354 0.25882354 0.2509804 ]\n",
      "   [0.24705882 0.24705882 0.23921569]\n",
      "   [0.24705882 0.24705882 0.23921569]]\n",
      "\n",
      "  [[0.09019608 0.10196079 0.16078432]\n",
      "   [0.04705882 0.0627451  0.10980392]\n",
      "   [0.07450981 0.09019608 0.13333334]\n",
      "   ...\n",
      "   [0.24705882 0.24705882 0.23921569]\n",
      "   [0.23921569 0.23921569 0.23137255]\n",
      "   [0.23921569 0.23921569 0.23137255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.49411765 0.40784314 0.35686275]\n",
      "   [0.5294118  0.44313726 0.3882353 ]\n",
      "   [0.5019608  0.42745098 0.36078432]\n",
      "   ...\n",
      "   [0.30980393 0.29803923 0.2627451 ]\n",
      "   [0.30980393 0.3137255  0.28235295]\n",
      "   [0.30980393 0.32156864 0.28627452]]\n",
      "\n",
      "  [[0.5372549  0.4509804  0.4       ]\n",
      "   [0.5254902  0.4392157  0.38431373]\n",
      "   [0.5372549  0.4627451  0.40392157]\n",
      "   ...\n",
      "   [0.4        0.38431373 0.34901962]\n",
      "   [0.35686275 0.36078432 0.32941177]\n",
      "   [0.33333334 0.34509805 0.30980393]]\n",
      "\n",
      "  [[0.49411765 0.40392157 0.34901962]\n",
      "   [0.5568628  0.47058824 0.41960785]\n",
      "   [0.5764706  0.5019608  0.44705883]\n",
      "   ...\n",
      "   [0.43529412 0.40784314 0.38431373]\n",
      "   [0.42352942 0.41960785 0.4       ]\n",
      "   [0.47058824 0.4745098  0.4509804 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43529412 0.4509804  0.4627451 ]\n",
      "   [0.4392157  0.45490196 0.46666667]\n",
      "   [0.42352942 0.4392157  0.4509804 ]\n",
      "   ...\n",
      "   [0.44313726 0.45882353 0.4627451 ]\n",
      "   [0.4862745  0.5019608  0.5058824 ]\n",
      "   [0.47843137 0.49411765 0.49803922]]\n",
      "\n",
      "  [[0.43529412 0.4509804  0.4627451 ]\n",
      "   [0.44313726 0.45882353 0.47058824]\n",
      "   [0.45490196 0.47058824 0.48235294]\n",
      "   ...\n",
      "   [0.45490196 0.47058824 0.46666667]\n",
      "   [0.45882353 0.4745098  0.47058824]\n",
      "   [0.47058824 0.4862745  0.48235294]]\n",
      "\n",
      "  [[0.41568628 0.43137255 0.44313726]\n",
      "   [0.4392157  0.45490196 0.46666667]\n",
      "   [0.4117647  0.42745098 0.4392157 ]\n",
      "   ...\n",
      "   [0.4627451  0.47843137 0.4745098 ]\n",
      "   [0.48235294 0.49803922 0.49411765]\n",
      "   [0.4862745  0.5019608  0.49803922]]]\n",
      "\n",
      "\n",
      " [[[0.39215687 0.47058824 0.3254902 ]\n",
      "   [0.31764707 0.40392157 0.2627451 ]\n",
      "   [0.32941177 0.40784314 0.3019608 ]\n",
      "   ...\n",
      "   [0.13333334 0.16470589 0.10588235]\n",
      "   [0.13333334 0.16470589 0.12156863]\n",
      "   [0.1254902  0.15686275 0.11372549]]\n",
      "\n",
      "  [[0.58431375 0.67058825 0.5294118 ]\n",
      "   [0.25882354 0.34117648 0.21176471]\n",
      "   [0.31764707 0.39607844 0.28627452]\n",
      "   ...\n",
      "   [0.20784314 0.23921569 0.18039216]\n",
      "   [0.13333334 0.16470589 0.11372549]\n",
      "   [0.24313726 0.27450982 0.22352941]]\n",
      "\n",
      "  [[0.44313726 0.5372549  0.40392157]\n",
      "   [0.5568628  0.6509804  0.5254902 ]\n",
      "   [0.3254902  0.40784314 0.28627452]\n",
      "   ...\n",
      "   [0.26666668 0.3019608  0.23529412]\n",
      "   [0.14901961 0.18039216 0.12156863]\n",
      "   [0.3254902  0.35686275 0.29803923]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.14901961 0.2509804  0.21568628]\n",
      "   [0.13725491 0.24313726 0.20784314]\n",
      "   [0.1764706  0.29411766 0.25490198]\n",
      "   ...\n",
      "   [0.25490198 0.3882353  0.32156864]\n",
      "   [0.14901961 0.28235295 0.21568628]\n",
      "   [0.20784314 0.34117648 0.27450982]]\n",
      "\n",
      "  [[0.16470589 0.27450982 0.22745098]\n",
      "   [0.15294118 0.2627451  0.21568628]\n",
      "   [0.18431373 0.3019608  0.25490198]\n",
      "   ...\n",
      "   [0.1882353  0.32156864 0.25882354]\n",
      "   [0.21176471 0.3372549  0.2784314 ]\n",
      "   [0.14901961 0.27450982 0.21568628]]\n",
      "\n",
      "  [[0.15294118 0.2627451  0.21568628]\n",
      "   [0.13725491 0.25490198 0.20784314]\n",
      "   [0.18039216 0.29803923 0.2509804 ]\n",
      "   ...\n",
      "   [0.15294118 0.28627452 0.23137255]\n",
      "   [0.19215687 0.30980393 0.2627451 ]\n",
      "   [0.17254902 0.2901961  0.24313726]]]\n",
      "\n",
      "\n",
      " [[[0.23529412 0.25882354 0.21960784]\n",
      "   [0.21176471 0.23529412 0.19607843]\n",
      "   [0.17254902 0.20392157 0.15294118]\n",
      "   ...\n",
      "   [0.27058825 0.27450982 0.25490198]\n",
      "   [0.27058825 0.26666668 0.2509804 ]\n",
      "   [0.17254902 0.16862746 0.14901961]]\n",
      "\n",
      "  [[0.13333334 0.15686275 0.11764706]\n",
      "   [0.10588235 0.12941177 0.09019608]\n",
      "   [0.12156863 0.15294118 0.10980392]\n",
      "   ...\n",
      "   [0.24705882 0.24705882 0.23921569]\n",
      "   [0.21960784 0.21568628 0.2       ]\n",
      "   [0.16078432 0.15686275 0.13725491]]\n",
      "\n",
      "  [[0.12156863 0.14901961 0.11764706]\n",
      "   [0.10980392 0.14117648 0.09803922]\n",
      "   [0.10196079 0.13333334 0.09019608]\n",
      "   ...\n",
      "   [0.2        0.2        0.19215687]\n",
      "   [0.2        0.19607843 0.1882353 ]\n",
      "   [0.15294118 0.14901961 0.13333334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44313726 0.56078434 0.22352941]\n",
      "   [0.47843137 0.60784316 0.26666668]\n",
      "   [0.44313726 0.57254905 0.22352941]\n",
      "   ...\n",
      "   [0.21568628 0.3254902  0.09411765]\n",
      "   [0.34901962 0.4745098  0.1882353 ]\n",
      "   [0.27450982 0.4117647  0.09803922]]\n",
      "\n",
      "  [[0.5803922  0.6901961  0.4       ]\n",
      "   [0.5803922  0.69803923 0.40784314]\n",
      "   [0.43137255 0.5529412  0.25490198]\n",
      "   ...\n",
      "   [0.11764706 0.23921569 0.        ]\n",
      "   [0.3372549  0.47058824 0.16862746]\n",
      "   [0.3137255  0.4627451  0.13725491]]\n",
      "\n",
      "  [[0.49411765 0.6        0.3372549 ]\n",
      "   [0.5254902  0.6392157  0.3764706 ]\n",
      "   [0.36862746 0.4862745  0.21176471]\n",
      "   ...\n",
      "   [0.24705882 0.36862746 0.09411765]\n",
      "   [0.30588236 0.4392157  0.13725491]\n",
      "   [0.25490198 0.40392157 0.07843138]]]]\n",
      "Sentence embeddings: [[-0.04839425  0.00194335  0.00044443 ... -0.04939776  0.02146097\n",
      "   0.05677493]\n",
      " [ 0.05630793 -0.0628757   0.06045282 ... -0.01400149  0.00682806\n",
      "   0.08007551]\n",
      " [-0.06098829 -0.02917129 -0.01157453 ... -0.05760512 -0.04701255\n",
      "  -0.02287189]\n",
      " ...\n",
      " [-0.03181052  0.03821148  0.09326454 ...  0.07253434  0.098501\n",
      "   0.05994003]\n",
      " [ 0.0152633   0.04577012 -0.02445744 ...  0.01080811  0.04443144\n",
      "   0.02956877]\n",
      " [ 0.03785849 -0.02844976  0.06302623 ... -0.00571264 -0.03886784\n",
      "   0.09822886]]\n",
      "Caption: [b'A person wearing Rollerblades jumps over a yellow gate .'\n",
      " b'Several people are playing outside in the water .'\n",
      " b'Two hikers with backpacks crossing a snow field .'\n",
      " b'Man relaxing in a folding chair on the street .'\n",
      " b'Four brothers and one sister posing for a picture , smiling .'\n",
      " b'An off road vehicle driving through a mud puddle .'\n",
      " b'Man carrying a tool box on a sidewalk'\n",
      " b'A dog is jumping through the air in an open , snow covered field .']\n",
      "Label : [0 1]\n",
      "-----------------------------------------\n",
      "done loading data...\n",
      "BUILDING model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:00:19.193569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1161]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-18 19:00:19.194694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [1161,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 16  448         ['image_input[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 28, 28, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 50176)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " text_embedding (InputLayer)    [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          6422656     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          49280       ['text_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " tf.nn.gelu (TFOpLambda)        (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.nn.gelu_1 (TFOpLambda)      (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['tf.nn.gelu[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['tf.nn.gelu_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128)          0           ['dense[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 128)          0           ['dense_2[0][0]',                \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128)         256         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 128)         256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['layer_normalization[0][0]',    \n",
      "                                                                  'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " ITM_Classifier-flickr (Dense)  (None, 2)            514         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,529,570\n",
      "Trainable params: 6,529,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "TRAINING model\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:00:19.918719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [19386,384]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-03-18 19:00:19.919685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int32 and shape [19386,2]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "/home/rinzler/Github/Image-Text-Matching/env/lib/python3.10/site-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['caption', 'file_name'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "2024-03-18 19:00:22.195629: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-03-18 19:00:22.592404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-03-18 19:00:22.617875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424/2424 [==============================] - ETA: 0s - loss: 0.7606 - binary_accuracy: 0.5794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 19:01:09.760325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1164]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-03-18 19:01:09.760984: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1164,384]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424/2424 [==============================] - 52s 20ms/step - loss: 0.7606 - binary_accuracy: 0.5794 - val_loss: 0.6470 - val_binary_accuracy: 0.6366\n",
      "Epoch 2/5\n",
      "2424/2424 [==============================] - 47s 19ms/step - loss: 0.6591 - binary_accuracy: 0.6471 - val_loss: 0.6329 - val_binary_accuracy: 0.6529\n",
      "Epoch 3/5\n",
      "2424/2424 [==============================] - 47s 19ms/step - loss: 0.6455 - binary_accuracy: 0.6527 - val_loss: 0.6345 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "2424/2424 [==============================] - 47s 19ms/step - loss: 0.6378 - binary_accuracy: 0.6586 - val_loss: 0.6300 - val_binary_accuracy: 0.6632\n",
      "Epoch 5/5\n",
      "2424/2424 [==============================] - 47s 20ms/step - loss: 0.6317 - binary_accuracy: 0.6640 - val_loss: 0.6333 - val_binary_accuracy: 0.6649\n",
      "model trained!\n",
      "TESTING classifier model (showing a sample of image-text-matching predictions)...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/Test_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's create an instance of the main class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m itm \u001b[38;5;241m=\u001b[39m \u001b[43mITM_Classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mITM_Classifier.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_classifier_model()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_classifier_model()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_classifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 102\u001b[0m, in \u001b[0;36mITM_Classifier.test_classifier_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filename):\n\u001b[1;32m    100\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(filename)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[1;32m    103\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(csv_file, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[1;32m    104\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriteheader()\n",
      "File \u001b[0;32m~/Github/Image-Text-Matching/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/Test_sample.csv'"
     ]
    }
   ],
   "source": [
    "# Let's create an instance of the main class\n",
    "itm = ITM_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final values of global variables\n",
    "print(\"Final Accuracy:\", Accuracy)\n",
    "print(\"Final Loss:\", Loss)\n",
    "print(\"Final Validation Accuracy:\", Validation_accuracy)\n",
    "print(\"Final Validation Loss:\", Validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(itm.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
