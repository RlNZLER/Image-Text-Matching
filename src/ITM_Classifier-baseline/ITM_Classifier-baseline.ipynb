{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dependencies\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import einops\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from official.nlp import optimization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading image and text data\n",
    "\n",
    "\n",
    "class ITM_DataLoader:\n",
    "    BATCH_SIZE = 16\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    IMAGE_SHAPE = (224, 224, 3)\n",
    "    SENTENCE_EMBEDDING_SHAPE = 384\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    DATA_PATH = \"D:\\_GITHUB_\\Image-Text-Matching\\data\"\n",
    "    IMAGES_PATH = DATA_PATH + \"/images\"\n",
    "    train_data_file = DATA_PATH + \"/flickr8k.TrainImages.txt\"\n",
    "    dev_data_file = DATA_PATH + \"/flickr8k.DevImages.txt\"\n",
    "    test_data_file = DATA_PATH + \"/flickr8k.TestImages.txt\"\n",
    "    sentence_embeddings_file = DATA_PATH + \"/flickr8k.cmp9137.sentence_transformers.pkl\"\n",
    "    sentence_embeddings = {}\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    test_ds = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentence_embeddings = self.load_sentence_embeddings()\n",
    "        self.train_ds = self.load_classifier_data(self.train_data_file)\n",
    "        self.val_ds = self.load_classifier_data(self.dev_data_file)\n",
    "        self.test_ds = self.load_classifier_data(self.test_data_file)\n",
    "        print(\"done loading data...\")\n",
    "\n",
    "    # Sentence embeddings are dense vectors representing text data, one vector per sentence.\n",
    "    # Sentences with similar vectors would mean sentences with equivalent meanning.\n",
    "    # They are useful here to provide text-based features of questions in the data.\n",
    "    # Note: sentence embeddings don't include label info, they are solely based on captions.\n",
    "    def load_sentence_embeddings(self):\n",
    "        sentence_embeddings = {}\n",
    "        print(\"READING sentence embeddings...\")\n",
    "        with open(self.sentence_embeddings_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            for sentence, dense_vector in data.items():\n",
    "                # print(\"*sentence=\",sentence)\n",
    "                sentence_embeddings[sentence] = dense_vector\n",
    "        print(\"Done reading sentence_embeddings!\")\n",
    "        return sentence_embeddings\n",
    "\n",
    "    # In contrast to text-data based on pre-trained features, image data does not use\n",
    "    # any form of pre-training in this program. Instead, it makes use of raw pixels.\n",
    "    # Notes that input features to the classifier are only pixels and sentence embeddings.\n",
    "    def process_input(self, img_path, dense_vector, text, label):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.IMAGE_SIZE)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img = tf.cast(img, tf.float32) / 255\n",
    "        features = {}\n",
    "        features[\"image_input\"] = img\n",
    "        features[\"text_embedding\"] = dense_vector\n",
    "        features[\"caption\"] = text\n",
    "        features[\"file_name\"] = img_path\n",
    "        return features, label\n",
    "\n",
    "    # This method loads the multimodal data, which comes from the following sources:\n",
    "    # (1) image files in IMAGES_PATH, and (2) files with pattern flickr8k.*Images.txt\n",
    "    # The data is stored in a tensorflow data structure to make it easy to use by\n",
    "    # the tensorflow model during training, validation and test. This method was\n",
    "    # carefully prepared to load the data rapidly, i.e., by loading already created\n",
    "    # sentence embeddings (text features) rather than creating them at runtime.\n",
    "    def load_classifier_data(self, data_files):\n",
    "        print(\"LOADING data from \" + str(data_files))\n",
    "        print(\"=========================================\")\n",
    "        image_data = []\n",
    "        text_data = []\n",
    "        embeddings_data = []\n",
    "        label_data = []\n",
    "\n",
    "        # get image, text, label of image_files\n",
    "        with open(data_files) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                img_name, text, raw_label = line.split(\"\t\")\n",
    "                img_name = os.path.join(self.IMAGES_PATH, img_name.strip())\n",
    "\n",
    "                # get binary labels from match/no-match answers\n",
    "                label = [1, 0] if raw_label == \"match\" else [0, 1]\n",
    "                # print(\"I=%s T=%s _L=%s L=%s\" % (img_name, text, raw_label, label))\n",
    "\n",
    "                # get sentence embeddings (of textual captions)\n",
    "                text_sentence_embedding = self.sentence_embeddings[text]\n",
    "                text_sentence_embedding = tf.constant(text_sentence_embedding)\n",
    "\n",
    "                image_data.append(img_name)\n",
    "                embeddings_data.append(text_sentence_embedding)\n",
    "                text_data.append(text)\n",
    "                label_data.append(label)\n",
    "\n",
    "        print(\"|image_data|=\" + str(len(image_data)))\n",
    "        print(\"|text_data|=\" + str(len(text_data)))\n",
    "        print(\"|label_data|=\" + str(len(label_data)))\n",
    "\n",
    "        # prepare a tensorflow dataset using the lists generated above\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (image_data, embeddings_data, text_data, label_data)\n",
    "        )\n",
    "        dataset = dataset.shuffle(self.BATCH_SIZE * 8)\n",
    "        dataset = dataset.map(self.process_input, num_parallel_calls=self.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.BATCH_SIZE).prefetch(self.AUTOTUNE)\n",
    "        self.print_data_samples(dataset)\n",
    "        return dataset\n",
    "\n",
    "    def print_data_samples(self, dataset):\n",
    "        print(\"PRINTING data samples...\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        for features_batch, label_batch in dataset.take(1):\n",
    "            for i in range(1):\n",
    "                print(f'Image pixels: {features_batch[\"image_input\"]}')\n",
    "                print(f'Sentence embeddings: {features_batch[\"text_embedding\"]}')\n",
    "                print(f'Caption: {features_batch[\"caption\"].numpy()}')\n",
    "                label = label_batch.numpy()[i]\n",
    "                print(f\"Label : {label}\")\n",
    "        print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class for the Image-Text Matching (ITM) task\n",
    "\n",
    "\n",
    "class ITM_Classifier(ITM_DataLoader):\n",
    "    epochs = 20\n",
    "    learning_rate = 4e-5\n",
    "    class_names = {\"match\", \"no-match\"}\n",
    "    num_classes = len(class_names)\n",
    "    classifier_model = None\n",
    "    history = None\n",
    "    classifier_model_name = \"ITM_Classifier-baseline\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_classifier_model()\n",
    "        self.train_classifier_model()\n",
    "        self.test_classifier_model()\n",
    "\n",
    "    # return learnt feature representations of input data (images)\n",
    "    def create_vision_encoder(\n",
    "        self, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        img_input = layers.Input(shape=self.IMAGE_SHAPE, name=\"image_input\")\n",
    "        cnn_layer = layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(img_input)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(cnn_layer)\n",
    "        cnn_layer = layers.MaxPooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Dropout(dropout_rate)(cnn_layer)\n",
    "        cnn_layer = layers.Flatten()(cnn_layer)\n",
    "        outputs = self.project_embeddings(\n",
    "            cnn_layer, num_projection_layers, projection_dims, dropout_rate\n",
    "        )\n",
    "        return img_input, outputs\n",
    "\n",
    "    # return learnt feature representations based on dense layers, dropout, and layer normalisation\n",
    "    def project_embeddings(\n",
    "        self, embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "        for _ in range(num_projection_layers):\n",
    "            x = tf.nn.gelu(projected_embeddings)\n",
    "            x = layers.Dense(projection_dims)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "            x = layers.Add()([projected_embeddings, x])\n",
    "            projected_embeddings = layers.LayerNormalization()(x)\n",
    "        return projected_embeddings\n",
    "\n",
    "    # return learnt feature representations of input data (text embeddings in the form of dense vectors)\n",
    "    def create_text_encoder(self, num_projection_layers, projection_dims, dropout_rate):\n",
    "        text_input = keras.Input(\n",
    "            shape=self.SENTENCE_EMBEDDING_SHAPE, name=\"text_embedding\"\n",
    "        )\n",
    "        outputs = self.project_embeddings(\n",
    "            text_input, num_projection_layers, projection_dims, dropout_rate\n",
    "        )\n",
    "        return text_input, outputs\n",
    "\n",
    "    # put together the feature representations above to create the image-text (multimodal) deep learning model\n",
    "    def build_classifier_model(self):\n",
    "        print(f\"BUILDING model\")\n",
    "        img_input, vision_net = self.create_vision_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "        text_input, text_net = self.create_text_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "        net = tf.keras.layers.Concatenate(axis=1)([vision_net, text_net])\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(\n",
    "            self.num_classes, activation=\"softmax\", name=self.classifier_model_name\n",
    "        )(net)\n",
    "        self.classifier_model = tf.keras.Model(\n",
    "            inputs=[img_input, text_input], outputs=net\n",
    "        )\n",
    "        self.classifier_model.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_dir = \"models\"\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)  # Ensure directory exists\n",
    "        model_path = os.path.join(model_dir, self.classifier_model_name)\n",
    "        history_path = os.path.join(\n",
    "            model_dir, f\"{self.classifier_model_name}_history.pkl\"\n",
    "        )\n",
    "        print(\"SAVING model history to\", model_path)\n",
    "        # self.classifier_model.save(model_path)  # Save the model\n",
    "        with open(history_path, \"wb\") as f:\n",
    "            pickle.dump(self.history.history, f)  # Save the training history\n",
    "\n",
    "    def train_classifier_model(self):\n",
    "        print(f\"TRAINING model\")\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        num_warmup_steps = int(0.2 * num_train_steps)\n",
    "\n",
    "        loss = tf.keras.losses.KLDivergence()\n",
    "        metrics = [\n",
    "            BinaryAccuracy(name=\"binary_accuracy\"),\n",
    "            Precision(name=\"precision\"),\n",
    "            Recall(name=\"recall\"),\n",
    "        ]\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=self.learning_rate,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type=\"adamw\",\n",
    "        )\n",
    "\n",
    "        self.classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # uncomment the next line if you wish to make use of early stopping during training\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=11, restore_best_weights=True)\n",
    "        ]\n",
    "\n",
    "        self.history = self.classifier_model.fit(\n",
    "            x=self.train_ds,\n",
    "            validation_data=self.val_ds,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        self.save_model()\n",
    "        print(\"model trained!\")\n",
    "\n",
    "    def test_classifier_model(self):\n",
    "        print(\n",
    "            \"TESTING classifier model (showing a sample of image-text-matching predictions)...\"\n",
    "        )\n",
    "        num_classifications = 0\n",
    "        num_correct_predictions = 0\n",
    "\n",
    "        # read test data for ITM classification\n",
    "        for features, groundtruth in self.test_ds:\n",
    "            groundtruth = groundtruth.numpy()\n",
    "            predictions = self.classifier_model(features)\n",
    "            predictions = predictions.numpy()\n",
    "            captions = features[\"caption\"].numpy()\n",
    "            file_names = features[\"file_name\"].numpy()\n",
    "\n",
    "            # read test data per batch\n",
    "            for batch_index in range(0, len(groundtruth)):\n",
    "                predicted_values = predictions[batch_index]\n",
    "                probability_match = predicted_values[0]\n",
    "                probability_nomatch = predicted_values[1]\n",
    "                predicted_class = (\n",
    "                    \"[1 0]\" if probability_match > probability_nomatch else \"[0 1]\"\n",
    "                )\n",
    "                if str(groundtruth[batch_index]) == predicted_class:\n",
    "                    num_correct_predictions += 1\n",
    "                num_classifications += 1\n",
    "\n",
    "                # print a sample of predictions -- about 10% of all possible\n",
    "                if random.random() < 0.1:\n",
    "                    caption = captions[batch_index]\n",
    "                    file_name = file_names[batch_index].decode(\"utf-8\")\n",
    "                    print(\n",
    "                        \"ITM=%s PREDICTIONS: match=%s, no-match=%s \\t -> \\t %s\"\n",
    "                        % (caption, probability_match, probability_nomatch, file_name)\n",
    "                    )\n",
    "\n",
    "        # reveal test performance using our own calculations above\n",
    "        accuracy = num_correct_predictions / num_classifications\n",
    "        print(\"TEST accuracy=%4f\" % (accuracy))\n",
    "\n",
    "        # reveal test performance using Tensorflow calculations\n",
    "        loss, accuracy, precision, recall = self.classifier_model.evaluate(self.test_ds)\n",
    "        print(\n",
    "            f\"Tensorflow test method: LOSS: {loss}; ACCURACY: {accuracy}: PRECISION: {precision}; RECALL: {recall}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 scores from precision and recall values.\n",
    "def calculate_f1_scores(precision_vals, recall_vals):\n",
    "    f1_scores = []\n",
    "    for p, r in zip(precision_vals, recall_vals):\n",
    "        if p + r == 0:  # Avoid division by zero\n",
    "            f1_scores.append(0)\n",
    "        else:\n",
    "            f1_score = (\n",
    "                2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n",
    "            )  # Ensure numerical stability\n",
    "            f1_scores.append(f1_score)\n",
    "    return f1_scores\n",
    "\n",
    "\n",
    "# Plot training history metrics for accuracy, loss, precision, recall, and F1 score.\n",
    "def plot_training_history(history_data):\n",
    "    # Extract metrics from history\n",
    "    acc = history_data.get(\"binary_accuracy\", [])\n",
    "    val_acc = history_data.get(\"val_binary_accuracy\", [])\n",
    "    loss = history_data.get(\"loss\", [])\n",
    "    val_loss = history_data.get(\"val_loss\", [])\n",
    "    precision = history_data.get(\"precision\", [])\n",
    "    val_precision = history_data.get(\"val_precision\", [])\n",
    "    recall = history_data.get(\"recall\", [])\n",
    "    val_recall = history_data.get(\"val_recall\", [])\n",
    "\n",
    "    # Calculate F1 Scores\n",
    "    f1 = calculate_f1_scores(precision, recall)\n",
    "    val_f1 = calculate_f1_scores(val_precision, val_recall)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Subplot for Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(acc, label=\"Train Accuracy\")\n",
    "    plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot for Loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(loss, label=\"Train Loss\")\n",
    "    plt.plot(val_loss, label=\"Validation Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot for Precision and Recall\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(precision, label=\"Train Precision\")\n",
    "    plt.plot(val_precision, label=\"Validation Precision\")\n",
    "    plt.plot(recall, label=\"Train Recall\")\n",
    "    plt.plot(val_recall, label=\"Validation Recall\")\n",
    "    plt.title(\"Precision and Recall\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot for F1 Score\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(f1, label=\"Train F1 Score\")\n",
    "    plt.plot(val_f1, label=\"Validation F1 Score\")\n",
    "    plt.title(\"F1 Score\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_history_plots.png\")  # Save the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU memory growth to avoid memory allocation issues.\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ITM classifier and plot the training history.\n",
    "\n",
    "itm = ITM_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(itm.history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
