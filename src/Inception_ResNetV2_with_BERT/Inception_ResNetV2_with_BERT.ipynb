{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "d:\\Conda\\envs\\GPU\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from official.nlp import optimization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading image and text data\n",
    "\n",
    "\n",
    "class ITM_DataLoader:\n",
    "    BATCH_SIZE = 16\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    IMAGE_SHAPE = (224, 224, 3)\n",
    "    MAX_SENTENCE_LENGTH = 50\n",
    "    SENTENCE_EMBEDDING_SHAPE = 384\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    DATA_PATH = \"D:/_GITHUB_/Image-Text-Matching/data\"\n",
    "    IMAGES_PATH = DATA_PATH + \"/images\"\n",
    "    train_data_file = DATA_PATH + \"/flickr8k.TrainImages.txt\"\n",
    "    dev_data_file = DATA_PATH + \"/flickr8k.DevImages.txt\"\n",
    "    test_data_file = DATA_PATH + \"/flickr8k.TestImages.txt\"\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    test_ds = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_ds = self.load_classifier_data(self.train_data_file)\n",
    "        self.val_ds = self.load_classifier_data(self.dev_data_file)\n",
    "        self.test_ds = self.load_classifier_data(self.test_data_file)\n",
    "        print(\"done loading data...\")\n",
    "\n",
    "    def process_input(\n",
    "        self, img_path, text_input_ids, text_attention_mask, label, caption\n",
    "    ):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, self.IMAGE_SIZE)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32) / 255.0\n",
    "        file_name = tf.strings.split(img_path, os.path.sep)[-1]\n",
    "        features = {\n",
    "            \"image_input\": img,\n",
    "            \"text_input_ids\": text_input_ids,\n",
    "            \"text_attention_mask\": text_attention_mask,\n",
    "            \"caption\": caption,\n",
    "            \"file_name\": file_name,\n",
    "        }\n",
    "        return features, label\n",
    "\n",
    "    def load_classifier_data(self, data_files):\n",
    "        print(\"LOADING data from \" + str(data_files))\n",
    "        image_data = []\n",
    "        text_input_ids = []\n",
    "        text_attention_masks = []\n",
    "        label_data = []\n",
    "        captions = []\n",
    "\n",
    "        with open(data_files) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                img_name, text, raw_label = line.split(\"\\t\")\n",
    "                img_name = os.path.join(self.IMAGES_PATH, img_name.strip())\n",
    "                label = [1, 0] if raw_label == \"match\" else [0, 1]\n",
    "\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.SENTENCE_EMBEDDING_SHAPE,  # Ensure this attribute is defined\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"tf\",\n",
    "                )\n",
    "\n",
    "                image_data.append(img_name)\n",
    "                text_input_ids.append(\n",
    "                    encoding[\"input_ids\"][0]\n",
    "                )  # [0] to unpack from batch\n",
    "                text_attention_masks.append(\n",
    "                    encoding[\"attention_mask\"][0]\n",
    "                )  # [0] to unpack from batch\n",
    "                label_data.append(label)\n",
    "                captions.append(text)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (image_data, text_input_ids, text_attention_masks, label_data, captions)\n",
    "        )\n",
    "        dataset = dataset.map(self.process_input, num_parallel_calls=self.AUTOTUNE)\n",
    "        dataset = (\n",
    "            dataset.shuffle(self.BATCH_SIZE * 8)\n",
    "            .batch(self.BATCH_SIZE)\n",
    "            .prefetch(self.AUTOTUNE)\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    def print_data_samples(self, dataset):\n",
    "        print(\"PRINTING data samples...\")\n",
    "        print(\"-----------------------------------------\")\n",
    "        for features_batch, label_batch in dataset.take(1):\n",
    "            for i in range(1):\n",
    "                print(f'Image pixels: {features_batch[\"image_input\"]}')\n",
    "                print(f'Caption: {features_batch[\"caption\"].numpy()}')\n",
    "                label = label_batch.numpy()[i]\n",
    "                print(f\"Label : {label}\")\n",
    "        print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main class for the Image-Text Matching (ITM) task\n",
    "\n",
    "\n",
    "class ITM_Classifier(ITM_DataLoader):\n",
    "    epochs = 1\n",
    "    learning_rate = 4e-5\n",
    "    class_names = {\"match\", \"no-match\"}\n",
    "    num_classes = len(class_names)\n",
    "    classifier_model = None\n",
    "    history = None\n",
    "    classifier_model_name = \"ITM_InceptionV3_BERT\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.build_classifier_model()\n",
    "        self.train_classifier_model()\n",
    "        self.test_classifier_model()\n",
    "\n",
    "    # return learnt feature representations of input data (images)\n",
    "    def create_vision_encoder(\n",
    "        self, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        img_input = layers.Input(shape=self.IMAGE_SHAPE, name=\"image_input\")\n",
    "\n",
    "        # Use InceptionResNetV2 with ImageNet weights, excluding the top (fully connected) layer\n",
    "        base_model = InceptionResNetV2(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=img_input,\n",
    "            input_shape=self.IMAGE_SHAPE,\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "\n",
    "        cnn_layer = base_model.output\n",
    "        cnn_layer = layers.GlobalAveragePooling2D()(cnn_layer)\n",
    "        cnn_layer = layers.Dropout(dropout_rate)(cnn_layer)\n",
    "\n",
    "        outputs = self.project_embeddings(\n",
    "            cnn_layer, num_projection_layers, projection_dims, dropout_rate\n",
    "        )\n",
    "        return img_input, outputs\n",
    "\n",
    "    # return learnt feature representations based on dense layers, dropout, and layer normalisation\n",
    "    def project_embeddings(\n",
    "        self, embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    ):\n",
    "        projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "        for _ in range(num_projection_layers):\n",
    "            x = tf.nn.gelu(projected_embeddings)\n",
    "            x = layers.Dense(projection_dims)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "            x = layers.Add()([projected_embeddings, x])\n",
    "            projected_embeddings = layers.LayerNormalization()(x)\n",
    "        return projected_embeddings\n",
    "\n",
    "    # return learnt feature representations of input data (text embeddings in the form of dense vectors)\n",
    "    def create_text_encoder(\n",
    "        self, num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "    ):\n",
    "        bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        bert_model.trainable = (\n",
    "            False  # Set to False to freeze BERT weights, or True to fine-tune\n",
    "        )\n",
    "\n",
    "        # Define the inputs for the BERT model\n",
    "        text_input_ids = tf.keras.Input(\n",
    "            shape=(self.SENTENCE_EMBEDDING_SHAPE,),\n",
    "            dtype=tf.int32,\n",
    "            name=\"text_input_ids\",\n",
    "        )\n",
    "        text_attention_mask = tf.keras.Input(\n",
    "            shape=(self.SENTENCE_EMBEDDING_SHAPE,),\n",
    "            dtype=tf.int32,\n",
    "            name=\"text_attention_mask\",\n",
    "        )\n",
    "\n",
    "        # Getting the output from BERT\n",
    "        bert_output = bert_model(text_input_ids, attention_mask=text_attention_mask)\n",
    "        text_features = bert_output.last_hidden_state\n",
    "        text_features = tf.keras.layers.GlobalAveragePooling1D()(text_features)\n",
    "\n",
    "        # Project the BERT outputs to the desired dimensionality\n",
    "        projected_embeddings = tf.keras.layers.Dense(\n",
    "            projection_dims, activation=\"relu\"\n",
    "        )(text_features)\n",
    "        for _ in range(\n",
    "            1, num_projection_layers\n",
    "        ):  # start from 1 because we already added one Dense layer\n",
    "            x = tf.keras.layers.Dense(projection_dims, activation=\"relu\")(\n",
    "                projected_embeddings\n",
    "            )\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "            projected_embeddings = tf.keras.layers.Add()(\n",
    "                [projected_embeddings, x]\n",
    "            )  # Element-wise addition\n",
    "            projected_embeddings = tf.keras.layers.LayerNormalization()(\n",
    "                projected_embeddings\n",
    "            )\n",
    "\n",
    "        return text_input_ids, text_attention_mask, projected_embeddings\n",
    "\n",
    "    # put together the feature representations above to create the image-text (multimodal) deep learning model\n",
    "    def build_classifier_model(self):\n",
    "        print(\"BUILDING model\")\n",
    "        # Create the vision model part\n",
    "        img_input, vision_net = self.create_vision_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "\n",
    "        # Create the text model part\n",
    "        text_input_ids, text_attention_mask, text_net = self.create_text_encoder(\n",
    "            num_projection_layers=1, projection_dims=128, dropout_rate=0.1\n",
    "        )\n",
    "\n",
    "        # Combine the outputs from both text and vision parts\n",
    "        combined_features = tf.keras.layers.Concatenate(axis=1)([vision_net, text_net])\n",
    "        combined_features = tf.keras.layers.Dense(512, activation=\"relu\")(\n",
    "            combined_features\n",
    "        )\n",
    "        combined_features = tf.keras.layers.Dropout(0.1)(combined_features)\n",
    "        combined_features = tf.keras.layers.Dense(512, activation=\"relu\")(\n",
    "            combined_features\n",
    "        )\n",
    "        combined_features = tf.keras.layers.LayerNormalization()(combined_features)\n",
    "\n",
    "        # Classifier layer\n",
    "        final_output = tf.keras.layers.Dense(\n",
    "            self.num_classes, activation=\"softmax\", name=self.classifier_model_name\n",
    "        )(combined_features)\n",
    "\n",
    "        # Create the full model\n",
    "        self.classifier_model = tf.keras.Model(\n",
    "            inputs=[img_input, text_input_ids, text_attention_mask],\n",
    "            outputs=final_output,\n",
    "        )\n",
    "        self.classifier_model.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        model_dir = \"models\"\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)  # Ensure directory exists\n",
    "        model_path = os.path.join(model_dir, self.classifier_model_name)\n",
    "        history_path = os.path.join(\n",
    "            model_dir, f\"{self.classifier_model_name}_history.pkl\"\n",
    "        )\n",
    "        print(\"SAVING model to\", model_path)\n",
    "        self.classifier_model.save(model_path)  # Save the model\n",
    "        with open(history_path, \"wb\") as f:\n",
    "            pickle.dump(self.history.history, f)  # Save the training history\n",
    "\n",
    "    def train_classifier_model(self):\n",
    "        print(f\"TRAINING model\")\n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        num_warmup_steps = int(0.2 * num_train_steps)\n",
    "\n",
    "        loss = tf.keras.losses.KLDivergence()\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=self.learning_rate,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type=\"adamw\",\n",
    "        )\n",
    "\n",
    "        self.classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # uncomment the next line if you wish to make use of early stopping during training\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=11, restore_best_weights=True)\n",
    "        ]\n",
    "\n",
    "        self.history = self.classifier_model.fit(\n",
    "            x=self.train_ds,\n",
    "            validation_data=self.val_ds,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        self.save_model()\n",
    "\n",
    "        print(\"model trained!\")\n",
    "\n",
    "    def test_classifier_model(self):\n",
    "        print(\n",
    "            \"TESTING classifier model (showing a sample of image-text-matching predictions)...\"\n",
    "        )\n",
    "        num_classifications = 0\n",
    "        num_correct_predictions = 0\n",
    "\n",
    "        # read test data for ITM classification\n",
    "        for features, groundtruth in self.test_ds:\n",
    "            groundtruth = groundtruth.numpy()\n",
    "            predictions = self.classifier_model(features)\n",
    "            predictions = predictions.numpy()\n",
    "            captions = features[\"caption\"].numpy()\n",
    "            file_names = features[\"file_name\"].numpy()\n",
    "\n",
    "            # read test data per batch\n",
    "            for batch_index in range(0, len(groundtruth)):\n",
    "                predicted_values = predictions[batch_index]\n",
    "                probability_match = predicted_values[0]\n",
    "                probability_nomatch = predicted_values[1]\n",
    "                predicted_class = (\n",
    "                    \"[1 0]\" if probability_match > probability_nomatch else \"[0 1]\"\n",
    "                )\n",
    "                if str(groundtruth[batch_index]) == predicted_class:\n",
    "                    num_correct_predictions += 1\n",
    "                num_classifications += 1\n",
    "\n",
    "                # print a sample of predictions -- about 10% of all possible\n",
    "                if random.random() < 0.1:\n",
    "                    caption = captions[batch_index]\n",
    "                    file_name = file_names[batch_index].decode(\"utf-8\")\n",
    "                    print(\n",
    "                        \"ITM=%s PREDICTIONS: match=%s, no-match=%s \\t -> \\t %s\"\n",
    "                        % (caption, probability_match, probability_nomatch, file_name)\n",
    "                    )\n",
    "\n",
    "        # reveal test performance using our own calculations above\n",
    "        accuracy = num_correct_predictions / num_classifications\n",
    "        print(\"TEST accuracy=%4f\" % (accuracy))\n",
    "\n",
    "        # reveal test performance using Tensorflow calculations\n",
    "        loss, accuracy = self.classifier_model.evaluate(self.test_ds)\n",
    "        print(f\"Tensorflow test method: Loss: {loss}; ACCURACY: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(itm):\n",
    "    history_path = os.path.join('models', f'{itm.classifier_model_name}_history.pkl')\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['binary_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_binary_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Let's create an instance of the main class\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING data from D:/_GITHUB_/Image-Text-Matching/data/flickr8k.TrainImages.txt\n"
     ]
    }
   ],
   "source": [
    "itm = ITM_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(itm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
